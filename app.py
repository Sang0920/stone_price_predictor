"""
Stone Price Predictor - Web Application
D·ª± ƒëo√°n gi√° s·∫£n ph·∫©m ƒë√° t·ª± nhi√™n d·ª±a tr√™n d·ªØ li·ªáu Salesforce

Features:
- Load d·ªØ li·ªáu t·ª´ Salesforce (PricebookEntry, Contract_Product__c)
- Machine Learning model ƒë·ªÉ d·ª± ƒëo√°n gi√°
- Ph√¢n t√≠ch gi√° theo ph√¢n kh√∫c (Economy, Common, Premium, Super Premium)
- T√¨m s·∫£n ph·∫©m t∆∞∆°ng t·ª± v·ªõi gi√° ƒë√£ bi·∫øt
"""

import streamlit as st
import pandas as pd
import numpy as np
from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import mean_absolute_error, r2_score
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import json
import os
from typing import Optional, Dict, Any, List, Tuple
import requests
from io import StringIO

# Import Salesforce data loader
from dotenv import load_dotenv
load_dotenv()  # Load .env file for Salesforce credentials

try:
    from salesforce_loader import SalesforceDataLoader
    SALESFORCE_AVAILABLE = True
except ImportError:
    SALESFORCE_AVAILABLE = False

# ============ Configuration ============
st.set_page_config(
    page_title="Stone Price Predictor",
    page_icon="üíé",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f4e79;
        text-align: center;
        margin-bottom: 2rem;
    }
    .segment-economy { background-color: #c6efce; color: #006100; padding: 5px 10px; border-radius: 5px; }
    .segment-common { background-color: #ffeb9c; color: #9c5700; padding: 5px 10px; border-radius: 5px; }
    .segment-premium { background-color: #ffc7ce; color: #9c0006; padding: 5px 10px; border-radius: 5px; }
    .segment-super { background-color: #9e7cc1; color: white; padding: 5px 10px; border-radius: 5px; }
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 20px;
        border-radius: 10px;
        color: white;
        text-align: center;
    }
    .stTabs [data-baseweb="tab-list"] {
        gap: 24px;
    }
</style>
""", unsafe_allow_html=True)

# ============ Pricing Rules Constants ============
SEGMENT_THRESHOLDS = {
    'Super premium': 1500,  # >= 1500 USD/m3
    'Premium': 800,         # >= 800 USD/m3
    'Common': 400,          # >= 400 USD/m3
    'Economy': 0            # < 400 USD/m3
}

# TLR (Tr·ªçng L∆∞·ª£ng Ri√™ng - Specific Weight) per T√çNH TO√ÅN & B√ÅO GI√Å documentation
TLR_CONSTANTS = {
    # ƒê√° ƒëen khu v·ª±c ƒêak N√¥ng
    'ABSOLUTE BASALT': 2.95,
    'DAK_NONG_BASALT': 2.95,
    # ƒê√° khu v·ª±c Ph∆∞·ªõc H√≤a v√† Qui Nh∆°n
    'BLACK BASALT': 2.65,  # Ch·∫ª tay: 2.65, c·∫Øt m√°y: 2.7
    'BLACK BASALT_SAWN': 2.70,
    'HIVE BASALT': 2.20,  # ƒê√° t·ªï ong
    # Granite
    'GREY GRANITE': 2.70,
    'DARK GREY GRANITE': 2.90,
    'WHITE GRANITE': 2.70,
    'YELLOW GRANITE': 2.70,
    'RED GRANITE': 2.70,
    'PINK GRANITE': 2.70,
    # Bluestone
    'BLUESTONE': 2.70,
    # Marble
    'WHITE MARBLE': 2.70,
    'YELLOW MARBLE': 2.70,
    # Default
    'DEFAULT': 2.70,
}

# HS (H·ªá S·ªë ·ªêp ƒê√°y - Coating Factor) per T√çNH TO√ÅN & B√ÅO GI√Å documentation
HS_FACTORS = {
    # ƒê√° l√°t 6cm m·∫∑t ƒë·ªët, c·∫°nh s·ªô (·ªëp ƒë√°y gi·∫£m 3%)
    'FLAMED_TILE_6CM': 0.97,
    # ƒê√° cubic ch·∫ª tay
    'CUBE_5X5X5': 1.00,
    'CUBE_8X8X8': 0.95,
    'CUBE_10X10X8': 0.875,
    'CUBE_20X10X8': 0.875,
    'CUBE_15X15X12': 0.85,
    # ƒê√° cubic m·∫∑t ƒë·ªët, c·∫°nh ch·∫ª tay
    'CUBE_FLAMED_10X10X8': 0.95,
    'CUBE_FLAMED_20X10X8': 0.95,
    # ƒê√° c√¢y c∆∞a l·ªôt (th√™m 5% do d√†y 10.5cm th·ª±c t·∫ø)
    'PALISADE_SAWN': 1.05,
    # Default
    'DEFAULT': 1.00,
}

# Customer Pricing Rules (A-F) per NGUY√äN T·∫ÆC √ÅP D·ª§NG B·∫¢NG GI√Å documentation
# Segment-aware adjustments
CUSTOMER_PRICING_RULES = {
    'A': {
        'description': 'Kh√°ch th√¢n thi·∫øt ƒë·∫∑c bi·ªát (>10 nƒÉm, 50-150 cont)',
        'base_adjustment': {'min': -0.03, 'max': -0.015},  # -1.5% to -3% vs B
        'label': 'B·ªõt 1.5-3% so v·ªõi B',
        'years': '>10',
        'volume': '50-150 cont',
        'authority': 'Th·∫£o lu·∫≠n chi·∫øn l∆∞·ª£c'
    },
    'B': {
        'description': 'Kh√°ch l·ªõn, chuy√™n nghi·ªáp (3-10 nƒÉm, 20-50 cont)',
        'base_adjustment': {'min': -0.04, 'max': -0.02},  # -2% to -4% vs C
        'usd_adjustment': {'min': -30, 'max': -10},  # -10 to -30 USD/m¬≥ vs C
        'label': 'Th·∫•p h∆°n C: 2-4% (10-30 USD/m¬≥)',
        'years': '3-10',
        'volume': '20-50 cont',
        'authority': 'Th·∫£o lu·∫≠n chi·∫øn l∆∞·ª£c'
    },
    'C': {
        'description': 'Kh√°ch h√†ng ph·ªï th√¥ng (1-5 nƒÉm, 5-20 cont)',
        'base_adjustment': {'min': 0, 'max': 0},  # Base price
        'label': 'Gi√° chu·∫©n',
        'years': '1-5',
        'volume': '5-20 cont',
        'authority': {
            'Economy': 10,      # ¬±10 USD/m¬≥
            'Common': 15,       # ¬±15 USD/m¬≥
            'Premium': 20,      # ¬±20 USD/m¬≥ or ¬±0.5 USD/m¬≤
        }
    },
    'D': {
        'description': 'Kh√°ch m·ªõi, khu v·ª±c chi tr·∫£ cao, size nh·ªè (1 nƒÉm, 1-10 cont)',
        'base_adjustment': {'min': 0.03, 'max': 0.06},  # +3% to +6%
        'usd_adjustment': {'min': 15, 'max': 45},  # +15 to +45 USD/m¬≥
        'label': 'Cao h∆°n C: 3-6% (15-45 USD/m¬≥)',
        'years': '1',
        'volume': '1-10 cont',
        'authority': {
            'Premium': 30,       # ¬±30 USD/m¬≥ or ¬±1.0 USD/m¬≤
            'Super premium': 40, # ¬±40 USD/m¬≥ or ¬±1.5 USD/m¬≤
        }
    },
    'E': {
        'description': 'S·∫£n ph·∫©m m·ªõi, s√°ng t·∫°o, cao c·∫•p (1 nƒÉm, 1-10 cont)',
        'base_adjustment': {'min': 0.08, 'max': 0.15},  # √ó1.08 to √ó1.15
        'label': 'Gi√° cao c·∫•p: √ó1.08-1.15 (+5-10%)',
        'years': '1',
        'volume': '1-10 cont',
        'authority': {
            'Premium': 30,       # ¬±30 USD/m¬≥ or ¬±1.0 USD/m¬≤
            'Super premium': 40, # ¬±40 USD/m¬≥ or ¬±1.5 USD/m¬≤
        }
    },
    'F': {
        'description': 'Kh√°ch h√†ng d·ª± √°n, cao c·∫•p (1-5 nƒÉm, 1-50 cont)',
        'base_adjustment': {'min': 0.08, 'max': 0.15},  # √ó1.08 to √ó1.15
        'label': 'D·ª± √°n: √ó1.08-1.15',
        'years': '1-5',
        'volume': '1-50 cont',
        'authority': {
            'Premium': 30,       # ¬±30 USD/m¬≥ or ¬±1.0 USD/m¬≤
            'Super premium': 40, # ¬±40 USD/m¬≥ or ¬±1.5 USD/m¬≤
        }
    },
}

PRODUCT_FAMILIES = [
    'Exterior_Tiles', 'Interior_Tiles', 'WALLSTONE', 'PALISADE', 
    'STAIR', 'ART', 'High-Class', 'SKIRTING', 'SLAB'
]

# Application codes (SKU positions 3-4) with English names
# Per "Copy of Code Rule AND Product list" and "Application Mapping" docs
APPLICATION_CODES = [
    ('1.1', 'Cubes / Cobbles'),
    ('1.3', 'Paving stone / Paving slab/ Crazy Paving'),
    ('2.1', 'Wall stone / Wall brick'),
    ('2.2', 'Wall covering / Wall top'),
    ('2.3', 'Rockface Walling'),
    ('3.1', 'Palisades'),
    ('3.2', 'Border / Kerbs'),
    ('3.3', 'Corner'),
    ('4.1', 'Stair / Step (Block)'),
    ('4.2', 'Step (Cladding)'),
    ('5.1', 'Block'),
    ('6.1', 'Pool surrounding'),
    ('6.2', 'Window sill'),
    ('7.2', 'Tile / Paver'),
    ('8.1', 'Skirtings'),
    ('9.1', 'Slab'),
]

# Application codes for search (includes 'All' option)
APPLICATION_CODES_SEARCH = [('', 'All')] + APPLICATION_CODES

# Stone Color Types and their family groupings
STONE_COLOR_TYPES = [
    'BLACK BASALT', 'BLUESTONE', 'GREY GRANITE', 'ABSOLUTE BASALT',
    'WHITE GRANITE', 'YELLOW GRANITE', 'RED GRANITE', 'PINK GRANITE',
    'WHITE MARBLE', 'YELLOW MARBLE', 'HIVE BASALT'
]

# Stone family mapping (for Priority 2 matching - same family)
STONE_FAMILY_MAP = {
    'BLACK BASALT': 'BASALT',
    'ABSOLUTE BASALT': 'BASALT',
    'HIVE BASALT': 'BASALT',
    'GREY GRANITE': 'GRANITE',
    'WHITE GRANITE': 'GRANITE',
    'YELLOW GRANITE': 'GRANITE',
    'RED GRANITE': 'GRANITE',
    'PINK GRANITE': 'GRANITE',
    'BLUESTONE': 'BLUESTONE',
    'WHITE MARBLE': 'MARBLE',
    'YELLOW MARBLE': 'MARBLE',
}

# Dimension tolerance levels per notes.md
DIMENSION_PRIORITY_LEVELS = {
    '∆Øu ti√™n 1 - ƒê√∫ng k√≠ch th∆∞·ªõc': {'height': 0, 'width': 0, 'length': 0},
    '∆Øu ti√™n 2 - Sai l·ªách nh·ªè': {'height': 1, 'width': 5, 'length': 10},
    '∆Øu ti√™n 3 - Sai l·ªách l·ªõn': {'height': 5, 'width': 15, 'length': 30},
}

CHARGE_UNITS = ['USD/PC', 'USD/M2', 'USD/TON', 'USD/ML', 'USD/M3']

# Customer Regional Groups (Nh√≥m Khu v·ª±c KH)
CUSTOMER_REGIONAL_GROUPS = [
    ('', 'All'),
    ('Nh√≥m ƒë·∫ßu 0', 'Nh√≥m ƒë·∫ßu 0'),
    ('Nh√≥m ƒë·∫ßu 1', 'Nh√≥m ƒë·∫ßu 1'),
    ('Nh√≥m ƒë·∫ßu 2', 'Nh√≥m ƒë·∫ßu 2'),
    ('Nh√≥m ƒë·∫ßu 3', 'Nh√≥m ƒë·∫ßu 3'),
    ('Nh√≥m ƒë·∫ßu 4', 'Nh√≥m ƒë·∫ßu 4'),
    ('Nh√≥m ƒë·∫ßu 5', 'Nh√≥m ƒë·∫ßu 5'),
    ('Nh√≥m ƒë·∫ßu 6', 'Nh√≥m ƒë·∫ßu 6'),
    ('Nh√≥m ƒë·∫ßu 7', 'Nh√≥m ƒë·∫ßu 7'),
    ('Nh√≥m ƒë·∫ßu 8', 'Nh√≥m ƒë·∫ßu 8'),
    ('Nh√≥m ƒë·∫ßu 9', 'Nh√≥m ƒë·∫ßu 9'),
]

# Processing codes with English and Vietnamese names
# Format: (code, English, Vietnamese)
PROCESSING_CODES = [
    ('CUA', 'Sawn', 'C∆∞a'),
    ('DOT', 'Flamed', 'ƒê·ªët'),
    ('DOC', 'Flamed Brush', 'ƒê·ªët Ch·∫£i'),
    ('DOX', 'Flamed Water', 'ƒê·ªët X·ªãt N∆∞·ªõc'),
    ('HON', 'Honed', 'Hon/M√†i M·ªãn'),
    ('CTA', 'Split Handmade', 'Ch·∫ª Tay'),
    ('CLO', 'Sawn then Cleaved', 'C∆∞a L·ªôt'),
    ('TDE', 'Chiseled', 'T∆∞·ªõc ƒê·∫Ωo'),
    ('GCR', 'Vibrated Honed Tumbled', 'G·ªçt C·∫°nh Rung'),
    ('GCT', 'Old Imitation', 'Gi·∫£ C·ªï Tay'),
    ('MGI', 'Scraped', 'M√†i Gi·∫•y'),
    ('PCA', 'Sandblasted', 'Phun C√°t'),
    ('QME', 'Tumbled', 'Quay M·∫ª'),
    ('TLO', 'Cleaved', 'T·ª± Nhi√™n L·ªìi'),
    ('BON', 'Polished', 'B√≥ng'),
    ('BAM', 'Bush Hammered', 'BƒÉm'),
    ('CHA', 'Brush', 'Ch·∫£i'),
]

# Processing codes for search (includes 'All' option)
PROCESSING_CODES_SEARCH = [('', 'All', 'T·∫•t c·∫£')] + PROCESSING_CODES


# ============ Data Generation (Simulated Salesforce Data) ============
@st.cache_data(ttl=3600)
def generate_sample_data(n_samples: int = 500) -> pd.DataFrame:
    """
    Generate sample product pricing data for demonstration.
    In production, this would be replaced with Salesforce API calls.
    """
    np.random.seed(42)
    
    data = []
    for i in range(n_samples):
        # Product attributes
        family = np.random.choice(PRODUCT_FAMILIES)
        stone_class = np.random.choice(STONE_CLASSES)
        stone_color = np.random.choice(STONE_COLOR_TYPES)
        
        # Dimensions in cm
        length = np.random.choice([10, 15, 20, 30, 40, 50, 60, 80, 100, 120])
        width = np.random.choice([5, 8, 10, 15, 20, 30, 40, 60])
        height = np.random.choice([2, 2.5, 3, 5, 6, 7, 8, 10, 12, 15, 20])
        
        # Calculate volume in m3
        volume_m3 = (length * width * height) / 1000000
        area_m2 = (length * width) / 10000
        
        # Base price calculation based on product complexity
        base_price_m3 = 350 + np.random.normal(0, 50)
        
        # Adjustments based on product type
        if family in ['STAIR', 'ART', 'High-Class']:
            base_price_m3 *= 2.5
        elif family in ['Interior_Tiles', 'SLAB']:
            base_price_m3 *= 1.8
        elif family == 'Exterior_Tiles':
            base_price_m3 *= 1.2
            
        # Stone type adjustment
        if stone_color in ['ABSOLUTE BASALT', 'WHITE MARBLE']:
            base_price_m3 *= 1.5
        elif stone_color in ['YELLOW MARBLE', 'RED GRANITE']:
            base_price_m3 *= 1.3
            
        # Size adjustment (smaller pieces = higher price per m3)
        if length <= 15 and width <= 15:
            base_price_m3 *= 1.4
        elif length >= 60 or width >= 60:
            base_price_m3 *= 0.9
            
        # Thickness adjustment
        if height <= 2:
            base_price_m3 *= 2.0  # Thin slices are more expensive
        elif height >= 10:
            base_price_m3 *= 0.85
            
        # Add noise
        price_m3 = max(200, base_price_m3 + np.random.normal(0, 80))
        
        # Calculate segment
        if price_m3 >= 1500:
            segment = 'Super premium'
        elif price_m3 >= 800:
            segment = 'Premium'
        elif price_m3 >= 400:
            segment = 'Common'
        else:
            segment = 'Economy'
            
        # Charge unit
        if family in ['PALISADE', 'STAIR']:
            charge_unit = 'USD/ML'
        elif height <= 3:
            charge_unit = 'USD/M2'
        elif length <= 20 and width <= 20:
            charge_unit = 'USD/PC'
        else:
            charge_unit = np.random.choice(['USD/M3', 'USD/TON'])
            
        # Convert price to selected unit
        if charge_unit == 'USD/M2':
            unit_price = price_m3 * height / 100
        elif charge_unit == 'USD/PC':
            unit_price = price_m3 * volume_m3
        elif charge_unit == 'USD/TON':
            specific_gravity = 2.8 if stone_class == 'BASALT' else 2.65
            unit_price = price_m3 / (specific_gravity * 1.1)
        elif charge_unit == 'USD/ML':
            unit_price = price_m3 * width * height / 10000
        else:
            unit_price = price_m3
            
        # Customer type
        customer_type = np.random.choice(['A', 'B', 'C', 'D', 'E', 'F'], 
                                         p=[0.05, 0.15, 0.35, 0.20, 0.10, 0.15])
        
        # Apply customer discount
        if customer_type == 'A':
            discount = np.random.uniform(0.015, 0.03)
        elif customer_type == 'B':
            discount = np.random.uniform(0.02, 0.04)
        elif customer_type == 'C':
            discount = 0
        elif customer_type == 'D':
            discount = -np.random.uniform(0.03, 0.06)  # Premium price
        elif customer_type == 'E':
            discount = -np.random.uniform(0.05, 0.10)
        else:
            discount = np.random.uniform(-0.02, 0.02)
            
        final_price = unit_price * (1 - discount)
        
        data.append({
            'product_id': f'PROD-{i+1:04d}',
            'product_name': f'{stone_color} {family.replace("_", " ")} {length}x{width}x{height}',
            'family': family,
            'stone_class': stone_class,
            'stone_color_type': stone_color,
            'length_cm': length,
            'width_cm': width,
            'height_cm': height,
            'volume_m3': volume_m3,
            'area_m2': area_m2,
            'charge_unit': charge_unit,
            'list_price': round(unit_price, 2),
            'price_m3': round(price_m3, 2),
            'segment': segment,
            'customer_type': customer_type,
            'discount_pct': round(discount * 100, 2),
            'final_price': round(final_price, 2),
            'created_date': pd.Timestamp.now() - pd.Timedelta(days=np.random.randint(1, 365))
        })
    
    return pd.DataFrame(data)


# ============ Machine Learning Model ============
class StonePricePredictor:
    """Machine Learning model for stone sales price prediction."""
    
    def __init__(self):
        self.model = None
        self.encoders = {}
        self.scaler = StandardScaler()
        self.feature_columns = []
        # NOTE: segment is EXCLUDED to prevent data leakage (segment is derived from price)
        # processing_code is the main surface processing type (e.g., DOT=Flamed, HON=Honed)
        # customer_regional_group is the customer's regional group (Nh√≥m ƒë·∫ßu 0-9) as per notes.md
        self.categorical_columns = ['family', 'stone_color_type', 'charge_unit', 'processing_code', 'customer_regional_group']
        self.numerical_columns = ['length_cm', 'width_cm', 'height_cm', 'volume_m3', 'area_m2']
        # Recency weight decay factor (prices decay by half every 365 days)
        self.recency_half_life_days = 365
        
    def clean_data(self, df: pd.DataFrame, target_col: str = 'sales_price') -> pd.DataFrame:
        """Clean data for training: remove invalid, missing, and outlier data."""
        df_clean = df.copy()
        
        # Remove rows with missing or invalid target
        df_clean = df_clean[df_clean[target_col].notna() & (df_clean[target_col] > 0)]
        
        # Clean processing_code: replace empty/Unknown with 'OTHER'
        if 'processing_code' in df_clean.columns:
            df_clean['processing_code'] = df_clean['processing_code'].fillna('OTHER')
            df_clean['processing_code'] = df_clean['processing_code'].replace('', 'OTHER')
            # Keep 'Unknown' as a valid category but standardize empty strings
        
        # Clean customer_regional_group: replace empty/None with 'Unknown'
        if 'customer_regional_group' in df_clean.columns:
            df_clean['customer_regional_group'] = df_clean['customer_regional_group'].fillna('Unknown')
            df_clean['customer_regional_group'] = df_clean['customer_regional_group'].replace('', 'Unknown')
        
        # Remove rows with missing critical features (excluding columns handled above)
        handled_cols = ['processing_code', 'customer_regional_group']
        for col in self.categorical_columns:
            if col in df_clean.columns and col not in handled_cols:
                df_clean = df_clean[df_clean[col].notna()]
        
        for col in self.numerical_columns:
            if col in df_clean.columns:
                df_clean = df_clean[df_clean[col].notna() & (df_clean[col] >= 0)]
        
        # Remove extreme outliers using IQR method for target variable
        Q1 = df_clean[target_col].quantile(0.01)
        Q3 = df_clean[target_col].quantile(0.99)
        df_clean = df_clean[(df_clean[target_col] >= Q1) & (df_clean[target_col] <= Q3)]
        
        return df_clean
    
    def calculate_recency_weights(self, df: pd.DataFrame) -> np.ndarray:
        """
        Calculate sample weights based on recency (more recent prices have higher weight).
        Uses exponential time decay with configurable half-life.
        
        This helps improve accuracy for new products by prioritizing recent price data,
        accounting for annual cost increases in raw materials and labor.
        """
        if 'created_date' not in df.columns:
            return np.ones(len(df))
        
        # Convert created_date to datetime
        dates = pd.to_datetime(df['created_date'], errors='coerce', utc=True)
        
        # Calculate days since each transaction
        reference_date = pd.Timestamp.now(tz='UTC')
        days_ago = (reference_date - dates).dt.total_seconds() / (24 * 3600)
        
        # Handle NaT values - fill with a large number (oldest date equivalent)
        max_days = days_ago.max()
        if pd.isna(max_days):
            max_days = 365 * 5  # Default to 5 years if all dates are NaT
        days_ago = days_ago.fillna(max_days)
        
        # Exponential time decay: weight = 2^(-days_ago / half_life)
        # Recent prices (days_ago=0) get weight=1, prices from 1 year ago get weight=0.5
        weights = np.power(2, -days_ago / self.recency_half_life_days)
        
        # Normalize weights to have mean of 1 (preserves sample count influence)
        weights = weights / weights.mean()
        
        return weights.values
        
    def prepare_features(self, df: pd.DataFrame, fit: bool = False) -> np.ndarray:
        """Prepare features for ML model."""
        features = df.copy()
        
        # Encode categorical variables
        for col in self.categorical_columns:
            if col in features.columns:
                if fit:
                    self.encoders[col] = LabelEncoder()
                    features[f'{col}_encoded'] = self.encoders[col].fit_transform(features[col].astype(str))
                else:
                    # Handle unseen categories
                    features[f'{col}_encoded'] = features[col].apply(
                        lambda x: self.encoders[col].transform([str(x)])[0] 
                        if str(x) in self.encoders[col].classes_ else -1
                    )
        
        # Select feature columns
        encoded_cols = [f'{col}_encoded' for col in self.categorical_columns if col in df.columns]
        available_numerical = [col for col in self.numerical_columns if col in df.columns]
        self.feature_columns = available_numerical + encoded_cols
        
        X = features[self.feature_columns].values
        
        if fit:
            X = self.scaler.fit_transform(X)
        else:
            X = self.scaler.transform(X)
            
        return X
    
    def train(self, df: pd.DataFrame, target_col: str = 'sales_price') -> Dict[str, float]:
        """Train the sales price prediction model with proper data cleaning and recency weighting."""
        # Clean data: remove invalid, missing, and outlier data
        df_clean = self.clean_data(df, target_col)
        
        if len(df_clean) < 50:
            raise ValueError(f"Kh√¥ng ƒë·ªß d·ªØ li·ªáu h·ª£p l·ªá ƒë·ªÉ hu·∫•n luy·ªán model (ch·ªâ c√≥ {len(df_clean)} m·∫´u, c·∫ßn √≠t nh·∫•t 50)")
        
        # Calculate recency weights (recent prices have higher weight)
        sample_weights = self.calculate_recency_weights(df_clean)
        
        # Prepare features
        X = self.prepare_features(df_clean, fit=True)
        y = df_clean[target_col].values
        
        # Split data with stratification based on charge_unit if possible
        # Also split sample weights to use during training
        X_train, X_test, y_train, y_test, weights_train, weights_test = train_test_split(
            X, y, sample_weights, test_size=0.2, random_state=42
        )
        
        # Optimized Gradient Boosting model for price prediction
        # - subsample < 1.0 helps prevent overfitting
        # - n_iter_no_change enables early stopping
        # - lower learning rate with more estimators for better generalization
        self.model = GradientBoostingRegressor(
            n_estimators=200,
            learning_rate=0.05,        # Lower learning rate for better generalization
            max_depth=4,               # Shallower trees to prevent overfitting
            min_samples_split=10,      # Require more samples to split
            min_samples_leaf=5,        # Require more samples in leaves
            subsample=0.8,             # Use 80% of data per tree (stochastic GB)
            max_features='sqrt',       # Use sqrt of features for each split
            n_iter_no_change=10,       # Early stopping if no improvement
            validation_fraction=0.1,   # Use 10% for validation
            random_state=42
        )
        # Use sample weights during training to prioritize recent prices
        self.model.fit(X_train, y_train, sample_weight=weights_train)
        
        # Evaluate on test set (weighted by recency)
        y_pred = self.model.predict(X_test)
        mae = mean_absolute_error(y_test, y_pred, sample_weight=weights_test)
        r2 = r2_score(y_test, y_pred, sample_weight=weights_test)
        
        # Cross-validation for more robust metrics (unweighted for comparison)
        cv_scores = cross_val_score(self.model, X, y, cv=5, scoring='neg_mean_absolute_error')
        cv_r2_scores = cross_val_score(self.model, X, y, cv=5, scoring='r2')
        
        return {
            'mae': mae,
            'r2': r2,
            'cv_mae_mean': -cv_scores.mean(),
            'cv_mae_std': cv_scores.std(),
            'cv_r2_mean': cv_r2_scores.mean(),
            'cv_r2_std': cv_r2_scores.std(),
            'train_samples': len(df_clean),
            'removed_samples': len(df) - len(df_clean),
            'target_col': target_col,
            'n_estimators_used': self.model.n_estimators_,
            'recency_weighted': True
        }
    
    def predict(self, df: pd.DataFrame) -> np.ndarray:
        """Predict sales prices for new data."""
        if self.model is None:
            raise ValueError("Model not trained. Please train the model first.")
        
        X = self.prepare_features(df, fit=False)
        return self.model.predict(X)
    
    def get_feature_importance(self) -> pd.DataFrame:
        """Get feature importance from the model."""
        if self.model is None:
            return pd.DataFrame()
        
        importance = pd.DataFrame({
            'feature': self.feature_columns,
            'importance': self.model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        return importance


# ============ Helper Functions ============
def get_tlr(stone_color_type: str, processing_code: str = None) -> float:
    """
    Get TLR (Specific Weight) for stone type.
    Per T√çNH TO√ÅN & B√ÅO GI√Å documentation.
    """
    # Check for sawn processing (c·∫Øt m√°y = higher TLR)
    if processing_code in ['CUA', 'HON', 'BON'] and 'BASALT' in stone_color_type.upper():
        return TLR_CONSTANTS.get(stone_color_type + '_SAWN', TLR_CONSTANTS.get(stone_color_type, 2.70))
    return TLR_CONSTANTS.get(stone_color_type, TLR_CONSTANTS['DEFAULT'])


def get_hs_factor(dimensions: tuple = None, processing_code: str = None, family: str = None) -> float:
    """
    Get HS (Coating Factor) for product dimensions/type.
    Per T√çNH TO√ÅN & B√ÅO GI√Å documentation.
    """
    if dimensions:
        l, w, h = dimensions
        # Check for cube dimensions
        if l == 5 and w == 5 and h == 5:
            return HS_FACTORS['CUBE_5X5X5']
        if l == 8 and w == 8 and h == 8:
            return HS_FACTORS['CUBE_8X8X8']
        if (l == 10 and w == 10 and h == 8) or (l == 20 and w == 10 and h == 8):
            if processing_code in ['DOT', 'DOC', 'DOX']:  # Flamed
                return HS_FACTORS['CUBE_FLAMED_10X10X8']
            return HS_FACTORS['CUBE_10X10X8']
        if l == 15 and w == 15 and h == 12:
            return HS_FACTORS['CUBE_15X15X12']
        # Flamed tile 6cm
        if h == 6 and processing_code in ['DOT', 'DOC', 'DOX']:
            return HS_FACTORS['FLAMED_TILE_6CM']
    
    # Check for palisade
    if family == 'PALISADE' and processing_code in ['CLO', 'CUA']:
        return HS_FACTORS['PALISADE_SAWN']
    
    return HS_FACTORS['DEFAULT']


def calculate_volume_m3(length_cm: float, width_cm: float, height_cm: float, quantity: int = 1) -> float:
    """Calculate volume in m¬≥. Formula: (L√óW√óH)/1,000,000 √ó qty"""
    return (length_cm * width_cm * height_cm) / 1_000_000 * quantity


def calculate_area_m2(length_cm: float, width_cm: float, quantity: int = 1) -> float:
    """Calculate area in m¬≤. Formula: (L√óW)/10,000 √ó qty"""
    return (length_cm * width_cm) / 10_000 * quantity


def calculate_weight_tons(volume_m3: float, stone_color_type: str, processing_code: str = None,
                          dimensions: tuple = None, family: str = None) -> float:
    """
    Calculate weight in tons.
    Formula: m¬≥ √ó TLR √ó HS
    """
    tlr = get_tlr(stone_color_type, processing_code)
    hs = get_hs_factor(dimensions, processing_code, family)
    return volume_m3 * tlr * hs


def convert_price(price: float, from_unit: str, to_unit: str, 
                  height_cm: float = None, tlr: float = 2.70, hs: float = 1.0,
                  length_cm: float = None, width_cm: float = None) -> float:
    """
    Convert price between units (USD/PC, USD/M2, USD/M3, USD/TON).
    Per T√çNH TO√ÅN & B√ÅO GI√Å documentation.
    """
    height_m = (height_cm / 100) if height_cm else 0.03
    
    # First convert to price per m¬≥
    if from_unit == 'USD/M3':
        price_m3 = price
    elif from_unit == 'USD/M2':
        price_m3 = price / height_m
    elif from_unit == 'USD/TON':
        price_m3 = price * tlr * hs
    elif from_unit == 'USD/PC':
        if length_cm and width_cm and height_cm:
            vol = (length_cm * width_cm * height_cm) / 1_000_000
            price_m3 = price / vol if vol > 0 else price
        else:
            price_m3 = price * 100  # Rough estimate
    else:
        price_m3 = price
    
    # Then convert from m¬≥ to target unit
    if to_unit == 'USD/M3':
        return price_m3
    elif to_unit == 'USD/M2':
        return price_m3 * height_m
    elif to_unit == 'USD/TON':
        return price_m3 / tlr / hs if tlr > 0 else price_m3
    elif to_unit == 'USD/PC':
        if length_cm and width_cm and height_cm:
            vol = (length_cm * width_cm * height_cm) / 1_000_000
            return price_m3 * vol
        else:
            return price_m3 / 100  # Rough estimate
    else:
        return price_m3


def classify_segment(price_m3: float, height_cm: float = None, family: str = None, 
                     processing_code: str = None) -> str:
    """
    Classify price into segment.
    Per PH√ÇN KH√öC D·ª∞A TR√äN GI√Å V√Ä S·∫¢N PH·∫®M documentation.
    
    Considers both price AND product characteristics:
    - Super premium: ‚â•$1500/m¬≥ OR thin paving (1-1.5cm), wall/pool covering, decorative
    - Premium: ‚â•$800/m¬≥ OR tiles (2-5cm), slabs, steps
    - Common: ‚â•$400/m¬≥ OR palisades, cubes, tumbled
    - Economy: <$400/m¬≥ OR natural split, thick pavers
    """
    # Check product-based rules first
    if height_cm is not None:
        # Thin paving (1.0-1.5cm) = Super premium
        if height_cm <= 1.5 and family in ['Exterior_Tiles', 'Interior_Tiles']:
            return 'Super premium'
        # Tiles 2-5cm with quality processing = Premium
        if 2.0 <= height_cm <= 5.0 and processing_code in ['DOT', 'DOC', 'DOX', 'HON', 'BON']:
            if price_m3 >= 600:  # Slightly lower threshold for processed tiles
                return 'Premium'
        # Thick natural split (‚â•6cm) = Economy
        if height_cm >= 6 and processing_code in ['CTA', 'TLO']:
            return 'Economy'
    
    # Check family-based rules
    if family:
        if family in ['ART', 'High-Class']:
            return 'Super premium'
        if family in ['SLAB', 'STAIR']:
            return 'Premium' if price_m3 >= 600 else 'Common'
        if family == 'PALISADE' and processing_code in ['CLO', 'CUA']:
            return 'Common'
    
    # Fall back to price-based classification
    if price_m3 >= 1500:
        return 'Super premium'
    elif price_m3 >= 800:
        return 'Premium'
    elif price_m3 >= 400:
        return 'Common'
    else:
        return 'Economy'

def get_segment_color(segment: str) -> str:
    """Get color for segment."""
    colors = {
        'Super premium': '#9e7cc1',
        'Premium': '#ff6b6b',
        'Common': '#ffd93d',
        'Economy': '#6bcb77'
    }
    return colors.get(segment, '#808080')

def calculate_customer_price(base_price: float, customer_type: str, 
                             segment: str = None, charge_unit: str = 'USD/M3') -> Dict[str, Any]:
    """
    Calculate price adjustments for different customer types.
    Per NGUY√äN T·∫ÆC √ÅP D·ª§NG B·∫¢NG GI√Å ABCDEF documentation.
    
    Args:
        base_price: The reference price
        customer_type: Customer classification (A-F)
        segment: Product segment for authority range
        charge_unit: Price unit for displaying USD adjustments
    """
    rules = CUSTOMER_PRICING_RULES.get(customer_type, CUSTOMER_PRICING_RULES['C'])
    adj = rules.get('base_adjustment', {'min': 0, 'max': 0})
    
    min_price = round(base_price * (1 + adj['min']), 2)
    max_price = round(base_price * (1 + adj['max']), 2)
    
    # Get authority range based on segment
    authority_range = None
    authority = rules.get('authority')
    if isinstance(authority, dict) and segment:
        authority_range = authority.get(segment)
    
    # Format authority display
    if authority_range:
        if charge_unit == 'USD/M2':
            auth_display = f"¬±{authority_range * 0.05:.1f} USD/m¬≤"  # Approximate m¬≤ conversion
        else:
            auth_display = f"¬±{authority_range} USD/m¬≥"
    elif isinstance(authority, str):
        auth_display = authority
    else:
        auth_display = rules.get('label', 'N/A')
    
    return {
        'base_price': base_price,
        'min_price': min_price,
        'max_price': max_price,
        'adjustment_label': rules.get('label', 'N/A'),
        'customer_description': rules.get('description', ''),
        'authority_range': auth_display,
        'volume': rules.get('volume', ''),
        'years': rules.get('years', ''),
    }

def find_similar_products(df: pd.DataFrame, query: Dict, top_n: int = 5) -> pd.DataFrame:
    """Find similar products based on attributes."""
    # Filter by basic criteria
    mask = pd.Series([True] * len(df))
    
    if query.get('stone_color_type'):
        mask &= df['stone_color_type'] == query['stone_color_type']
    
    if query.get('family'):
        mask &= df['family'] == query['family']
    
    filtered_df = df[mask].copy()
    
    if len(filtered_df) == 0:
        return pd.DataFrame()
    
    # Calculate similarity score based on dimensions
    if all(k in query for k in ['length_cm', 'width_cm', 'height_cm']):
        filtered_df['dim_diff'] = (
            abs(filtered_df['length_cm'] - query['length_cm']) +
            abs(filtered_df['width_cm'] - query['width_cm']) +
            abs(filtered_df['height_cm'] - query['height_cm'])
        )
        filtered_df = filtered_df.nsmallest(top_n, 'dim_diff')
    else:
        filtered_df = filtered_df.head(top_n)
    
    return filtered_df


# ============ Similarity-Based Price Predictor ============
class SimilarityPricePredictor:
    """
    Price estimation based on similarity search with priority levels.
    Matches products using criteria from notes.md.
    """
    
    def __init__(self):
        self.data = None
        self.recency_half_life_days = 365
        
    def load_data(self, df: pd.DataFrame):
        """Load and prepare data for similarity search."""
        self.data = df[df['sales_price'].notna() & (df['sales_price'] > 0)].copy()
        # Add stone family for priority 2 matching
        if 'stone_color_type' in self.data.columns:
            self.data['stone_family'] = self.data['stone_color_type'].map(STONE_FAMILY_MAP).fillna('OTHER')
        return len(self.data)
    
    def find_matching_products(
        self, 
        stone_color_type: str,
        processing_code: str,
        length_cm: float,
        width_cm: float,
        height_cm: float,
        application_codes: list,  # List of application codes (empty = all)
        customer_regional_group: str,
        charge_unit: str,
        stone_priority: str = '∆Øu ti√™n 1',  # Exact, Same Family, All
        processing_priority: str = '∆Øu ti√™n 1',  # Exact, All
        dimension_priority: str = '∆Øu ti√™n 1 - ƒê√∫ng k√≠ch th∆∞·ªõc',
        region_priority: str = '∆Øu ti√™n 1',  # Exact, All
    ) -> pd.DataFrame:
        """
        Find matching products based on priority criteria from notes.md.
        
        Priority Levels:
        - ∆Øu ti√™n 1: Exact match
        - ∆Øu ti√™n 2: Same family / small tolerance
        - ∆Øu ti√™n 3: All / large tolerance
        """
        if self.data is None or len(self.data) == 0:
            return pd.DataFrame()
        
        df = self.data.copy()
        mask = pd.Series([True] * len(df), index=df.index)
        
        # 1. Stone Type Filter
        query_family = STONE_FAMILY_MAP.get(stone_color_type, 'OTHER')
        if stone_priority == '∆Øu ti√™n 1':
            mask &= df['stone_color_type'] == stone_color_type
        elif stone_priority == '∆Øu ti√™n 2':
            mask &= df['stone_family'] == query_family
        # ∆Øu ti√™n 3: No filter (All stones)
        
        # 2. Processing Filter
        if processing_priority == '∆Øu ti√™n 1' and processing_code:
            mask &= df['processing_code'] == processing_code
        # ∆Øu ti√™n 2+: No filter (All processing types)
        
        # 3. Application Filter (extracted from SKU positions 3-4)
        # If application_codes is not empty, filter by those codes
        if application_codes and len(application_codes) > 0 and 'application_code' in df.columns:
            mask &= df['application_code'].isin(application_codes)
        
        # 4. Charge Unit Filter
        if charge_unit:
            mask &= df['charge_unit'] == charge_unit
        
        # 5. Regional Group Filter
        if 'customer_regional_group' in df.columns:
            if region_priority == '∆Øu ti√™n 1' and customer_regional_group:
                mask &= df['customer_regional_group'] == customer_regional_group
            # ∆Øu ti√™n 2+: No filter (All regions)
        
        # Apply initial filters
        df_filtered = df[mask].copy()
        
        if len(df_filtered) == 0:
            return pd.DataFrame()
        
        # 6. Dimension Filter with tolerances
        tolerances = DIMENSION_PRIORITY_LEVELS.get(dimension_priority, {'height': 0, 'width': 0, 'length': 0})
        
        dim_mask = (
            (abs(df_filtered['height_cm'] - height_cm) <= tolerances['height']) &
            (abs(df_filtered['width_cm'] - width_cm) <= tolerances['width']) &
            (abs(df_filtered['length_cm'] - length_cm) <= tolerances['length'])
        )
        
        df_matches = df_filtered[dim_mask].copy()
        
        return df_matches
    
    def get_match_diagnostics(
        self,
        stone_color_type: str,
        processing_code: str,
        length_cm: float,
        width_cm: float,
        height_cm: float,
        application_codes: list,
        customer_regional_group: str,
        charge_unit: str,
        stone_priority: str = '∆Øu ti√™n 1',
        processing_priority: str = '∆Øu ti√™n 1',
        dimension_priority: str = '∆Øu ti√™n 1 - ƒê√∫ng k√≠ch th∆∞·ªõc',
        region_priority: str = '∆Øu ti√™n 1',
    ) -> Dict[str, Any]:
        """
        Analyze why no matches were found and return diagnostic information.
        Returns closest available dimensions and filter breakdown.
        """
        if self.data is None or len(self.data) == 0:
            return {'reason': 'Kh√¥ng c√≥ d·ªØ li·ªáu', 'suggestions': []}
        
        df = self.data.copy()
        diagnostics = {
            'reason': '',
            'suggestions': [],
            'closest_height': None,
            'closest_width': None,
            'closest_length': None,
            'filter_counts': {}
        }
        
        # Track filter stages
        mask = pd.Series([True] * len(df), index=df.index)
        diagnostics['filter_counts']['total'] = len(df)
        
        # 1. Stone type
        query_family = STONE_FAMILY_MAP.get(stone_color_type, 'OTHER')
        if stone_priority == '∆Øu ti√™n 1':
            stone_mask = df['stone_color_type'] == stone_color_type
        elif stone_priority == '∆Øu ti√™n 2':
            stone_mask = df['stone_family'] == query_family
        else:
            stone_mask = pd.Series([True] * len(df), index=df.index)
        mask &= stone_mask
        diagnostics['filter_counts']['after_stone'] = mask.sum()
        
        # 2. Processing
        if processing_priority == '∆Øu ti√™n 1' and processing_code:
            proc_mask = df['processing_code'] == processing_code
            mask &= proc_mask
        diagnostics['filter_counts']['after_processing'] = mask.sum()
        
        # 3. Application
        if application_codes and len(application_codes) > 0 and 'application_code' in df.columns:
            mask &= df['application_code'].isin(application_codes)
        diagnostics['filter_counts']['after_application'] = mask.sum()
        
        # 4. Charge unit
        if charge_unit:
            mask &= df['charge_unit'] == charge_unit
        diagnostics['filter_counts']['after_charge_unit'] = mask.sum()
        
        # 5. Region
        if 'customer_regional_group' in df.columns and region_priority == '∆Øu ti√™n 1' and customer_regional_group:
            mask &= df['customer_regional_group'] == customer_regional_group
        diagnostics['filter_counts']['after_region'] = mask.sum()
        
        df_filtered = df[mask].copy()
        
        if len(df_filtered) == 0:
            # Find which filter caused the problem
            if diagnostics['filter_counts']['after_stone'] == 0:
                diagnostics['reason'] = f"Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m lo·∫°i ƒë√° '{stone_color_type}'"
                diagnostics['suggestions'].append("Th·ª≠ ch·ªçn ∆Øu ti√™n 2 ho·∫∑c 3 cho Lo·∫°i ƒë√°")
            elif diagnostics['filter_counts']['after_processing'] == 0:
                diagnostics['reason'] = f"Kh√¥ng t√¨m th·∫•y gia c√¥ng '{processing_code}' cho lo·∫°i ƒë√° n√†y"
                diagnostics['suggestions'].append("Th·ª≠ ch·ªçn ∆Øu ti√™n 2 cho Gia c√¥ng")
            elif diagnostics['filter_counts']['after_application'] == 0:
                app_names = ', '.join(application_codes) if application_codes else ''
                diagnostics['reason'] = f"Kh√¥ng t√¨m th·∫•y ·ª©ng d·ª•ng '{app_names}' cho c√°c ti√™u ch√≠ ƒë√£ ch·ªçn"
                diagnostics['suggestions'].append("Th·ª≠ b·ªè ch·ªçn ·ª©ng d·ª•ng c·ª• th·ªÉ")
            elif diagnostics['filter_counts']['after_charge_unit'] == 0:
                diagnostics['reason'] = f"Kh√¥ng t√¨m th·∫•y ƒë∆°n v·ªã t√≠nh '{charge_unit}'"
                diagnostics['suggestions'].append("Th·ª≠ ƒë·ªïi ƒë∆°n v·ªã t√≠nh gi√°")
            else:
                diagnostics['reason'] = "Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m v·ªõi c√°c ti√™u ch√≠ ƒë√£ ch·ªçn"
            return diagnostics
        
        # 6. Check dimensions
        tolerances = DIMENSION_PRIORITY_LEVELS.get(dimension_priority, {'height': 0, 'width': 0, 'length': 0})
        
        # Find closest dimensions in filtered data
        closest_height = df_filtered.loc[(df_filtered['height_cm'] - height_cm).abs().idxmin(), 'height_cm']
        closest_width = df_filtered.loc[(df_filtered['width_cm'] - width_cm).abs().idxmin(), 'width_cm']
        closest_length = df_filtered.loc[(df_filtered['length_cm'] - length_cm).abs().idxmin(), 'length_cm']
        
        diagnostics['closest_height'] = closest_height
        diagnostics['closest_width'] = closest_width
        diagnostics['closest_length'] = closest_length
        
        height_diff = abs(closest_height - height_cm)
        width_diff = abs(closest_width - width_cm)
        length_diff = abs(closest_length - length_cm)
        
        # Check which dimension is blocking
        dim_issues = []
        if height_diff > tolerances['height']:
            dim_issues.append(f"Cao {height_cm}cm (g·∫ßn nh·∫•t: {closest_height}cm, sai l·ªách: {height_diff:.0f}cm > ¬±{tolerances['height']}cm)")
        if width_diff > tolerances['width']:
            dim_issues.append(f"R·ªông {width_cm}cm (g·∫ßn nh·∫•t: {closest_width}cm, sai l·ªách: {width_diff:.0f}cm > ¬±{tolerances['width']}cm)")
        if length_diff > tolerances['length']:
            dim_issues.append(f"D√†i {length_cm}cm (g·∫ßn nh·∫•t: {closest_length}cm, sai l·ªách: {length_diff:.0f}cm > ¬±{tolerances['length']}cm)")
        
        if dim_issues:
            diagnostics['reason'] = "Kh√¥ng t√¨m th·∫•y k√≠ch th∆∞·ªõc ph√π h·ª£p:\n‚Ä¢ " + "\n‚Ä¢ ".join(dim_issues)
            diagnostics['suggestions'].append("Th·ª≠ ch·ªçn ∆Øu ti√™n 3 cho K√≠ch th∆∞·ªõc (sai l·ªách l·ªõn)")
        
        diagnostics['filter_counts']['after_dimensions'] = len(self.find_matching_products(
            stone_color_type, processing_code, length_cm, width_cm, height_cm,
            application_codes, customer_regional_group, charge_unit,
            stone_priority, processing_priority, dimension_priority, region_priority
        ))
        
        return diagnostics
    
    def calculate_recency_weights(self, df: pd.DataFrame) -> pd.Series:
        """Calculate recency weights for price averaging."""
        if 'created_date' not in df.columns or len(df) == 0:
            return pd.Series([1.0] * len(df), index=df.index)
        
        dates = pd.to_datetime(df['created_date'], errors='coerce', utc=True)
        reference_date = pd.Timestamp.now(tz='UTC')
        days_ago = (reference_date - dates).dt.total_seconds() / (24 * 3600)
        
        max_days = days_ago.max()
        if pd.isna(max_days):
            max_days = 365 * 5
        days_ago = days_ago.fillna(max_days)
        
        weights = np.power(2, -days_ago / self.recency_half_life_days)
        return weights
    
    def estimate_price(self, matches: pd.DataFrame, use_recent_only: bool = True, recent_count: int = 10,
                        query_length_cm: float = None, query_width_cm: float = None, query_height_cm: float = None,
                        target_charge_unit: str = 'USD/M3', stone_color_type: str = None, processing_code: str = None) -> Dict[str, Any]:
        """
        Estimate price from matching products.
        Uses recency-weighted average, optionally filtering to most recent products.
        
        IMPORTANT: Normalizes all prices to USD/M3 before averaging to account for 
        different product sizes. Then converts back to target_charge_unit using 
        query dimensions. This ensures that larger products are priced proportionally 
        higher than smaller similar products.
        
        Args:
            matches: DataFrame of matching products
            use_recent_only: If True, filter to only the most recent products
            recent_count: Number of most recent products to use (if use_recent_only=True)
            query_length_cm: Length of the product being quoted (for unit conversion)
            query_width_cm: Width of the product being quoted (for unit conversion)
            query_height_cm: Height of the product being quoted (for unit conversion)
            target_charge_unit: The unit to return the price in (USD/PC, USD/M2, USD/M3, USD/TON)
            stone_color_type: Stone type for TLR calculation
            processing_code: Processing code for TLR/HS calculation
        """
        if len(matches) == 0:
            return {
                'estimated_price': None,
                'min_price': None,
                'max_price': None,
                'median_price': None,
                'match_count': 0,
                'total_matches': 0,
                'confidence': 'none',
                'years_used': '',
                'price_m3': None
            }
        
        total_matches = len(matches)
        
        # Filter to most recent products based on fy_year and created_date
        if use_recent_only and len(matches) > recent_count:
            # Sort by fy_year (desc) then created_date (desc)
            sorted_matches = matches.copy()
            if 'fy_year' in sorted_matches.columns:
                # Convert fy_year to numeric for proper sorting
                sorted_matches['_fy_year_numeric'] = pd.to_numeric(sorted_matches['fy_year'], errors='coerce')
                sorted_matches = sorted_matches.sort_values(
                    by=['_fy_year_numeric', 'created_date'], 
                    ascending=[False, False],
                    na_position='last'
                )
                sorted_matches = sorted_matches.drop(columns=['_fy_year_numeric'])
            elif 'created_date' in sorted_matches.columns:
                sorted_matches = sorted_matches.sort_values(
                    by=['created_date'], 
                    ascending=[False],
                    na_position='last'
                )
            # Take only the top N most recent
            matches = sorted_matches.head(recent_count)
        
        # Get years used for display
        years_used = ''
        if 'fy_year' in matches.columns:
            unique_years = matches['fy_year'].dropna().unique()
            unique_years = sorted([int(y) for y in unique_years if pd.notna(y)], reverse=True)
            if len(unique_years) > 0:
                years_used = ', '.join(str(y) for y in unique_years[:3])
        
        # Calculate weights
        weights = self.calculate_recency_weights(matches)
        
        # Normalize all prices to USD/M3 before averaging
        # This ensures fair comparison across different product sizes
        prices_m3 = []
        for idx, row in matches.iterrows():
            price = row['sales_price']
            unit = row.get('charge_unit', 'USD/M3')
            match_length = row.get('length_cm', 10)
            match_width = row.get('width_cm', 10)
            match_height = row.get('height_cm', 3)
            match_stone = row.get('stone_color_type', stone_color_type or 'ABSOLUTE BASALT')
            match_proc = row.get('processing_code', processing_code)
            
            # Get TLR and HS for this product
            tlr = get_tlr(match_stone, match_proc)
            hs = get_hs_factor((match_length, match_width, match_height), match_proc)
            
            # Convert to USD/M3
            price_m3 = convert_price(
                price, unit, 'USD/M3',
                height_cm=match_height,
                length_cm=match_length,
                width_cm=match_width,
                tlr=tlr,
                hs=hs
            )
            prices_m3.append(price_m3)
        
        prices_m3 = pd.Series(prices_m3, index=matches.index)
        
        # Weighted average in USD/M3 (the normalized unit)
        weighted_price_m3 = np.average(prices_m3, weights=weights)
        
        # Convert from USD/M3 to target unit using QUERY dimensions
        # This is the key: we use the NEW product's dimensions, not the matched products'
        if query_length_cm is not None and query_width_cm is not None and query_height_cm is not None:
            query_tlr = get_tlr(stone_color_type or 'ABSOLUTE BASALT', processing_code)
            query_hs = get_hs_factor((query_length_cm, query_width_cm, query_height_cm), processing_code)
            
            estimated_price = convert_price(
                weighted_price_m3, 'USD/M3', target_charge_unit,
                height_cm=query_height_cm,
                length_cm=query_length_cm,
                width_cm=query_width_cm,
                tlr=query_tlr,
                hs=query_hs
            )
            
            # Also convert min/max/median to target unit
            min_price = convert_price(
                prices_m3.min(), 'USD/M3', target_charge_unit,
                height_cm=query_height_cm, length_cm=query_length_cm, width_cm=query_width_cm,
                tlr=query_tlr, hs=query_hs
            )
            max_price = convert_price(
                prices_m3.max(), 'USD/M3', target_charge_unit,
                height_cm=query_height_cm, length_cm=query_length_cm, width_cm=query_width_cm,
                tlr=query_tlr, hs=query_hs
            )
            median_price = convert_price(
                prices_m3.median(), 'USD/M3', target_charge_unit,
                height_cm=query_height_cm, length_cm=query_length_cm, width_cm=query_width_cm,
                tlr=query_tlr, hs=query_hs
            )
        else:
            # Fallback: use original method (direct averaging) if no query dimensions
            prices = matches['sales_price']
            estimated_price = np.average(prices, weights=weights)
            min_price = prices.min()
            max_price = prices.max()
            median_price = prices.median()
        
        # Confidence based on match count
        if len(matches) >= 10:
            confidence = 'high'
        elif len(matches) >= 5:
            confidence = 'medium'
        elif len(matches) >= 2:
            confidence = 'low'
        else:
            confidence = 'very_low'
        
        # Calculate price trend based on fy_year
        price_trend = None
        trend_pct = None
        if 'fy_year' in matches.columns and len(matches) >= 3:
            # Group by year and calculate average price_m3
            yearly_data = pd.DataFrame({
                'fy_year': matches['fy_year'],
                'price_m3': prices_m3
            })
            yearly_avg = yearly_data.groupby('fy_year')['price_m3'].mean()
            if len(yearly_avg) >= 2:
                sorted_years = sorted(yearly_avg.index, reverse=True)
                if len(sorted_years) >= 2:
                    this_year_price = yearly_avg[sorted_years[0]]
                    last_year_price = yearly_avg[sorted_years[1]]
                    if last_year_price > 0:
                        trend_pct = ((this_year_price - last_year_price) / last_year_price) * 100
                        if trend_pct > 0:
                            price_trend = 'up'
                        elif trend_pct < 0:
                            price_trend = 'down'
                        else:
                            price_trend = 'stable'
        
        return {
            'estimated_price': round(estimated_price, 2),
            'min_price': round(min_price, 2),
            'max_price': round(max_price, 2),
            'median_price': round(median_price, 2),
            'match_count': len(matches),
            'total_matches': total_matches,
            'confidence': confidence,
            'years_used': years_used,
            'price_m3': round(weighted_price_m3, 2),
            'price_trend': price_trend,
            'trend_pct': round(trend_pct, 1) if trend_pct is not None else None
        }
    
    def predict_with_escalation(
        self,
        stone_color_type: str,
        processing_code: str,
        length_cm: float,
        width_cm: float,
        height_cm: float,
        application_codes: list,  # List of application codes (empty = all)
        customer_regional_group: str,
        charge_unit: str,
    ) -> Tuple[Dict[str, Any], pd.DataFrame, str]:
        """
        Try to find matches with automatic priority escalation.
        Starts with ∆Øu ti√™n 1 and escalates if no matches found.
        
        Returns:
            - Price estimation dict
            - Matching products DataFrame
            - Priority level used
        """
        priority_levels = [
            ('∆Øu ti√™n 1', '∆Øu ti√™n 1', '∆Øu ti√™n 1 - ƒê√∫ng k√≠ch th∆∞·ªõc', '∆Øu ti√™n 1'),
            ('∆Øu ti√™n 1', '∆Øu ti√™n 1', '∆Øu ti√™n 2 - Sai l·ªách nh·ªè', '∆Øu ti√™n 1'),
            ('∆Øu ti√™n 1', '∆Øu ti√™n 2', '∆Øu ti√™n 2 - Sai l·ªách nh·ªè', '∆Øu ti√™n 2'),
            ('∆Øu ti√™n 2', '∆Øu ti√™n 2', '∆Øu ti√™n 2 - Sai l·ªách nh·ªè', '∆Øu ti√™n 2'),
            ('∆Øu ti√™n 2', '∆Øu ti√™n 2', '∆Øu ti√™n 3 - Sai l·ªách l·ªõn', '∆Øu ti√™n 2'),
            ('∆Øu ti√™n 3', '∆Øu ti√™n 2', '∆Øu ti√™n 3 - Sai l·ªách l·ªõn', '∆Øu ti√™n 2'),
        ]
        
        for stone_p, proc_p, dim_p, region_p in priority_levels:
            matches = self.find_matching_products(
                stone_color_type=stone_color_type,
                processing_code=processing_code,
                length_cm=length_cm,
                width_cm=width_cm,
                height_cm=height_cm,
                application_codes=application_codes,
                customer_regional_group=customer_regional_group,
                charge_unit=charge_unit,
                stone_priority=stone_p,
                processing_priority=proc_p,
                dimension_priority=dim_p,
                region_priority=region_p,
            )
            
            if len(matches) > 0:
                estimation = self.estimate_price(matches)
                priority_used = f"ƒê√°: {stone_p}, Gia c√¥ng: {proc_p}, K√≠ch th∆∞·ªõc: {dim_p}, Khu v·ª±c: {region_p}"
                return estimation, matches, priority_used
        
        return self.estimate_price(pd.DataFrame()), pd.DataFrame(), "Kh√¥ng t√¨m th·∫•y"


# ============ Streamlit App ============
def main():
    # Header
    st.markdown('<h1 class="main-header">üíé Stone Price Predictor</h1>', unsafe_allow_html=True)
    st.markdown('<p style="text-align: center; color: #666;">D·ª± ƒëo√°n gi√° s·∫£n ph·∫©m ƒë√° t·ª± nhi√™n v·ªõi AI v√† d·ªØ li·ªáu Salesforce</p>', unsafe_allow_html=True)
    
    # Initialize session state
    if 'data' not in st.session_state:
        st.session_state.data = None
    if 'model' not in st.session_state:
        st.session_state.model = None
    if 'model_metrics' not in st.session_state:
        st.session_state.model_metrics = None
    
    # Sidebar
    with st.sidebar:
        st.markdown("## üíé Stone Price Predictor")
        st.title("‚öôÔ∏è C·∫•u h√¨nh")
        
        # Data source - Salesforce only
        st.markdown("**Ngu·ªìn d·ªØ li·ªáu:** Salesforce Contract Products")
        
        # Optional account code filter for Salesforce
        account_filter = st.text_input(
            "M√£ kh√°ch h√†ng (t√πy ch·ªçn)",
            placeholder="e.g., X09",
            help="L·ªçc theo Account_Code_C__c"
        )
        
        if st.button("üîÑ T·∫£i / L√†m m·ªõi d·ªØ li·ªáu t·ª´ Salesforce", use_container_width=True):
            with st.spinner("ƒêang t·∫£i v√† x·ª≠ l√Ω d·ªØ li·ªáu..."):
                if SALESFORCE_AVAILABLE:
                    try:
                        # Step 1: Load data from Salesforce
                        loader = SalesforceDataLoader()
                        df = loader.get_contract_products(account_code=account_filter if account_filter else None)
                        if len(df) > 0:
                            st.session_state.data = df
                            
                            # Step 2: Auto-preprocess data
                            predictor = SimilarityPricePredictor()
                            count = predictor.load_data(df)
                            st.session_state.model = predictor
                            st.session_state.model_metrics = {'loaded_samples': count}
                            
                            st.success(f"‚úÖ ƒê√£ t·∫£i {len(df):,} s·∫£n ph·∫©m, s·∫µn s√†ng v·ªõi {count:,} s·∫£n ph·∫©m c√≥ gi√°!")
                        else:
                            st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu t·ª´ Salesforce.")
                    except Exception as e:
                        st.error(f"‚ùå L·ªói k·∫øt n·ªëi Salesforce: {str(e)}")
                else:
                    st.error("‚ùå Salesforce ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh. Vui l√≤ng ki·ªÉm tra file .env")
        
        # Show status
        if st.session_state.data is not None:
            count = len(st.session_state.data)
            ready_count = st.session_state.model_metrics.get('loaded_samples', 0) if st.session_state.model_metrics else 0
            st.success(f"‚úÖ ƒê√£ s·∫µn s√†ng v·ªõi {count:,} s·∫£n ph·∫©m ({ready_count:,} s·∫£n ph·∫©m c√≥ gi√°)")
        
        st.divider()
    
    # Main content
    if st.session_state.data is None:
        st.info("üëà Vui l√≤ng t·∫£i d·ªØ li·ªáu t·ª´ sidebar ƒë·ªÉ b·∫Øt ƒë·∫ßu")
        
        # Show sample pricing matrix
        st.subheader("üìä Ma tr·∫≠n gi√° theo ph√¢n kh√∫c v√† lo·∫°i s·∫£n ph·∫©m")
        
        matrix_data = {
            'Lo·∫°i s·∫£n ph·∫©m': ['ƒê√° l√°t m·ªèng 1-1.5cm', 'ƒê√° n·ªôi ngo·∫°i th·∫•t 2-5cm', 'ƒê√° b·∫≠c thang', 'ƒê√° c√¢y', 'ƒê√° m·ªπ ngh·ªá'],
            'Economy (<$400/m¬≥)': ['ƒê√° m·∫ª, ƒë√° g√µ tay', 'ƒê√° c∆° b·∫£n', '-', 'ƒê√° c√¢y c∆∞a l·ªôt', 'C∆° b·∫£n'],
            'Common ($400-800/m¬≥)': ['ƒê√° 1 m·∫∑t ƒë·ªët', 'ƒê√° l√°t th√¥ng d·ª•ng', 'ƒê√° nguy√™n kh·ªëi', 'ƒê·ªët ch·∫£i', 'Trung b√¨nh'],
            'Premium ($800-1500/m¬≥)': ['ƒê√° x·ª≠ l√Ω ƒë·∫∑c bi·ªát', 'ƒê√° cao c·∫•p', 'ƒê√° ·ªëp b·∫≠c thang', 'X·ª≠ l√Ω nhi·ªÅu m·∫∑t', 'Cao c·∫•p'],
            'Super Premium (>$1500/m¬≥)': ['ƒê√° m·ªèng ƒë·∫∑c bi·ªát', 'ƒê√° n·∫Øp t∆∞·ªùng, h·ªì b∆°i', 'ƒê·∫∑c bi·ªát', 'ƒê·∫∑c bi·ªát', 'M·ªπ ngh·ªá ƒë·∫∑c bi·ªát']
        }
        st.dataframe(pd.DataFrame(matrix_data), use_container_width=True)
        return
    
    # Tabs
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "üîÆ D·ª± ƒëo√°n gi√°", 
        "üìä Ph√¢n t√≠ch d·ªØ li·ªáu", 
        "üîç T√¨m s·∫£n ph·∫©m t∆∞∆°ng t·ª±",
        "üìê B·∫£ng tra c·ª©u",
        "üìã D·ªØ li·ªáu chi ti·∫øt"
    ])
    
    # Tab 1: Price Prediction
    with tab1:
        st.subheader("üîÆ ∆Ø·ªõc t√≠nh gi√° s·∫£n ph·∫©m (Similarity-Based)")
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.markdown("#### Th√¥ng tin s·∫£n ph·∫©m")
            
            # Application multiselect - allows selecting multiple applications (e.g., 4.1 + 4.2 for "Step")
            # Empty selection = All (no filter)
            application_lookup = {code: name for code, name in APPLICATION_CODES}
            selected_applications = st.multiselect(
                "·ª®ng d·ª•ng s·∫£n ph·∫©m (Application)",
                options=[code for code, name in APPLICATION_CODES],
                format_func=lambda x: f"{x} - {application_lookup.get(x, 'Unknown')}",
                default=[],
                help="Ch·ªçn m·ªôt ho·∫∑c nhi·ªÅu ·ª©ng d·ª•ng. ƒê·ªÉ tr·ªëng = T·∫•t c·∫£"
            )
            stone_color = st.selectbox("M√†u ƒë√° (Stone Color)", STONE_COLOR_TYPES)
            
            # Main Processing dropdown with English and Vietnamese names
            # Create a dict for lookup: code -> (english, vietnamese)
            processing_lookup = {code: (eng, vn) for code, eng, vn in PROCESSING_CODES}
            processing_code = st.selectbox(
                "Gia c√¥ng ch√≠nh (Main Processing)",
                options=[code for code, eng, vn in PROCESSING_CODES],
                format_func=lambda x: f"{x} - {processing_lookup.get(x, ('Other', 'Kh√°c'))[0]} ({processing_lookup.get(x, ('Other', 'Kh√°c'))[1]})",
                index=0
            )
            
            col_dim1, col_dim2, col_dim3 = st.columns(3)
            with col_dim1:
                length = st.number_input("D√†i (cm)", min_value=1, max_value=300, value=30)
            with col_dim2:
                width = st.number_input("R·ªông (cm)", min_value=1, max_value=300, value=30)
            with col_dim3:
                height = st.number_input("D√†y (cm)", min_value=0.5, max_value=50.0, value=3.0, step=0.5)
            
            charge_unit = st.selectbox("ƒê∆°n v·ªã t√≠nh gi√°", CHARGE_UNITS)
            
            # Customer Regional Group (Nh√≥m Khu v·ª±c KH)
            customer_regional_group = st.selectbox(
                "Nh√≥m Khu v·ª±c KH (Regional Group)",
                options=[code for code, name in CUSTOMER_REGIONAL_GROUPS if code],
                format_func=lambda x: x,
                index=0,
                help="Nh√≥m ƒë·∫ßu 0-9 theo khu v·ª±c kh√°ch h√†ng"
            )
            
            st.divider()
            
            # Rules and Formulas expanders
            with st.expander("üìã Quy t·∫Øc ƒë·ªãnh gi√°"):
                st.markdown("""
**Ph√¢n kh√∫c gi√° (USD/m¬≥):**
| Ph√¢n kh√∫c | Gi√° | S·∫£n ph·∫©m |
|-----------|-----|----------|
| üü£ Super Premium | ‚â• $1,500 | ƒê√° m·ªèng 1-1.5cm, n·∫Øp t∆∞·ªùng, m·ªπ ngh·ªá |
| üî¥ Premium | ‚â• $800 | ƒê√° l√°t 2-5cm, slab, b·∫≠c thang |
| üü° Common | ‚â• $400 | ƒê√° c√¢y, cubic ƒë·ªët, quay m·∫ª |
| üü¢ Economy | < $400 | ƒê√° g√µ tay, cubic ch·∫ª tay |
                """)
            
            with st.expander("üë• Ph√¢n lo·∫°i kh√°ch h√†ng"):
                st.markdown("""
| Lo·∫°i | M√¥ t·∫£ | ƒêi·ªÅu ch·ªânh |
|------|-------|------------|
| **A** | Th√¢n thi·∫øt >10 nƒÉm | -1.5% ƒë·∫øn -3% |
| **B** | L·ªõn 3-10 nƒÉm | -2% ƒë·∫øn -4% |
| **C** | Ph·ªï th√¥ng | Gi√° chu·∫©n |
| **D** | M·ªõi, nh·ªè | +3% ƒë·∫øn +6% |
| **E** | S·∫£n ph·∫©m m·ªõi | √ó1.08-1.15 |
| **F** | D·ª± √°n | √ó1.08-1.15 |
                """)
            
            with st.expander("üìê C√¥ng th·ª©c t√≠nh to√°n"):
                st.markdown("""
**Th·ªÉ t√≠ch:** `m¬≥ = (D√óR√óC) / 1.000.000 √ó SL`

**Di·ªán t√≠ch:** `m¬≤ = (D√óR) / 10.000 √ó SL`

**Tr·ªçng l∆∞·ª£ng:** `T·∫•n = m¬≥ √ó TLR √ó HS`

**Quy ƒë·ªïi gi√°:**
- `Gi√°/m¬≤ = Gi√°/m¬≥ √ó Cao(m)`
- `Gi√°/T·∫•n = Gi√°/m¬≥ √∑ TLR √∑ HS`

**TLR tham kh·∫£o:**
- Absolute Basalt: 2.95
- Black Basalt: 2.65-2.70
- Granite th∆∞·ªùng: 2.70
- Dark Grey Granite: 2.90
                """)
            
            with st.expander("üéØ Ti√™u ch√≠ t√¨m ki·∫øm", expanded=True):
                st.markdown("""
| Ti√™u ch√≠ | ∆Øu ti√™n 1 | ∆Øu ti√™n 2 | ∆Øu ti√™n 3 |
|----------|-----------|-----------|-----------|
| **Lo·∫°i ƒë√°** | ƒê√∫ng m√†u ƒë√° | C√πng ch·ªßng lo·∫°i | T·∫•t c·∫£ lo·∫°i ƒë√° |
| **Gia c√¥ng** | ƒê√∫ng lo·∫°i gia c√¥ng | T·∫•t c·∫£ gia c√¥ng | - |
| **Cao (cm)** | ¬±0 | ¬±1 | ¬±5 |
| **R·ªông (cm)** | ¬±0 | ¬±5 | ¬±15 |
| **D√†i (cm)** | ¬±0 | ¬±10 | ¬±30 |
| **Khu v·ª±c** | ƒê√∫ng khu v·ª±c | T·∫•t c·∫£ khu v·ª±c | - |
                """)
            
            with st.expander("üì¶ Quy t·∫Øc ·ª©ng d·ª•ng s·∫£n ph·∫©m (Application Mapping)"):
                st.markdown("""
**M√£ ·ª©ng d·ª•ng** tr√≠ch xu·∫•t t·ª´ v·ªã tr√≠ 3-4 trong SKU (chuy·ªÉn ƒë·ªïi sang ƒë·ªãnh d·∫°ng X.Y).

| M√£ | English | Ti·∫øng Vi·ªát |
|----|---------|------------|
| 1.1 | Cubes / Cobbles | Cubic (ƒê√° vu√¥ng) |
| 1.3 | Paving stone / Paving slab / Crazy paving | ƒê√° l√°t ngo√†i tr·ªùi |
| 2.1 | Wall stone / Wall brick | ƒê√° x√¢y t∆∞·ªùng r√†o |
| 2.2 | Wall covering / Wall top | ƒê√° ·ªëp t∆∞·ªùng r√†o |
| 2.3 | Rockface Walling | ƒê√° m·∫∑t l·ªói ·ªëp t∆∞·ªùng |
| 3.1 | Palisades | ƒê√° c√¢y |
| 3.2 | Border / Kerbs | ƒê√° b√≥ v·ªâa h√® lo·∫°i th·∫≥ng |
| 3.3 | Corner | ƒê√° b√≥ v·ªâa h√®, lo·∫°i g√≥c ho·∫∑c cong |
| 4.1 | Stair / Step (Block) | ƒê√° b·∫≠c thang nguy√™n kh·ªëi |
| 4.2 | Step (Cladding) | ƒê√° ·ªëp b·∫≠c thang |
| 5.1 | Block | ƒê√° kh·ªëi |
| 6.1 | Pool surrounding | ƒê√° gh√©p h·ªì b∆°i |
| 6.2 | Window sill | ƒê√° b·ªá c·ª≠a s·ªï, g·ªù t∆∞·ªùng |
| 7.2 | Tile / Paver | ƒê√° l√°t, c·∫Øt quy c√°ch |
| 8.1 | Skirtings | ƒê√° len ch√¢n t∆∞·ªùng |
| 9.1 | Slab | ƒê√° slab k√≠ch th∆∞·ªõc kh·ªï l·ªõn |

**V√≠ d·ª• SKU:** `BD01DOT2-06004060`
- `BD` = V·∫≠t li·ªáu (Basalt ƒêen)
- `01` ‚Üí `0.1` = **·ª®ng d·ª•ng** (Cubes)
- `DOT` = Gia c√¥ng (ƒê·ªët/Flamed)
                """)
            
            customer_type = st.selectbox(
                "Ph√¢n lo·∫°i kh√°ch h√†ng",
                ['C', 'A', 'B', 'D', 'E', 'F'],
                format_func=lambda x: f"{x} - {CUSTOMER_PRICING_RULES[x]['description']}"
            )
            
            st.divider()
            st.markdown("#### üéöÔ∏è M·ª©c ƒë·ªô ∆∞u ti√™n t√¨m ki·∫øm")
            
            # Priority level selectors per notes.md
            col_p1, col_p2 = st.columns(2)
            with col_p1:
                stone_priority = st.selectbox(
                    "Lo·∫°i ƒë√°",
                    options=['∆Øu ti√™n 1', '∆Øu ti√™n 2', '∆Øu ti√™n 3'],
                    format_func=lambda x: {
                        '∆Øu ti√™n 1': '1 - ƒê√∫ng m√†u ƒë√°',
                        '∆Øu ti√™n 2': '2 - C√πng ch·ªßng lo·∫°i',
                        '∆Øu ti√™n 3': '3 - T·∫•t c·∫£ lo·∫°i ƒë√°',
                    }[x],
                    index=0  # Default: ∆Øu ti√™n 1 (ƒê√∫ng m√†u ƒë√°)
                )
                processing_priority = st.selectbox(
                    "Gia c√¥ng",
                    options=['∆Øu ti√™n 1', '∆Øu ti√™n 2'],
                    format_func=lambda x: {
                        '∆Øu ti√™n 1': '1 - ƒê√∫ng lo·∫°i gia c√¥ng',
                        '∆Øu ti√™n 2': '2 - T·∫•t c·∫£ gia c√¥ng',
                    }[x],
                    index=1  # Default: ∆Øu ti√™n 2 (T·∫•t c·∫£ gia c√¥ng)
                )
            with col_p2:
                dimension_priority = st.selectbox(
                    "K√≠ch th∆∞·ªõc",
                    options=list(DIMENSION_PRIORITY_LEVELS.keys()),
                    index=0  # Default: ∆Øu ti√™n 1 (ƒê√∫ng k√≠ch th∆∞·ªõc)
                )
                region_priority = st.selectbox(
                    "Khu v·ª±c KH",
                    options=['∆Øu ti√™n 1', '∆Øu ti√™n 2'],
                    format_func=lambda x: {
                        '∆Øu ti√™n 1': '1 - ƒê√∫ng khu v·ª±c',
                        '∆Øu ti√™n 2': '2 - T·∫•t c·∫£ khu v·ª±c',
                    }[x],
                    index=1  # Default: ∆Øu ti√™n 2 (T·∫•t c·∫£ khu v·ª±c)
                )
            
            st.divider()
            st.markdown("#### üìÖ C√†i ƒë·∫∑t t√≠nh to√°n gi√°")
            use_recent_only = st.checkbox(
                "Ch·ªâ s·ª≠ d·ª•ng d·ªØ li·ªáu g·∫ßn nh·∫•t",
                value=True,
                help="Ch·ªâ s·ª≠ d·ª•ng N s·∫£n ph·∫©m g·∫ßn nh·∫•t (theo nƒÉm t√†i ch√≠nh) ƒë·ªÉ ∆∞·ªõc t√≠nh gi√° ch√≠nh x√°c h∆°n"
            )
            recent_count = st.slider(
                "S·ªë l∆∞·ª£ng s·∫£n ph·∫©m tham kh·∫£o",
                min_value=5,
                max_value=35,
                value=15,
                step=5,
                help="S·ªë l∆∞·ª£ng s·∫£n ph·∫©m g·∫ßn nh·∫•t s·ª≠ d·ª•ng ƒë·ªÉ ∆∞·ªõc t√≠nh gi√°",
                disabled=not use_recent_only
            )
            
            predict_btn = st.button("üîç T√¨m ki·∫øm & ∆Ø·ªõc t√≠nh gi√°", type="primary", use_container_width=True)
        
        with col2:
            if predict_btn and st.session_state.model is not None:
                # Use similarity-based predictor
                predictor = st.session_state.model
                
                matches = predictor.find_matching_products(
                    stone_color_type=stone_color,
                    processing_code=processing_code,
                    length_cm=length,
                    width_cm=width,
                    height_cm=height,
                    application_codes=selected_applications,
                    customer_regional_group=customer_regional_group,
                    charge_unit=charge_unit,
                    stone_priority=stone_priority,
                    processing_priority=processing_priority,
                    dimension_priority=dimension_priority,
                    region_priority=region_priority,
                )
                
                estimation = predictor.estimate_price(
                    matches, 
                    use_recent_only=use_recent_only, 
                    recent_count=recent_count,
                    query_length_cm=length,
                    query_width_cm=width,
                    query_height_cm=height,
                    target_charge_unit=charge_unit,
                    stone_color_type=stone_color,
                    processing_code=processing_code
                )
                
                st.markdown("#### üìä K·∫øt qu·∫£ ∆∞·ªõc t√≠nh")
                
                if estimation['estimated_price'] is not None:
                    # Confidence indicator
                    confidence_colors = {
                        'high': '#6bcb77',
                        'medium': '#ffd93d',
                        'low': '#ff6b6b',
                        'very_low': '#9e7cc1',
                    }
                    confidence_labels = {
                        'high': 'Cao (‚â•10 m·∫´u)',
                        'medium': 'Trung b√¨nh (5-9 m·∫´u)',
                        'low': 'Th·∫•p (2-4 m·∫´u)',
                        'very_low': 'R·∫•t th·∫•p (1 m·∫´u)',
                    }
                    conf_color = confidence_colors.get(estimation['confidence'], '#808080')
                    conf_label = confidence_labels.get(estimation['confidence'], 'N/A')
                    
                    st.markdown(f"""
                    <div style="background-color: {conf_color}; padding: 15px; border-radius: 10px; text-align: center; margin-bottom: 20px;">
                        <h3 style="color: white; margin: 0;">ƒê·ªô tin c·∫≠y: {conf_label}</h3>
                    </div>
                    """, unsafe_allow_html=True)
                    
                    # Main estimated price
                    st.metric(f"üí∞ Gi√° ∆∞·ªõc t√≠nh ({charge_unit})", f"${estimation['estimated_price']:,.2f}")
                    
                    # Price range
                    st.markdown(f"Kho·∫£ng gi√° th·ª±c t·∫ø: **\\${estimation['min_price']:,.2f}** ‚Äì **\\${estimation['max_price']:,.2f}**")
                    st.markdown(f"**Gi√° trung v·ªã:** ${estimation['median_price']:,.2f}")
                    
                    # Show match count info with years if using recent only
                    if use_recent_only and estimation.get('total_matches', 0) > estimation['match_count']:
                        st.markdown(f"**S·ªë m·∫´u kh·ªõp:** {estimation['match_count']} / {estimation['total_matches']} (s·ª≠ d·ª•ng {estimation['match_count']} m·∫´u g·∫ßn nh·∫•t)")
                        if estimation.get('years_used'):
                            st.markdown(f"**NƒÉm tham kh·∫£o:** {estimation['years_used']}")
                    else:
                        st.markdown(f"**S·ªë m·∫´u kh·ªõp:** {estimation['match_count']}")
                    
                    # Show price trend if available
                    if estimation.get('price_trend') and estimation.get('trend_pct') is not None:
                        trend_pct = estimation['trend_pct']
                        if estimation['price_trend'] == 'up':
                            st.markdown(f"üìà **Xu h∆∞·ªõng gi√°:** TƒÉng **+{abs(trend_pct):.1f}%** so v·ªõi nƒÉm tr∆∞·ªõc")
                        elif estimation['price_trend'] == 'down':
                            st.markdown(f"üìâ **Xu h∆∞·ªõng gi√°:** Gi·∫£m **-{abs(trend_pct):.1f}%** so v·ªõi nƒÉm tr∆∞·ªõc")
                        else:
                            st.markdown(f"‚û°Ô∏è **Xu h∆∞·ªõng gi√°:** ·ªîn ƒë·ªãnh")
                    
                    st.divider()
                    
                    # Calculate segment for pricing (use first selected application or empty for classify_segment)
                    first_app = selected_applications[0] if selected_applications else ''
                    est_price_m3 = convert_price(
                        estimation['estimated_price'], charge_unit, 'USD/M3',
                        height_cm=height, length_cm=length, width_cm=width,
                        tlr=get_tlr(stone_color, processing_code)
                    )
                    segment = classify_segment(est_price_m3, height_cm=height, family=first_app, processing_code=processing_code)
                    
                    # Customer price adjustment with segment awareness
                    price_info = calculate_customer_price(
                        estimation['estimated_price'], customer_type, 
                        segment=segment, charge_unit=charge_unit
                    )
                    st.markdown(f"**üë§ Gi√° theo kh√°ch h√†ng lo·∫°i {customer_type}:**")
                    st.markdown(f"- {price_info['customer_description']}")
                    st.markdown(f"- Kho·∫£ng gi√°: **\\${price_info['min_price']:,.2f}** ‚Äì **\\${price_info['max_price']:,.2f}**")
                    st.markdown(f"- ƒêi·ªÅu ch·ªânh: {price_info['adjustment_label']}")
                    st.markdown(f"- Quy·ªÅn t·ª± quy·∫øt: {price_info['authority_range']}")
                    
                else:
                    # Get detailed diagnostics for why no matches found
                    diagnostics = predictor.get_match_diagnostics(
                        stone_color_type=stone_color,
                        processing_code=processing_code,
                        length_cm=length,
                        width_cm=width,
                        height_cm=height,
                        application_codes=selected_applications,
                        customer_regional_group=customer_regional_group,
                        charge_unit=charge_unit,
                        stone_priority=stone_priority,
                        processing_priority=processing_priority,
                        dimension_priority=dimension_priority,
                        region_priority=region_priority,
                    )
                    
                    st.warning(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m ph√π h·ª£p")
                    
                    if diagnostics.get('reason'):
                        st.error(f"**L√Ω do:** {diagnostics['reason']}")
                    
                    if diagnostics.get('suggestions'):
                        st.info("**üí° G·ª£i √Ω:**\n" + "\n".join([f"‚Ä¢ {s}" for s in diagnostics['suggestions']]))
                
                st.divider()
                
                # Product info summary with weight calculation
                st.markdown("**üì¶ Th√¥ng tin s·∫£n ph·∫©m:**")
                volume_m3 = calculate_volume_m3(length, width, height)
                area_m2 = calculate_area_m2(length, width)
                tlr = get_tlr(stone_color, processing_code)
                first_app = selected_applications[0] if selected_applications else ''
                hs = get_hs_factor((length, width, height), processing_code, first_app)
                weight_tons = calculate_weight_tons(volume_m3, stone_color, processing_code, (length, width, height), first_app)
                
                col_info1, col_info2 = st.columns(2)
                with col_info1:
                    st.markdown(f"- K√≠ch th∆∞·ªõc: {length} x {width} x {height} cm")
                    st.markdown(f"- Th·ªÉ t√≠ch: {volume_m3:.6f} m¬≥")
                    st.markdown(f"- Di·ªán t√≠ch: {area_m2:.4f} m¬≤")
                with col_info2:
                    st.markdown(f"- TLR: {tlr} t·∫•n/m¬≥")
                    st.markdown(f"- HS: {hs}")
                    st.markdown(f"- Kh·ªëi l∆∞·ª£ng: **{weight_tons:.4f} t·∫•n**")
                
        # ============ MATCHING PRODUCTS (Full Width) ============
        if predict_btn and st.session_state.model is not None:
            st.divider()
            st.markdown("#### üìã S·∫£n ph·∫©m trong h·ªá th·ªëng kh·ªõp ti√™u ch√≠")
            
            if len(matches) > 0:
                st.success(f"‚úÖ T√¨m th·∫•y **{len(matches)}** s·∫£n ph·∫©m kh·ªõp ti√™u ch√≠!")
                
                # Statistics
                match_prices = matches['sales_price']
                stat_col1, stat_col2, stat_col3, stat_col4 = st.columns(4)
                with stat_col1:
                    st.metric("Th·∫•p nh·∫•t", f"${match_prices.min():,.2f}")
                with stat_col2:
                    st.metric("Cao nh·∫•t", f"${match_prices.max():,.2f}")
                with stat_col3:
                    st.metric("Trung b√¨nh", f"${match_prices.mean():,.2f}")
                with stat_col4:
                    st.metric("Trung v·ªã", f"${match_prices.median():,.2f}")
                
                # Show table of ALL matches with Regional Group included
                display_cols = [
                    'contract_product_name', 'contract_name', 'account_code',
                    'customer_regional_group',  # Regional Group now visible
                    'sku', 'application_code', 'application',
                    'processing_code', 'processing_name',
                    'stone_color_type', 'segment',
                    'length_cm', 'width_cm', 'height_cm',
                    'charge_unit', 'sales_price', 'price_m3',
                    'created_date', 'fy_year',
                ]
                available_cols = [col for col in display_cols if col in matches.columns]
                
                # Column config for headers
                col_config = {
                    'sku': st.column_config.TextColumn('SKU'),
                    'application_code': st.column_config.TextColumn('App Code'),
                    'application': st.column_config.TextColumn('Application'),
                    'processing_code': st.column_config.TextColumn('Main Processing Code'),
                    'processing_name': st.column_config.TextColumn('Main Processing'),
                    'customer_regional_group': st.column_config.TextColumn('Regional Group'),
                }
                
                with st.expander(f"üìã Xem danh s√°ch {len(matches)} s·∫£n ph·∫©m kh·ªõp", expanded=True):
                    st.dataframe(matches[available_cols], use_container_width=True, height=300, column_config=col_config)
            else:
                st.info("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m ph√π h·ª£p. Th·ª≠ m·ªü r·ªông ti√™u ch√≠ (∆Øu ti√™n 2 ho·∫∑c 3).")
        
        elif predict_btn and st.session_state.model is None:
            st.warning("‚ö†Ô∏è Vui l√≤ng chu·∫©n b·ªã t√¨m ki·∫øm tr∆∞·ªõc (n√∫t üîç ·ªü sidebar)")
        elif not predict_btn:
            pass  # User hasn't clicked yet
    
    # Tab 2: Data Analysis
    with tab2:
        st.subheader("üìä Ph√¢n t√≠ch d·ªØ li·ªáu gi√°")
        
        df = st.session_state.data.copy()
        
        # Clean data: remove products with price 0, missing, or negative
        df_clean = df[df['sales_price'].notna() & (df['sales_price'] > 0)]
        
        # Show data quality info
        total_products = len(df)
        valid_products = len(df_clean)
        excluded_products = total_products - valid_products
        
        if excluded_products > 0:
            st.info(f"üìä ƒê√£ lo·∫°i b·ªè {excluded_products:,} s·∫£n ph·∫©m c√≥ gi√° = 0, √¢m ho·∫∑c thi·∫øu. Ph√¢n t√≠ch v·ªõi {valid_products:,} / {total_products:,} s·∫£n ph·∫©m.")
        
        # Summary metrics using sales_price (clean data)
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("üì¶ S·∫£n ph·∫©m h·ª£p l·ªá", f"{valid_products:,}")
        with col2:
            st.metric("üí∞ Gi√° TB (Sales Price)", f"${df_clean['sales_price'].mean():,.2f}")
        with col3:
            st.metric("üìà Gi√° cao nh·∫•t", f"${df_clean['sales_price'].max():,.2f}")
        with col4:
            st.metric("üìâ Gi√° th·∫•p nh·∫•t", f"${df_clean['sales_price'].min():,.2f}")
        
        st.divider()
        
        # Charts
        chart_col1, chart_col2 = st.columns(2)
        
        with chart_col1:
            # Price distribution by segment (using clean data)
            segment_counts = df_clean['segment'].value_counts()
            fig_segment = px.pie(
                values=segment_counts.values,
                names=segment_counts.index,
                title="Ph√¢n b·ªë theo ph√¢n kh√∫c",
                color=segment_counts.index,
                color_discrete_map={
                    'Super premium': '#9e7cc1',
                    'Premium': '#ff6b6b',
                    'Common': '#ffd93d',
                    'Economy': '#6bcb77'
                }
            )
            st.plotly_chart(fig_segment, use_container_width=True)
        
        with chart_col2:
            # Average sales_price by family (using clean data)
            avg_by_family = df_clean.groupby('family')['sales_price'].mean().sort_values(ascending=True)
            fig_family = px.bar(
                x=avg_by_family.values,
                y=avg_by_family.index,
                orientation='h',
                title="Gi√° b√°n trung b√¨nh theo lo·∫°i s·∫£n ph·∫©m",
                labels={'x': 'Sales Price (USD)', 'y': 'Lo·∫°i s·∫£n ph·∫©m'}
            )
            fig_family.update_traces(marker_color='#667eea')
            st.plotly_chart(fig_family, use_container_width=True)
        
        # Price by stone type (using clean data)
        st.markdown("#### üíé Gi√° b√°n theo lo·∫°i ƒë√°")
        fig_stone = px.box(
            df_clean,
            x='stone_color_type',
            y='sales_price',
            color='stone_color_type',
            title="Ph√¢n b·ªë gi√° b√°n theo m√†u ƒë√°",
            labels={'sales_price': 'Sales Price (USD)', 'stone_color_type': 'Stone Color Type'}
        )
        st.plotly_chart(fig_stone, use_container_width=True)
        
        # Price vs dimensions (using clean data)
        st.markdown("#### üìê Gi√° b√°n theo k√≠ch th∆∞·ªõc")
        fig_scatter = px.scatter(
            df_clean,
            x='volume_m3',
            y='sales_price',
            color='segment',
            size='height_cm',
            hover_data=['contract_product_name', 'family'],
            title="Sales Price vs Th·ªÉ t√≠ch",
            labels={'sales_price': 'Sales Price (USD)', 'volume_m3': 'Volume (m¬≥)'},
            color_discrete_map={
                'Super premium': '#9e7cc1',
                'Premium': '#ff6b6b',
                'Common': '#ffd93d',
                'Economy': '#6bcb77'
            }
        )
        st.plotly_chart(fig_scatter, use_container_width=True)
        
        st.divider()
        
        # New charts section
        st.markdown("### üìä Ph√¢n t√≠ch n√¢ng cao")
        
        chart_col3, chart_col4 = st.columns(2)
        
        with chart_col3:
            # Price by Application (new column)
            if 'application' in df_clean.columns:
                app_prices = df_clean.groupby('application').agg({
                    'sales_price': ['mean', 'count']
                }).round(2)
                app_prices.columns = ['Gi√° TB', 'S·ªë l∆∞·ª£ng']
                app_prices = app_prices.sort_values('Gi√° TB', ascending=True)
                
                fig_app = px.bar(
                    x=app_prices['Gi√° TB'].values,
                    y=app_prices.index,
                    orientation='h',
                    title="üí∞ Gi√° trung b√¨nh theo ·ª®ng d·ª•ng (Application)",
                    labels={'x': 'Gi√° TB (USD)', 'y': 'Application'},
                    text=app_prices['S·ªë l∆∞·ª£ng'].values
                )
                fig_app.update_traces(marker_color='#48bb78', texttemplate='n=%{text}', textposition='inside')
                st.plotly_chart(fig_app, use_container_width=True)
        
        with chart_col4:
            # Price by Processing type
            if 'processing_name' in df_clean.columns:
                proc_prices = df_clean.groupby('processing_name').agg({
                    'sales_price': ['mean', 'count']
                }).round(2)
                proc_prices.columns = ['Gi√° TB', 'S·ªë l∆∞·ª£ng']
                proc_prices = proc_prices.sort_values('Gi√° TB', ascending=True)
                
                fig_proc = px.bar(
                    x=proc_prices['Gi√° TB'].values,
                    y=proc_prices.index,
                    orientation='h',
                    title="üîß Gi√° trung b√¨nh theo Gia c√¥ng (Processing)",
                    labels={'x': 'Gi√° TB (USD)', 'y': 'Processing'},
                    text=proc_prices['S·ªë l∆∞·ª£ng'].values
                )
                fig_proc.update_traces(marker_color='#ed8936', texttemplate='n=%{text}', textposition='inside')
                st.plotly_chart(fig_proc, use_container_width=True)
        
        chart_col5, chart_col6 = st.columns(2)
        
        with chart_col5:
            # Price trend by year
            if 'fy_year' in df_clean.columns:
                yearly_data = df_clean.groupby('fy_year').agg({
                    'sales_price': ['mean', 'median', 'count'],
                    'price_m3': 'mean'
                }).round(2)
                yearly_data.columns = ['Gi√° TB', 'Gi√° Trung v·ªã', 'S·ªë ƒë∆°n h√†ng', 'Gi√°/m¬≥ TB']
                yearly_data = yearly_data.reset_index()
                yearly_data = yearly_data[yearly_data['fy_year'].notna()]
                
                fig_trend = px.line(
                    yearly_data,
                    x='fy_year',
                    y=['Gi√° TB', 'Gi√° Trung v·ªã'],
                    title="üìà Xu h∆∞·ªõng gi√° theo nƒÉm",
                    labels={'value': 'Gi√° (USD)', 'fy_year': 'NƒÉm', 'variable': 'Lo·∫°i gi√°'},
                    markers=True
                )
                fig_trend.update_layout(legend=dict(orientation="h", yanchor="bottom", y=1.02))
                st.plotly_chart(fig_trend, use_container_width=True)
        
        with chart_col6:
            # Regional Group analysis
            if 'customer_regional_group' in df_clean.columns:
                region_data = df_clean[df_clean['customer_regional_group'].notna()]
                if len(region_data) > 0:
                    region_prices = region_data.groupby('customer_regional_group').agg({
                        'sales_price': ['mean', 'count'],
                        'price_m3': 'mean'
                    }).round(2)
                    region_prices.columns = ['Gi√° TB', 'S·ªë ƒë∆°n h√†ng', 'Gi√°/m¬≥ TB']
                    region_prices = region_prices.sort_values('Gi√° TB', ascending=True).reset_index()
                    
                    fig_region = px.bar(
                        region_prices,
                        x='customer_regional_group',
                        y='Gi√° TB',
                        color='Gi√°/m¬≥ TB',
                        title="üåç Gi√° trung b√¨nh theo Khu v·ª±c kh√°ch h√†ng",
                        labels={'customer_regional_group': 'Nh√≥m Khu v·ª±c', 'Gi√° TB': 'Gi√° TB (USD)'},
                        text='S·ªë ƒë∆°n h√†ng',
                        color_continuous_scale='Blues'
                    )
                    fig_region.update_traces(texttemplate='n=%{text}', textposition='outside')
                    st.plotly_chart(fig_region, use_container_width=True)
        
        # Correlation heatmap for numeric columns
        st.markdown("#### üîó T∆∞∆°ng quan gi·ªØa c√°c y·∫øu t·ªë")
        numeric_cols = ['length_cm', 'width_cm', 'height_cm', 'volume_m3', 'area_m2', 'sales_price', 'price_m3']
        available_numeric = [col for col in numeric_cols if col in df_clean.columns]
        if len(available_numeric) >= 3:
            corr_matrix = df_clean[available_numeric].corr().round(2)
            fig_corr = px.imshow(
                corr_matrix,
                text_auto=True,
                title="Ma tr·∫≠n t∆∞∆°ng quan (Correlation Matrix)",
                color_continuous_scale='RdBu_r',
                aspect='auto'
            )
            st.plotly_chart(fig_corr, use_container_width=True)
    
    # Tab 3: Similar Products
    with tab3:
        st.subheader("üîç T√¨m s·∫£n ph·∫©m t∆∞∆°ng t·ª±")
        
        col1, col2 = st.columns([1, 2])
        
        with col1:
            st.markdown("#### Ti√™u ch√≠ t√¨m ki·∫øm")
            search_family = st.selectbox("Lo·∫°i s·∫£n ph·∫©m", [''] + PRODUCT_FAMILIES, key='search_family')
            search_stone = st.selectbox("M√†u ƒë√°", [''] + STONE_COLOR_TYPES, key='search_stone')
            
            # Processing code dropdown with Vietnamese
            search_processing_lookup = {code: (eng, vn) for code, eng, vn in PROCESSING_CODES_SEARCH}
            search_processing = st.selectbox(
                "Gia c√¥ng ch√≠nh (Main Processing)",
                options=[code for code, eng, vn in PROCESSING_CODES_SEARCH],
                format_func=lambda x: f"{x} - {search_processing_lookup.get(x, ('All', 'T·∫•t c·∫£'))[0]} ({search_processing_lookup.get(x, ('All', 'T·∫•t c·∫£'))[1]})" if x else "All (T·∫•t c·∫£)",
                key='search_processing'
            )
            
            # Customer Regional Group filter
            search_regional_group = st.selectbox(
                "Nh√≥m Khu v·ª±c KH (Regional Group)",
                options=[code for code, name in CUSTOMER_REGIONAL_GROUPS],
                format_func=lambda x: x if x else "All",
                key='search_regional_group',
                help="L·ªçc theo nh√≥m khu v·ª±c kh√°ch h√†ng"
            )
            
            search_col1, search_col2, search_col3 = st.columns(3)
            with search_col1:
                search_length = st.number_input("D√†i (cm)", min_value=0, value=30, key='search_l')
            with search_col2:
                search_width = st.number_input("R·ªông (cm)", min_value=0, value=30, key='search_w')
            with search_col3:
                search_height = st.number_input("D√†y (cm)", min_value=0.0, value=3.0, key='search_h')
            
            st.divider()
            
            # Show related checkbox and slider
            show_related = st.checkbox("üìã Hi·ªÉn th·ªã s·∫£n ph·∫©m li√™n quan", value=False, 
                                       help="Hi·ªÉn th·ªã c√°c s·∫£n ph·∫©m c√≥ ƒë·∫∑c ƒëi·ªÉm t∆∞∆°ng t·ª± n·∫øu kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£ ch√≠nh x√°c")
            
            if show_related:
                related_count = st.slider("S·ªë s·∫£n ph·∫©m li√™n quan", 5, 50, 20)
            
            search_btn = st.button("üîç T√¨m ki·∫øm", type="primary", use_container_width=True)
        
        with col2:
            if search_btn:
                df = st.session_state.data.copy()
                
                # Clean data for searching
                df_clean = df[df['sales_price'].notna() & (df['sales_price'] > 0)].copy()
                df_clean = df_clean.reset_index(drop=True)  # Reset index to avoid alignment issues
                
                # Step 1: Find EXACT matches
                exact_mask = pd.Series([True] * len(df_clean), index=df_clean.index)
                
                if search_family:
                    exact_mask &= df_clean['family'] == search_family
                if search_stone:
                    exact_mask &= df_clean['stone_color_type'] == search_stone
                if search_processing and 'processing_code' in df_clean.columns:
                    exact_mask &= df_clean['processing_code'] == search_processing
                if search_regional_group and 'customer_regional_group' in df_clean.columns:
                    exact_mask &= df_clean['customer_regional_group'] == search_regional_group
                if search_length > 0:
                    exact_mask &= df_clean['length_cm'] == search_length
                if search_width > 0:
                    exact_mask &= df_clean['width_cm'] == search_width
                if search_height > 0:
                    exact_mask &= df_clean['height_cm'] == search_height
                
                exact_matches = df_clean[exact_mask]
                
                # Include application and processing columns in display
                display_cols = ['contract_product_name', 'stone_color_type', 
                                'sku', 'application_code', 'application',
                                'processing_code', 'processing_name',
                                'customer_regional_group',
                                'length_cm', 'width_cm', 'height_cm', 'charge_unit', 'sales_price', 'price_m3', 'segment']
                available_cols = [col for col in display_cols if col in df_clean.columns]
                
                # Column config for English headers
                col_config = {
                    'sku': st.column_config.TextColumn('SKU'),
                    'application_code': st.column_config.TextColumn('App Code'),
                    'application': st.column_config.TextColumn('Application'),
                    'processing_code': st.column_config.TextColumn('Main Processing Code'),
                    'processing_name': st.column_config.TextColumn('Main Processing'),
                    'customer_regional_group': st.column_config.TextColumn('Regional Group'),
                }
                
                # Display exact matches
                if len(exact_matches) > 0:
                    st.markdown(f"#### ‚úÖ T√¨m th·∫•y {len(exact_matches)} s·∫£n ph·∫©m kh·ªõp ch√≠nh x√°c")
                    st.dataframe(exact_matches[available_cols], use_container_width=True, height=300, column_config=col_config)
                    
                    # Statistics for exact matches
                    valid_prices = exact_matches['sales_price']
                    if len(valid_prices) > 0:
                        st.markdown("##### üìä Th·ªëng k√™ gi√° (kh·ªõp ch√≠nh x√°c)")
                        stat_col1, stat_col2, stat_col3, stat_col4 = st.columns(4)
                        with stat_col1:
                            st.metric("Th·∫•p nh·∫•t", f"${valid_prices.min():,.2f}")
                        with stat_col2:
                            st.metric("Cao nh·∫•t", f"${valid_prices.max():,.2f}")
                        with stat_col3:
                            st.metric("Trung b√¨nh", f"${valid_prices.mean():,.2f}")
                        with stat_col4:
                            st.metric("Trung v·ªã", f"${valid_prices.median():,.2f}")
                else:
                    st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m kh·ªõp ch√≠nh x√°c v·ªõi ti√™u ch√≠.")
                
                # Step 2: Show related products if checkbox is checked
                if show_related:
                    st.divider()
                    st.markdown(f"#### üîó S·∫£n ph·∫©m li√™n quan (top {related_count})")
                    
                    # Find related products based on partial criteria
                    related_mask = pd.Series([False] * len(df_clean), index=df_clean.index)
                    
                    if search_family:
                        related_mask |= df_clean['family'] == search_family
                    if search_stone:
                        related_mask |= df_clean['stone_color_type'] == search_stone
                    if search_processing and 'processing_code' in df_clean.columns:
                        related_mask |= df_clean['processing_code'] == search_processing
                    if search_regional_group and 'customer_regional_group' in df_clean.columns:
                        related_mask |= df_clean['customer_regional_group'] == search_regional_group
                    
                    # Exclude exact matches
                    related_mask &= ~exact_mask
                    
                    related_products = df_clean[related_mask].copy()
                    
                    # Sort by dimension similarity if dimensions provided
                    if search_length > 0 and search_width > 0 and search_height > 0:
                        related_products['dim_diff'] = (
                            abs(related_products['length_cm'] - search_length) +
                            abs(related_products['width_cm'] - search_width) +
                            abs(related_products['height_cm'] - search_height)
                        )
                        related_products = related_products.nsmallest(related_count, 'dim_diff')
                    else:
                        related_products = related_products.head(related_count)
                    
                    if len(related_products) > 0:
                        st.dataframe(related_products[available_cols], use_container_width=True, height=300, column_config=col_config)
                        
                        # Statistics for related products
                        valid_prices = related_products['sales_price']
                        if len(valid_prices) > 0:
                            st.markdown("##### üìä Th·ªëng k√™ gi√° (s·∫£n ph·∫©m li√™n quan)")
                            stat_col1, stat_col2, stat_col3, stat_col4 = st.columns(4)
                            with stat_col1:
                                st.metric("Th·∫•p nh·∫•t", f"${valid_prices.min():,.2f}")
                            with stat_col2:
                                st.metric("Cao nh·∫•t", f"${valid_prices.max():,.2f}")
                            with stat_col3:
                                st.metric("Trung b√¨nh", f"${valid_prices.mean():,.2f}")
                            with stat_col4:
                                st.metric("Trung v·ªã", f"${valid_prices.median():,.2f}")
                            
                            # Summary
                            price_range = valid_prices.max() - valid_prices.min()
                            st.caption(f"Kho·∫£ng gi√°: ${price_range:,.2f} | ƒê·ªô l·ªách chu·∫©n: ${valid_prices.std():,.2f}")
                    else:
                        st.info("Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m li√™n quan.")
    
    # Tab 4: Weight & Conversion Reference
    with tab4:
        st.subheader("üìê B·∫£ng tra c·ª©u TLR & H·ªá s·ªë")
        
        if st.session_state.model_metrics is not None:
            metrics = st.session_state.model_metrics
            loaded = metrics.get('loaded_samples', 0)
            st.success(f"‚úÖ ƒê√£ t·∫£i **{loaded:,}** s·∫£n ph·∫©m c√≥ gi√°")
        
        st.divider()
        
        # TLR Reference Table
        st.markdown("#### ‚öñÔ∏è Tr·ªçng L∆∞·ª£ng Ri√™ng (TLR)")
        tlr_data = {
            'S·∫£n ph·∫©m': [
                'ƒê√° ƒëen ƒêak N√¥ng (Absolute Basalt)',
                'ƒê√° Ph∆∞·ªõc H√≤a/Qui Nh∆°n (c∆∞a c·∫Øt m√°y)',
                'ƒê√° Ph∆∞·ªõc H√≤a/Qui Nh∆°n (ch·∫ª tay)',
                'Dark Grey Granite',
                'Granite th∆∞·ªùng',
                'Bluestone (Thanh H√≥a)',
                'ƒê√° t·ªï ong'
            ],
            'TLR (t·∫•n/m¬≥)': ['2.95', '2.70', '2.65', '2.90', '2.70', '2.70', '2.20'],
            'Ghi ch√∫': [
                'H√†ng Dak N√¥ng m·ªói cont 9.3-9.6 m¬≥',
                '',
                '',
                '',
                '',
                '',
                ''
            ]
        }
        st.dataframe(pd.DataFrame(tlr_data), use_container_width=True, hide_index=True)
        
        st.divider()
        
        # HS Factors Table
        st.markdown("#### üìä H·ªá S·ªë ·ªêp ƒê√°y (HS)")
        hs_data = {
            'S·∫£n ph·∫©m': [
                'ƒê√° l√°t 6cm m·∫∑t ƒë·ªët, c·∫°nh s·ªô',
                'ƒê√° cubic ch·∫ª tay 5√ó5√ó5cm',
                'ƒê√° cubic ch·∫ª tay 8√ó8√ó8cm',
                'ƒê√° cubic ch·∫ª tay 10√ó10√ó8cm, 20√ó10√ó8cm',
                'ƒê√° cubic ch·∫ª tay 15√ó15√ó12cm',
                'ƒê√° cubic m·∫∑t ƒë·ªët, c·∫°nh ch·∫ª tay',
                'ƒê√° c√¢y c∆∞a l·ªôt'
            ],
            'HS': ['0.97', '1.00', '0.95', '0.875', '0.85', '0.95', '1.05'],
            'Ghi ch√∫': [
                '·ªêp ƒë√°y gi·∫£m 3%',
                '',
                '',
                '',
                '',
                '',
                'D√†y th·ª±c t·∫ø 10.5cm, +5%'
            ]
        }
        st.dataframe(pd.DataFrame(hs_data), use_container_width=True, hide_index=True)
        
        st.divider()
        
        # Formulas
        st.markdown("#### üìù C√¥ng th·ª©c t√≠nh to√°n")
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("""
**T√≠nh m¬≥ (Th·ªÉ t√≠ch):**
```
m¬≥ = (D√†i √ó R·ªông √ó Cao) / 1.000.000 √ó S·ªë vi√™n
```

**T√≠nh m¬≤ (Di·ªán t√≠ch):**
```
m¬≤ = (D√†i √ó R·ªông) / 10.000 √ó S·ªë vi√™n
```

**T√≠nh T·∫•n (Tr·ªçng l∆∞·ª£ng):**
```
T·∫•n = m¬≥ √ó TLR √ó HS
```
            """)
        with col2:
            st.markdown("""
**Quy ƒë·ªïi gi√° t·ª´ Vi√™n:**
- `Gi√°/m¬≤ = Gi√° Vi√™n √∑ D(m) √∑ R(m)`
- `Gi√°/m¬≥ = Gi√° Vi√™n √∑ D(m) √∑ R(m) √∑ C(m)`
- `Gi√°/T·∫•n = Gi√° Vi√™n √∑ D √∑ R √∑ C √∑ TLR √∑ HS`

**Quy ƒë·ªïi gi·ªØa ƒë∆°n v·ªã:**
- `Gi√°/m¬≤ = Gi√°/m¬≥ √ó Cao(m)`
- `Gi√°/m¬≥ = Gi√°/T·∫•n √ó TLR √ó HS`
            """)
        
        st.divider()
        
        # Container weight reference
        st.markdown("#### üö¢ Quy chu·∫©n tr·ªçng l∆∞·ª£ng Container")
        container_data = {
            'Th·ªã tr∆∞·ªùng': ['M·ªπ', 'Ch√¢u √Çu', '√öc', 'Nh·∫≠t'],
            'Tr·ªçng l∆∞·ª£ng (t·∫•n)': ['20-21', '27-28', '24-26', '27.5-28']
        }
        st.dataframe(pd.DataFrame(container_data), use_container_width=True, hide_index=True)
    
    # Tab 5: Detailed Data
    with tab5:
        st.subheader("üìã D·ªØ li·ªáu chi ti·∫øt")
        
        # Filters
        filter_col1, filter_col2, filter_col3, filter_col4 = st.columns(4)
        with filter_col1:
            filter_family = st.multiselect("Lo·∫°i s·∫£n ph·∫©m", PRODUCT_FAMILIES)
        with filter_col2:
            filter_segment = st.multiselect("Ph√¢n kh√∫c", ['Economy', 'Common', 'Premium', 'Super premium'])
        with filter_col3:
            filter_regional_group = st.multiselect(
                "Nh√≥m Khu v·ª±c KH", 
                [code for code, name in CUSTOMER_REGIONAL_GROUPS if code]
            )
        with filter_col4:
            price_range = st.slider("Kho·∫£ng gi√° (USD/m¬≥)", 0, 2000, (0, 2000))
        
        # Apply filters
        filtered_df = st.session_state.data.copy()
        if filter_family:
            filtered_df = filtered_df[filtered_df['family'].isin(filter_family)]
        if filter_segment:
            filtered_df = filtered_df[filtered_df['segment'].isin(filter_segment)]
        if filter_regional_group and 'customer_regional_group' in filtered_df.columns:
            filtered_df = filtered_df[filtered_df['customer_regional_group'].isin(filter_regional_group)]
        filtered_df = filtered_df[
            (filtered_df['price_m3'] >= price_range[0]) & 
            (filtered_df['price_m3'] <= price_range[1])
        ]
        
        st.markdown(f"**Hi·ªÉn th·ªã {len(filtered_df):,} / {len(st.session_state.data):,} s·∫£n ph·∫©m**")
        
        # Define all columns from the contract query in logical order
        # These match the fields from contract_query.txt and salesforce_loader.py
        all_contract_columns = [
            'contract_product_name',   # Name
            'contract_name',           # Contract__r.Name
            'account_code',            # Account_Code_C__c
            'customer_regional_group', # Contract__r.Account__r.Nhom_Khu_vuc_KH__c
            'stone_color_type',        # Product__r.STONE_Color_Type__c
            'sku',                     # Product__r.StockKeepingUnit (SKU)
            'application_code',        # Application code (from SKU positions 3-5)
            'application',             # Application name (English)
            'application_vn',          # Application name (Vietnamese)
            'processing_code',         # Main processing code (from SKU)
            'processing_name',         # Main processing name (English)
            'family',                  # Product__r.Family (legacy)
            'segment',                 # Segment__c
            'created_date',            # Created_Date__c
            'fy_year',                 # Fiscal Year (calculated)
            'product_description',     # Product_Discription__c
            'product_description_vn',  # Product__r.Product_description_in_Vietnamese__c
            'length_cm',               # Length__c
            'width_cm',                # Width__c
            'height_cm',               # Height__c
            'quantity',                # Quantity__c
            'crates',                  # Crates__c
            'm2',                      # m2__c
            'm3',                      # m3__c
            'ml',                      # ml__c
            'tons',                    # Tons__c
            'sales_price',             # Sales_Price__c
            'charge_unit',             # Charge_Unit__c
            'total_price_usd',         # Total_Price_USD__c
            'price_m3',                # Calculated price per m3
            'volume_m3',               # Calculated volume
            'area_m2',                 # Calculated area
        ]
        
        # Filter to only columns that exist in the dataframe
        available_columns = [col for col in all_contract_columns if col in filtered_df.columns]
        
        # Add any remaining columns not in the predefined list
        remaining_columns = [col for col in filtered_df.columns if col not in available_columns]
        display_columns = available_columns + remaining_columns
        
        # Column configuration for English headers on specific columns
        column_config = {
            'sku': st.column_config.TextColumn('SKU', help='Product Stock Keeping Unit'),
            'application_code': st.column_config.TextColumn('App Code', help='Application code from SKU'),
            'application': st.column_config.TextColumn('Application', help='Application name (English)'),
            'application_vn': st.column_config.TextColumn('Application (VN)', help='Application name (Vietnamese)'),
            'processing_code': st.column_config.TextColumn('Main Processing Code', help='K√Ω hi·ªáu gia c√¥ng ch√≠nh'),
            'processing_name': st.column_config.TextColumn('Main Processing', help='Nh√≥m m√£ gia c√¥ng ch√≠nh'),
            'customer_regional_group': st.column_config.TextColumn('Regional Group', help='Nh√≥m Khu v·ª±c KH'),
        }
        
        # Display data with all columns
        st.dataframe(
            filtered_df[display_columns],
            use_container_width=True,
            height=500,
            column_config=column_config
        )
        
        # Download button
        csv = filtered_df[display_columns].to_csv(index=False)
        st.download_button(
            "üì• T·∫£i xu·ªëng CSV",
            csv,
            "stone_price_data.csv",
            "text/csv",
            use_container_width=True
        )


if __name__ == "__main__":
    main()
