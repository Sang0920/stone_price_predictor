"""
Stone Price Predictor - Web Application
D·ª± ƒëo√°n gi√° s·∫£n ph·∫©m ƒë√° t·ª± nhi√™n d·ª±a tr√™n d·ªØ li·ªáu Salesforce

Features:
- Load d·ªØ li·ªáu t·ª´ Salesforce (PricebookEntry, Contract_Product__c)
- Machine Learning model ƒë·ªÉ d·ª± ƒëo√°n gi√°
- Ph√¢n t√≠ch gi√° theo ph√¢n kh√∫c (Economy, Common, Premium, Super Premium)
- T√¨m s·∫£n ph·∫©m t∆∞∆°ng t·ª± v·ªõi gi√° ƒë√£ bi·∫øt
"""

import streamlit as st
import pandas as pd
import numpy as np
from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import mean_absolute_error, r2_score
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import json
import os
from typing import Optional, Dict, Any, List, Tuple
import requests
from io import StringIO

# Import Salesforce data loader
from dotenv import load_dotenv
load_dotenv()  # Load .env file for Salesforce credentials

try:
    from salesforce_loader import SalesforceDataLoader
    SALESFORCE_AVAILABLE = True
except ImportError:
    SALESFORCE_AVAILABLE = False

# ============ Configuration ============
st.set_page_config(
    page_title="Stone Price Predictor",
    page_icon="üíé",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f4e79;
        text-align: center;
        margin-bottom: 2rem;
    }
    .segment-economy { background-color: #c6efce; color: #006100; padding: 5px 10px; border-radius: 5px; }
    .segment-common { background-color: #ffeb9c; color: #9c5700; padding: 5px 10px; border-radius: 5px; }
    .segment-premium { background-color: #ffc7ce; color: #9c0006; padding: 5px 10px; border-radius: 5px; }
    .segment-super { background-color: #9e7cc1; color: white; padding: 5px 10px; border-radius: 5px; }
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 20px;
        border-radius: 10px;
        color: white;
        text-align: center;
    }
    .stTabs [data-baseweb="tab-list"] {
        gap: 24px;
    }
</style>
""", unsafe_allow_html=True)

# ============ Pricing Rules Constants ============
SEGMENT_THRESHOLDS = {
    'Super premium': 1500,  # >= 1500 USD/m3
    'Premium': 800,         # >= 800 USD/m3
    'Common': 400,          # >= 400 USD/m3
    'Economy': 0            # < 400 USD/m3
}

# TLR (Tr·ªçng L∆∞·ª£ng Ri√™ng - Specific Weight) per T√çNH TO√ÅN & B√ÅO GI√Å documentation
TLR_CONSTANTS = {
    # ƒê√° ƒëen khu v·ª±c ƒêak N√¥ng
    'ABSOLUTE BASALT': 2.95,
    'DAK_NONG_BASALT': 2.95,
    # ƒê√° khu v·ª±c Ph∆∞·ªõc H√≤a v√† Qui Nh∆°n
    'BLACK BASALT': 2.65,  # Ch·∫ª tay: 2.65, c·∫Øt m√°y: 2.7
    'BLACK BASALT_SAWN': 2.70,
    'HIVE BASALT': 2.20,  # ƒê√° t·ªï ong
    # Granite
    'GREY GRANITE': 2.70,
    'DARK GREY GRANITE': 2.90,
    'WHITE GRANITE': 2.70,
    'YELLOW GRANITE': 2.70,
    'RED GRANITE': 2.70,
    'PINK GRANITE': 2.70,
    # Bluestone
    'BLUESTONE': 2.70,
    # Marble
    'WHITE MARBLE': 2.70,
    'YELLOW MARBLE': 2.70,
    # Default
    'DEFAULT': 2.70,
}

# HS (H·ªá S·ªë ·ªêp ƒê√°y - Coating Factor) per T√çNH TO√ÅN & B√ÅO GI√Å documentation
HS_FACTORS = {
    # ƒê√° l√°t 6cm m·∫∑t ƒë·ªët, c·∫°nh s·ªô (·ªëp ƒë√°y gi·∫£m 3%)
    'FLAMED_TILE_6CM': 0.97,
    # ƒê√° cubic ch·∫ª tay
    'CUBE_5X5X5': 1.00,
    'CUBE_8X8X8': 0.95,
    'CUBE_10X10X8': 0.875,
    'CUBE_20X10X8': 0.875,
    'CUBE_15X15X12': 0.85,
    # ƒê√° cubic m·∫∑t ƒë·ªët, c·∫°nh ch·∫ª tay
    'CUBE_FLAMED_10X10X8': 0.95,
    'CUBE_FLAMED_20X10X8': 0.95,
    # ƒê√° c√¢y c∆∞a l·ªôt (th√™m 5% do d√†y 10.5cm th·ª±c t·∫ø)
    'PALISADE_SAWN': 1.05,
    # Default
    'DEFAULT': 1.00,
}

# Customer Pricing Rules (A-F) per NGUY√äN T·∫ÆC √ÅP D·ª§NG B·∫¢NG GI√Å documentation
# Segment-aware adjustments
CUSTOMER_PRICING_RULES = {
    'A': {
        'description': 'Kh√°ch th√¢n thi·∫øt ƒë·∫∑c bi·ªát (>10 nƒÉm, 50-150 cont)',
        'base_adjustment': {'min': -0.03, 'max': -0.015},  # -1.5% to -3% vs B
        'label': 'B·ªõt 1.5-3% so v·ªõi B',
        'years': '>10',
        'volume': '50-150 cont',
        'authority': 'Th·∫£o lu·∫≠n chi·∫øn l∆∞·ª£c'
    },
    'B': {
        'description': 'Kh√°ch l·ªõn, chuy√™n nghi·ªáp (3-10 nƒÉm, 20-50 cont)',
        'base_adjustment': {'min': -0.04, 'max': -0.02},  # -2% to -4% vs C
        'usd_adjustment': {'min': -30, 'max': -10},  # -10 to -30 USD/m¬≥ vs C
        'label': 'Th·∫•p h∆°n C: 2-4% (10-30 USD/m¬≥)',
        'years': '3-10',
        'volume': '20-50 cont',
        'authority': 'Th·∫£o lu·∫≠n chi·∫øn l∆∞·ª£c'
    },
    'C': {
        'description': 'Kh√°ch h√†ng ph·ªï th√¥ng (1-5 nƒÉm, 5-20 cont)',
        'base_adjustment': {'min': 0, 'max': 0},  # Base price
        'label': 'Gi√° chu·∫©n',
        'years': '1-5',
        'volume': '5-20 cont',
        'authority': {
            'Economy': 10,      # ¬±10 USD/m¬≥
            'Common': 15,       # ¬±15 USD/m¬≥
            'Premium': 20,      # ¬±20 USD/m¬≥ or ¬±0.5 USD/m¬≤
        }
    },
    'D': {
        'description': 'Kh√°ch m·ªõi, khu v·ª±c chi tr·∫£ cao, size nh·ªè (1 nƒÉm, 1-10 cont)',
        'base_adjustment': {'min': 0.03, 'max': 0.06},  # +3% to +6%
        'usd_adjustment': {'min': 15, 'max': 45},  # +15 to +45 USD/m¬≥
        'label': 'Cao h∆°n C: 3-6% (15-45 USD/m¬≥)',
        'years': '1',
        'volume': '1-10 cont',
        'authority': {
            'Premium': 30,       # ¬±30 USD/m¬≥ or ¬±1.0 USD/m¬≤
            'Super premium': 40, # ¬±40 USD/m¬≥ or ¬±1.5 USD/m¬≤
        }
    },
    'E': {
        'description': 'S·∫£n ph·∫©m m·ªõi, s√°ng t·∫°o, cao c·∫•p (1 nƒÉm, 1-10 cont)',
        'base_adjustment': {'min': 0.08, 'max': 0.15},  # √ó1.08 to √ó1.15
        'label': 'Gi√° cao c·∫•p: √ó1.08-1.15 (+5-10%)',
        'years': '1',
        'volume': '1-10 cont',
        'authority': {
            'Premium': 30,       # ¬±30 USD/m¬≥ or ¬±1.0 USD/m¬≤
            'Super premium': 40, # ¬±40 USD/m¬≥ or ¬±1.5 USD/m¬≤
        }
    },
    'F': {
        'description': 'Kh√°ch h√†ng d·ª± √°n, cao c·∫•p (1-5 nƒÉm, 1-50 cont)',
        'base_adjustment': {'min': 0.08, 'max': 0.15},  # √ó1.08 to √ó1.15
        'label': 'D·ª± √°n: √ó1.08-1.15',
        'years': '1-5',
        'volume': '1-50 cont',
        'authority': {
            'Premium': 30,       # ¬±30 USD/m¬≥ or ¬±1.0 USD/m¬≤
            'Super premium': 40, # ¬±40 USD/m¬≥ or ¬±1.5 USD/m¬≤
        }
    },
}

PRODUCT_FAMILIES = [
    'Exterior_Tiles', 'Interior_Tiles', 'WALLSTONE', 'PALISADE', 
    'STAIR', 'ART', 'High-Class', 'SKIRTING', 'SLAB'
]

# Application codes (SKU positions 3-4) with application names
# Per "Application Mapping - Application Mapping.pdf" and LaTeX docs
# Format: (code_value, display_name) where display shows "APP_NAME - Code(s)"
APPLICATION_CODES = [
    ('1.1', 'CUBE - 1.1'),                     # Cubes / Cobbles
    ('1.3', 'PAVING - 1.3'),                   # Paving stone / Paving slab
    ('1.4', 'CRAZY - 1.4'),                    # Crazy Paving
    ('2.1', 'WALL_STONE - 2.1'),               # Wall stone / Wall brick
    ('2.2', 'WALL_COVERING - 2.2'),            # Wall covering / Wall top
    ('2.3', 'ROCKFACE_WALLING - 2.3'),         # Rockface Walling
    ('3.1', 'PALISADE - 3.1'),                 # Palisades
    ('3.2', 'KERB - 3.2'),                     # Border / Kerbs
    ('3.3', 'CORNER - 3.3'),                   # Corner
    ('4.1,4.2', 'STEP - 4.1 & 4.2'),           # Step (Solid + Cladding)
    ('5.1', 'BLOCK - 5.1'),                    # Block
    ('6.1', 'POOL_SURROUNDING - 6.1'),         # Pool surrounding
    ('6.2', 'WINDOW_SILL - 6.2'),              # Window sill
    ('7.1,7.2,7.3', 'TILE - 7.1 & 7.2 & 7.3'), # Tile / Paver
    ('8.1', 'SKIRTINGS - 8.1'),                # Skirtings
    ('9.1', 'SLAB - 9.1'),                     # Slab
]

# Application codes for search (includes 'All' option)
APPLICATION_CODES_SEARCH = [('', 'All')] + APPLICATION_CODES

# Stone Color Types and their family groupings
# Based on sku.tex - Nguy√™n v·∫≠t li·ªáu (V·ªã tr√≠ 1, 2)
# Format: (internal_value, display_label)
# Stone classes for categorization
STONE_CLASSES = ['BASALT', 'GRANITE', 'BLUE STONE']

# Stone Color Types and their family groupings
# Based on sku.tex - Nguy√™n v·∫≠t li·ªáu (V·ªã tr√≠ 1, 2)
# Format: (internal_value, display_label)
STONE_COLOR_TYPES = [
    ('BD', 'BD - Basalt Black'),
    ('BX', 'BX - Basalt Grey'),
    ('BT', 'BT - Basalt Hive'),
    ('GX', 'GX - Granite Grey'),
    ('GT', 'GT - Granite White'),
    ('GV', 'GV - Granite Yellow'),
    ('GD', 'GD - Granite Red'),
    ('GH', 'GH - Granite Pink'),
    ('MB', 'MB - Marble Bluestone'),
    ('MT', 'MT - Marble White'),
    ('MV', 'MV - Marble Yellow'),
]

# Lookup for display labels
STONE_COLOR_LOOKUP = {code: label for code, label in STONE_COLOR_TYPES}

# Stone family mapping (for Priority 2 matching - same family)
STONE_FAMILY_MAP = {
    'BD': 'BASALT',
    'BX': 'BASALT',
    'BT': 'BASALT',
    'GX': 'GRANITE',
    'GT': 'GRANITE',
    'GV': 'GRANITE',
    'GD': 'GRANITE',
    'GH': 'GRANITE',
    'MB': 'MARBLE',
    'MT': 'MARBLE',
    'MV': 'MARBLE',
}

# Dimension tolerance levels per notes.md
DIMENSION_PRIORITY_LEVELS = {
    '∆Øu ti√™n 1 - ƒê√∫ng k√≠ch th∆∞·ªõc': {'height': 0, 'width': 0, 'length': 0},
    '∆Øu ti√™n 2 - Sai l·ªách nh·ªè': {'height': 1, 'width': 5, 'length': 10},
    '∆Øu ti√™n 3 - Sai l·ªách l·ªõn': {'height': 5, 'width': 20, 'length': 30},
}

CHARGE_UNITS = ['USD/PC', 'USD/M2', 'USD/TON', 'USD/ML', 'USD/M3']



# Customer Regional Groups (Nh√≥m Khu v·ª±c KH)
CUSTOMER_REGIONAL_GROUPS = [
    ('', 'All'),
    ('Nh√≥m ƒë·∫ßu 0', 'Nh√≥m ƒë·∫ßu 0'),
    ('Nh√≥m ƒë·∫ßu 1', 'Nh√≥m ƒë·∫ßu 1'),
    ('Nh√≥m ƒë·∫ßu 2', 'Nh√≥m ƒë·∫ßu 2'),
    ('Nh√≥m ƒë·∫ßu 3', 'Nh√≥m ƒë·∫ßu 3'),
    ('Nh√≥m ƒë·∫ßu 4', 'Nh√≥m ƒë·∫ßu 4'),
    ('Nh√≥m ƒë·∫ßu 5', 'Nh√≥m ƒë·∫ßu 5'),
    ('Nh√≥m ƒë·∫ßu 6', 'Nh√≥m ƒë·∫ßu 6'),
    ('Nh√≥m ƒë·∫ßu 7', 'Nh√≥m ƒë·∫ßu 7'),
    ('Nh√≥m ƒë·∫ßu 8', 'Nh√≥m ƒë·∫ßu 8'),
    ('Nh√≥m ƒë·∫ßu 9', 'Nh√≥m ƒë·∫ßu 9'),
]

# Processing codes with English and Vietnamese names
# Format: (code, English, Vietnamese)
PROCESSING_CODES = [
    ('CUA', 'Sawn', 'C∆∞a'),
    ('DOT', 'Flamed', 'ƒê·ªët'),
    ('DOC', 'Flamed Brush', 'ƒê·ªët Ch·∫£i'),
    ('DOX', 'Flamed Water', 'ƒê·ªët X·ªãt N∆∞·ªõc'),
    ('HON', 'Honed', 'Hon/M√†i M·ªãn'),
    ('CTA', 'Split Handmade', 'Ch·∫ª Tay'),
    ('CLO', 'Sawn then Cleaved', 'C∆∞a L·ªôt'),
    ('TDE', 'Chiseled', 'T∆∞·ªõc ƒê·∫Ωo'),
    ('GCR', 'Vibrated Honed Tumbled', 'G·ªçt C·∫°nh Rung'),
    ('GCT', 'Old Imitation', 'Gi·∫£ C·ªï Tay'),
    ('MGI', 'Scraped', 'M√†i Gi·∫•y'),
    ('PCA', 'Sandblasted', 'Phun C√°t'),
    ('QME', 'Tumbled', 'Quay M·∫ª'),
    ('TLO', 'Cleaved', 'T·ª± Nhi√™n L·ªìi'),
    ('BON', 'Polished', 'B√≥ng'),
    ('BAM', 'Bush Hammered', 'BƒÉm'),
    ('CHA', 'Brush', 'Ch·∫£i'),
]

# Processing codes for search (includes 'All' option)
PROCESSING_CODES_SEARCH = [('', 'All', 'T·∫•t c·∫£')] + PROCESSING_CODES

# Processing Groups for Priority 2 matching (per Notes on Modifying the Pricing Tool.tex)
# Group: GIA C√îNG TAY (Hand Processing)
# Group: GIA C√îNG M√ÅY + TAY (Machine + Hand)
# Group: GIA C√îNG M√ÅY (Machine Processing)
# Group: GIA C√îNG M√ÅY CAO C·∫§P (High-end Machine)
PROCESSING_GROUPS = {
    'GIA_CONG_TAY': ['CTA', 'TLO', 'TDE'],  # Ch·∫ª tay, T·ª± nhi√™n l·ªìi, T∆∞·ªõc ƒë·∫Ωo
    'GIA_CONG_MAY_TAY': ['CUA', 'CLO', 'QME', 'GCT'],  # C∆∞a, C∆∞a l·ªôt, Quay m·∫ª, Gi·∫£ c·ªï tay
    'GIA_CONG_MAY': ['DOT', 'DOC', 'DOX', 'GCR', 'MGI', 'PCA', 'BAM'],  # ƒê·ªët, ƒê·ªët ch·∫£i, ƒê·ªët x·ªãt, etc.
    'GIA_CONG_MAY_CAO_CAP': ['HON', 'BON', 'CHA'],  # Hone, B√≥ng, Ch·∫£i
}

# Reverse mapping: code -> group name
PROCESSING_CODE_TO_GROUP = {}
for group_name, codes in PROCESSING_GROUPS.items():
    for code in codes:
        PROCESSING_CODE_TO_GROUP[code] = group_name

# Human-readable group names
PROCESSING_GROUP_NAMES = {
    'GIA_CONG_TAY': 'Gia c√¥ng Tay',
    'GIA_CONG_MAY_TAY': 'Gia c√¥ng M√°y + Tay',
    'GIA_CONG_MAY': 'Gia c√¥ng M√°y',
    'GIA_CONG_MAY_CAO_CAP': 'Gia c√¥ng M√°y Cao c·∫•p',
}

# ============ Data Generation (Simulated Salesforce Data) ============
@st.cache_data(ttl=3600)
def generate_sample_data(n_samples: int = 500) -> pd.DataFrame:
    """
    Generate sample product pricing data for demonstration.
    In production, this would be replaced with Salesforce API calls.
    """
    np.random.seed(42)
    
    data = []
    for i in range(n_samples):
        # Product attributes
        family = np.random.choice(PRODUCT_FAMILIES)
        stone_class = np.random.choice(STONE_CLASSES)
        stone_color = np.random.choice(STONE_COLOR_TYPES)
        
        # Dimensions in cm
        length = np.random.choice([10, 15, 20, 30, 40, 50, 60, 80, 100, 120])
        width = np.random.choice([5, 8, 10, 15, 20, 30, 40, 60])
        height = np.random.choice([2, 2.5, 3, 5, 6, 7, 8, 10, 12, 15, 20])
        
        # Calculate volume in m3
        volume_m3 = (length * width * height) / 1000000
        area_m2 = (length * width) / 10000
        
        # Base price calculation based on product complexity
        base_price_m3 = 350 + np.random.normal(0, 50)
        
        # Adjustments based on product type
        if family in ['STAIR', 'ART', 'High-Class']:
            base_price_m3 *= 2.5
        elif family in ['Interior_Tiles', 'SLAB']:
            base_price_m3 *= 1.8
        elif family == 'Exterior_Tiles':
            base_price_m3 *= 1.2
            
        # Stone type adjustment
        if stone_color in ['ABSOLUTE BASALT', 'WHITE MARBLE']:
            base_price_m3 *= 1.5
        elif stone_color in ['YELLOW MARBLE', 'RED GRANITE']:
            base_price_m3 *= 1.3
            
        # Size adjustment (smaller pieces = higher price per m3)
        if length <= 15 and width <= 15:
            base_price_m3 *= 1.4
        elif length >= 60 or width >= 60:
            base_price_m3 *= 0.9
            
        # Thickness adjustment
        if height <= 2:
            base_price_m3 *= 2.0  # Thin slices are more expensive
        elif height >= 10:
            base_price_m3 *= 0.85
            
        # Add noise
        price_m3 = max(200, base_price_m3 + np.random.normal(0, 80))
        
        # Calculate segment
        if price_m3 >= 1500:
            segment = 'Super premium'
        elif price_m3 >= 800:
            segment = 'Premium'
        elif price_m3 >= 400:
            segment = 'Common'
        else:
            segment = 'Economy'
            
        # Charge unit
        if family in ['PALISADE', 'STAIR']:
            charge_unit = 'USD/ML'
        elif height <= 3:
            charge_unit = 'USD/M2'
        elif length <= 20 and width <= 20:
            charge_unit = 'USD/PC'
        else:
            charge_unit = np.random.choice(['USD/M3', 'USD/TON'])
            
        # Convert price to selected unit
        if charge_unit == 'USD/M2':
            unit_price = price_m3 * height / 100
        elif charge_unit == 'USD/PC':
            unit_price = price_m3 * volume_m3
        elif charge_unit == 'USD/TON':
            specific_gravity = 2.8 if stone_class == 'BASALT' else 2.65
            unit_price = price_m3 / (specific_gravity * 1.1)
        elif charge_unit == 'USD/ML':
            unit_price = price_m3 * width * height / 10000
        else:
            unit_price = price_m3
            
        # Customer type
        customer_type = np.random.choice(['A', 'B', 'C', 'D', 'E', 'F'], 
                                         p=[0.05, 0.15, 0.35, 0.20, 0.10, 0.15])
        
        # Apply customer discount
        if customer_type == 'A':
            discount = np.random.uniform(0.015, 0.03)
        elif customer_type == 'B':
            discount = np.random.uniform(0.02, 0.04)
        elif customer_type == 'C':
            discount = 0
        elif customer_type == 'D':
            discount = -np.random.uniform(0.03, 0.06)  # Premium price
        elif customer_type == 'E':
            discount = -np.random.uniform(0.05, 0.10)
        else:
            discount = np.random.uniform(-0.02, 0.02)
            
        final_price = unit_price * (1 - discount)
        
        data.append({
            'product_id': f'PROD-{i+1:04d}',
            'product_name': f'{stone_color} {family.replace("_", " ")} {length}x{width}x{height}',
            'family': family,
            'stone_class': stone_class,
            'stone_color_type': stone_color,
            'length_cm': length,
            'width_cm': width,
            'height_cm': height,
            'volume_m3': volume_m3,
            'area_m2': area_m2,
            'charge_unit': charge_unit,
            'list_price': round(unit_price, 2),
            'price_m3': round(price_m3, 2),
            'segment': segment,
            'customer_type': customer_type,
            'discount_pct': round(discount * 100, 2),
            'final_price': round(final_price, 2),
            'created_date': pd.Timestamp.now() - pd.Timedelta(days=np.random.randint(1, 365))
        })
    
    return pd.DataFrame(data)


# ============ Machine Learning Model ============
class StonePricePredictor:
    """Machine Learning model for stone sales price prediction."""
    
    def __init__(self):
        self.model = None
        self.encoders = {}
        self.scaler = StandardScaler()
        self.feature_columns = []
        # NOTE: segment is EXCLUDED to prevent data leakage (segment is derived from price)
        # processing_code is the main surface processing type (e.g., DOT=Flamed, HON=Honed)
        # customer_regional_group is the customer's regional group (Nh√≥m ƒë·∫ßu 0-9) as per notes.md
        self.categorical_columns = ['family', 'stone_color_type', 'charge_unit', 'processing_code', 'customer_regional_group']
        self.numerical_columns = ['length_cm', 'width_cm', 'height_cm', 'volume_m3', 'area_m2']
        # Recency weight decay factor (prices decay by half every 365 days)
        self.recency_half_life_days = 365
        
    def clean_data(self, df: pd.DataFrame, target_col: str = 'sales_price') -> pd.DataFrame:
        """Clean data for training: remove invalid, missing, and outlier data."""
        df_clean = df.copy()
        
        # Remove rows with missing or invalid target
        df_clean = df_clean[df_clean[target_col].notna() & (df_clean[target_col] > 0)]
        
        # Clean processing_code: replace empty/Unknown with 'OTHER'
        if 'processing_code' in df_clean.columns:
            df_clean['processing_code'] = df_clean['processing_code'].fillna('OTHER')
            df_clean['processing_code'] = df_clean['processing_code'].replace('', 'OTHER')
            # Keep 'Unknown' as a valid category but standardize empty strings
        
        # Clean customer_regional_group: replace empty/None with 'Unknown'
        if 'customer_regional_group' in df_clean.columns:
            df_clean['customer_regional_group'] = df_clean['customer_regional_group'].fillna('Unknown')
            df_clean['customer_regional_group'] = df_clean['customer_regional_group'].replace('', 'Unknown')
        
        # Remove rows with missing critical features (excluding columns handled above)
        handled_cols = ['processing_code', 'customer_regional_group']
        for col in self.categorical_columns:
            if col in df_clean.columns and col not in handled_cols:
                df_clean = df_clean[df_clean[col].notna()]
        
        for col in self.numerical_columns:
            if col in df_clean.columns:
                df_clean = df_clean[df_clean[col].notna() & (df_clean[col] >= 0)]
        
        # Remove extreme outliers using IQR method for target variable
        Q1 = df_clean[target_col].quantile(0.01)
        Q3 = df_clean[target_col].quantile(0.99)
        df_clean = df_clean[(df_clean[target_col] >= Q1) & (df_clean[target_col] <= Q3)]
        
        return df_clean
    
    def calculate_recency_weights(self, df: pd.DataFrame) -> np.ndarray:
        """
        Calculate sample weights based on recency (more recent prices have higher weight).
        Uses exponential time decay with configurable half-life.
        
        This helps improve accuracy for new products by prioritizing recent price data,
        accounting for annual cost increases in raw materials and labor.
        """
        if 'created_date' not in df.columns:
            return np.ones(len(df))
        
        # Convert created_date to datetime
        dates = pd.to_datetime(df['created_date'], errors='coerce', utc=True)
        
        # Calculate days since each transaction
        reference_date = pd.Timestamp.now(tz='UTC')
        days_ago = (reference_date - dates).dt.total_seconds() / (24 * 3600)
        
        # Handle NaT values - fill with a large number (oldest date equivalent)
        max_days = days_ago.max()
        if pd.isna(max_days):
            max_days = 365 * 5  # Default to 5 years if all dates are NaT
        days_ago = days_ago.fillna(max_days)
        
        # Exponential time decay: weight = 2^(-days_ago / half_life)
        # Recent prices (days_ago=0) get weight=1, prices from 1 year ago get weight=0.5
        weights = np.power(2, -days_ago / self.recency_half_life_days)
        
        # Normalize weights to have mean of 1 (preserves sample count influence)
        weights = weights / weights.mean()
        
        return weights.values
        
    def prepare_features(self, df: pd.DataFrame, fit: bool = False) -> np.ndarray:
        """Prepare features for ML model."""
        features = df.copy()
        
        # Encode categorical variables
        for col in self.categorical_columns:
            if col in features.columns:
                if fit:
                    self.encoders[col] = LabelEncoder()
                    features[f'{col}_encoded'] = self.encoders[col].fit_transform(features[col].astype(str))
                else:
                    # Handle unseen categories
                    features[f'{col}_encoded'] = features[col].apply(
                        lambda x: self.encoders[col].transform([str(x)])[0] 
                        if str(x) in self.encoders[col].classes_ else -1
                    )
        
        # Select feature columns
        encoded_cols = [f'{col}_encoded' for col in self.categorical_columns if col in df.columns]
        available_numerical = [col for col in self.numerical_columns if col in df.columns]
        self.feature_columns = available_numerical + encoded_cols
        
        X = features[self.feature_columns].values
        
        if fit:
            X = self.scaler.fit_transform(X)
        else:
            X = self.scaler.transform(X)
            
        return X
    
    def train(self, df: pd.DataFrame, target_col: str = 'sales_price') -> Dict[str, float]:
        """Train the sales price prediction model with proper data cleaning and recency weighting."""
        # Clean data: remove invalid, missing, and outlier data
        df_clean = self.clean_data(df, target_col)
        
        if len(df_clean) < 50:
            raise ValueError(f"Kh√¥ng ƒë·ªß d·ªØ li·ªáu h·ª£p l·ªá ƒë·ªÉ hu·∫•n luy·ªán model (ch·ªâ c√≥ {len(df_clean)} m·∫´u, c·∫ßn √≠t nh·∫•t 50)")
        
        # Calculate recency weights (recent prices have higher weight)
        sample_weights = self.calculate_recency_weights(df_clean)
        
        # Prepare features
        X = self.prepare_features(df_clean, fit=True)
        y = df_clean[target_col].values
        
        # Split data with stratification based on charge_unit if possible
        # Also split sample weights to use during training
        X_train, X_test, y_train, y_test, weights_train, weights_test = train_test_split(
            X, y, sample_weights, test_size=0.2, random_state=42
        )
        
        # Optimized Gradient Boosting model for price prediction
        # - subsample < 1.0 helps prevent overfitting
        # - n_iter_no_change enables early stopping
        # - lower learning rate with more estimators for better generalization
        self.model = GradientBoostingRegressor(
            n_estimators=200,
            learning_rate=0.05,        # Lower learning rate for better generalization
            max_depth=4,               # Shallower trees to prevent overfitting
            min_samples_split=10,      # Require more samples to split
            min_samples_leaf=5,        # Require more samples in leaves
            subsample=0.8,             # Use 80% of data per tree (stochastic GB)
            max_features='sqrt',       # Use sqrt of features for each split
            n_iter_no_change=10,       # Early stopping if no improvement
            validation_fraction=0.1,   # Use 10% for validation
            random_state=42
        )
        # Use sample weights during training to prioritize recent prices
        self.model.fit(X_train, y_train, sample_weight=weights_train)
        
        # Evaluate on test set (weighted by recency)
        y_pred = self.model.predict(X_test)
        mae = mean_absolute_error(y_test, y_pred, sample_weight=weights_test)
        r2 = r2_score(y_test, y_pred, sample_weight=weights_test)
        
        # Cross-validation for more robust metrics (unweighted for comparison)
        cv_scores = cross_val_score(self.model, X, y, cv=5, scoring='neg_mean_absolute_error')
        cv_r2_scores = cross_val_score(self.model, X, y, cv=5, scoring='r2')
        
        return {
            'mae': mae,
            'r2': r2,
            'cv_mae_mean': -cv_scores.mean(),
            'cv_mae_std': cv_scores.std(),
            'cv_r2_mean': cv_r2_scores.mean(),
            'cv_r2_std': cv_r2_scores.std(),
            'train_samples': len(df_clean),
            'removed_samples': len(df) - len(df_clean),
            'target_col': target_col,
            'n_estimators_used': self.model.n_estimators_,
            'recency_weighted': True
        }
    
    def predict(self, df: pd.DataFrame) -> np.ndarray:
        """Predict sales prices for new data."""
        if self.model is None:
            raise ValueError("Model not trained. Please train the model first.")
        
        X = self.prepare_features(df, fit=False)
        return self.model.predict(X)
    
    def get_feature_importance(self) -> pd.DataFrame:
        """Get feature importance from the model."""
        if self.model is None:
            return pd.DataFrame()
        
        importance = pd.DataFrame({
            'feature': self.feature_columns,
            'importance': self.model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        return importance


# ============ Helper Functions ============
def get_tlr(stone_color_type: str, processing_code: str = None) -> float:
    """
    Get TLR (Specific Weight) for stone type.
    Per T√çNH TO√ÅN & B√ÅO GI√Å documentation.
    """
    # Check for sawn processing (c·∫Øt m√°y = higher TLR)
    if processing_code in ['CUA', 'HON', 'BON'] and 'BASALT' in stone_color_type.upper():
        return TLR_CONSTANTS.get(stone_color_type + '_SAWN', TLR_CONSTANTS.get(stone_color_type, 2.70))
    return TLR_CONSTANTS.get(stone_color_type, TLR_CONSTANTS['DEFAULT'])


def get_hs_factor(dimensions: tuple = None, processing_code: str = None, family: str = None) -> float:
    """
    Get HS (Coating Factor) for product dimensions/type.
    Per T√çNH TO√ÅN & B√ÅO GI√Å documentation.
    """
    if dimensions:
        l, w, h = dimensions
        # Check for cube dimensions
        if l == 5 and w == 5 and h == 5:
            return HS_FACTORS['CUBE_5X5X5']
        if l == 8 and w == 8 and h == 8:
            return HS_FACTORS['CUBE_8X8X8']
        if (l == 10 and w == 10 and h == 8) or (l == 20 and w == 10 and h == 8):
            if processing_code in ['DOT', 'DOC', 'DOX']:  # Flamed
                return HS_FACTORS['CUBE_FLAMED_10X10X8']
            return HS_FACTORS['CUBE_10X10X8']
        if l == 15 and w == 15 and h == 12:
            return HS_FACTORS['CUBE_15X15X12']
        # Flamed tile 6cm
        if h == 6 and processing_code in ['DOT', 'DOC', 'DOX']:
            return HS_FACTORS['FLAMED_TILE_6CM']
    
    # Check for palisade
    if family == 'PALISADE' and processing_code in ['CLO', 'CUA']:
        return HS_FACTORS['PALISADE_SAWN']
    
    return HS_FACTORS['DEFAULT']


def calculate_volume_m3(length_cm: float, width_cm: float, height_cm: float, quantity: int = 1) -> float:
    """Calculate volume in m¬≥. Formula: (L√óW√óH)/1,000,000 √ó qty"""
    return (length_cm * width_cm * height_cm) / 1_000_000 * quantity


def calculate_area_m2(length_cm: float, width_cm: float, quantity: int = 1) -> float:
    """Calculate area in m¬≤. Formula: (L√óW)/10,000 √ó qty"""
    return (length_cm * width_cm) / 10_000 * quantity


def calculate_weight_tons(volume_m3: float, stone_color_type: str, processing_code: str = None,
                          dimensions: tuple = None, family: str = None) -> float:
    """
    Calculate weight in tons.
    Formula: m¬≥ √ó TLR √ó HS
    """
    tlr = get_tlr(stone_color_type, processing_code)
    hs = get_hs_factor(dimensions, processing_code, family)
    return volume_m3 * tlr * hs


def convert_price(price: float, from_unit: str, to_unit: str, 
                  height_cm: float = None, tlr: float = 2.70, hs: float = 1.0,
                  length_cm: float = None, width_cm: float = None) -> float:
    """
    Convert price between units (USD/PC, USD/M2, USD/M3, USD/TON).
    Per T√çNH TO√ÅN & B√ÅO GI√Å documentation.
    """
    height_m = (height_cm / 100) if height_cm else 0.03
    
    # First convert to price per m¬≥
    if from_unit == 'USD/M3':
        price_m3 = price
    elif from_unit == 'USD/M2':
        price_m3 = price / height_m
    elif from_unit == 'USD/TON':
        price_m3 = price * tlr * hs
    elif from_unit == 'USD/PC':
        if length_cm and width_cm and height_cm:
            vol = (length_cm * width_cm * height_cm) / 1_000_000
            price_m3 = price / vol if vol > 0 else price
        else:
            price_m3 = price * 100  # Rough estimate
    else:
        price_m3 = price
    
    # Then convert from m¬≥ to target unit
    if to_unit == 'USD/M3':
        return price_m3
    elif to_unit == 'USD/M2':
        return price_m3 * height_m
    elif to_unit == 'USD/TON':
        return price_m3 / tlr / hs if tlr > 0 else price_m3
    elif to_unit == 'USD/PC':
        if length_cm and width_cm and height_cm:
            vol = (length_cm * width_cm * height_cm) / 1_000_000
            return price_m3 * vol
        else:
            return price_m3 / 100  # Rough estimate
    else:
        return price_m3


def classify_segment(price_m3: float, height_cm: float = None, family: str = None, 
                     processing_code: str = None) -> str:
    """
    Classify price into segment.
    Per PH√ÇN KH√öC D·ª∞A TR√äN GI√Å V√Ä S·∫¢N PH·∫®M documentation.
    
    Considers both price AND product characteristics:
    - Super premium: ‚â•$1500/m¬≥ OR thin paving (1-1.5cm), wall/pool covering, decorative
    - Premium: ‚â•$800/m¬≥ OR tiles (2-5cm), slabs, steps
    - Common: ‚â•$400/m¬≥ OR palisades, cubes, tumbled
    - Economy: <$400/m¬≥ OR natural split, thick pavers
    """
    # Check product-based rules first
    if height_cm is not None:
        # Thin paving (1.0-1.5cm) = Super premium
        if height_cm <= 1.5 and family in ['Exterior_Tiles', 'Interior_Tiles']:
            return 'Super premium'
        # Tiles 2-5cm with quality processing = Premium
        if 2.0 <= height_cm <= 5.0 and processing_code in ['DOT', 'DOC', 'DOX', 'HON', 'BON']:
            if price_m3 >= 600:  # Slightly lower threshold for processed tiles
                return 'Premium'
        # Thick natural split (‚â•6cm) = Economy
        if height_cm >= 6 and processing_code in ['CTA', 'TLO']:
            return 'Economy'
    
    # Check family-based rules
    if family:
        if family in ['ART', 'High-Class']:
            return 'Super premium'
        if family in ['SLAB', 'STAIR']:
            return 'Premium' if price_m3 >= 600 else 'Common'
        if family == 'PALISADE' and processing_code in ['CLO', 'CUA']:
            return 'Common'
    
    # Fall back to price-based classification
    if price_m3 >= 1500:
        return 'Super premium'
    elif price_m3 >= 800:
        return 'Premium'
    elif price_m3 >= 400:
        return 'Common'
    else:
        return 'Economy'

def get_segment_color(segment: str) -> str:
    """Get color for segment."""
    colors = {
        'Super premium': '#9e7cc1',
        'Premium': '#ff6b6b',
        'Common': '#ffd93d',
        'Economy': '#6bcb77'
    }
    return colors.get(segment, '#808080')

def calculate_customer_price(base_price: float, customer_type: str, 
                             segment: str = None, charge_unit: str = 'USD/M3') -> Dict[str, Any]:
    """
    Calculate price adjustments for different customer types.
    Per NGUY√äN T·∫ÆC √ÅP D·ª§NG B·∫¢NG GI√Å ABCDEF documentation.
    
    Args:
        base_price: The reference price
        customer_type: Customer classification (A-F)
        segment: Product segment for authority range
        charge_unit: Price unit for displaying USD adjustments
    """
    rules = CUSTOMER_PRICING_RULES.get(customer_type, CUSTOMER_PRICING_RULES['C'])
    adj = rules.get('base_adjustment', {'min': 0, 'max': 0})
    
    min_price = round(base_price * (1 + adj['min']), 2)
    max_price = round(base_price * (1 + adj['max']), 2)
    
    # Get authority range based on segment
    authority_range = None
    authority = rules.get('authority')
    if isinstance(authority, dict) and segment:
        authority_range = authority.get(segment)
    
    # Format authority display
    if authority_range:
        if charge_unit == 'USD/M2':
            auth_display = f"¬±{authority_range * 0.05:.1f} USD/m¬≤"  # Approximate m¬≤ conversion
        else:
            auth_display = f"¬±{authority_range} USD/m¬≥"
    elif isinstance(authority, str):
        auth_display = authority
    else:
        auth_display = rules.get('label', 'N/A')
    
    return {
        'base_price': base_price,
        'min_price': min_price,
        'max_price': max_price,
        'adjustment_label': rules.get('label', 'N/A'),
        'customer_description': rules.get('description', ''),
        'authority_range': auth_display,
        'volume': rules.get('volume', ''),
        'years': rules.get('years', ''),
    }

def generate_price_report(
    query_params: Dict[str, Any],
    estimation: Dict[str, Any],
    matched_products: pd.DataFrame,
    customer_price_info: Dict[str, Any] = None,
    yearly_adjustment: Dict[str, Any] = None
) -> str:
    """
    Generate an HTML report for price calculation that can be printed to PDF.
    
    Per manager's notes: Report includes selected options, data/records used for prediction,
    step-by-step formula explanation, and DateTime of calculation.
    """
    from datetime import datetime
    
    now = datetime.now()
    timestamp = now.strftime("%Y-%m-%d %H:%M:%S")
    
    # Build HTML report
    html = f"""
<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>Stone Price Report - {timestamp}</title>
    <style>
        body {{ font-family: Arial, sans-serif; max-width: 800px; margin: 0 auto; padding: 20px; }}
        h1 {{ color: #1f4e79; border-bottom: 2px solid #1f4e79; padding-bottom: 10px; }}
        h2 {{ color: #333; margin-top: 30px; }}
        table {{ width: 100%; border-collapse: collapse; margin: 15px 0; }}
        th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
        th {{ background-color: #1f4e79; color: white; }}
        tr:nth-child(even) {{ background-color: #f9f9f9; }}
        .highlight {{ background-color: #e8f4fd; font-weight: bold; }}
        .price {{ font-size: 1.2em; color: #2e7d32; }}
        .footer {{ margin-top: 30px; font-size: 0.9em; color: #666; border-top: 1px solid #ddd; padding-top: 10px; }}
        @media print {{ body {{ margin: 0; }} }}
    </style>
</head>
<body>
    <h1>üíé Stone Price Report</h1>
    <p><strong>DateTime:</strong> {timestamp}</p>
    
    <h2>üìã Query Parameters</h2>
    <table>
        <tr><th>Parameter</th><th>Value</th></tr>
        <tr><td>Stone Color</td><td>{query_params.get('stone_color', 'N/A')}</td></tr>
        <tr><td>Dimensions (L√óW√óH)</td><td>{query_params.get('length', 0)}√ó{query_params.get('width', 0)}√ó{query_params.get('height', 0)} cm</td></tr>
        <tr><td>Processing</td><td>{query_params.get('processing_code', 'N/A')}</td></tr>
        <tr><td>Regional Group</td><td>{query_params.get('regional_group', 'N/A')}</td></tr>
        <tr><td>Application</td><td>{', '.join(query_params.get('applications', [])) or 'All'}</td></tr>
        <tr><td>Charge Unit</td><td>{query_params.get('charge_unit', 'USD/M3')}</td></tr>
        <tr><td>Customer Type</td><td>{query_params.get('customer_type', 'C')}</td></tr>
    </table>
    
    <h2>üí∞ Price Estimation</h2>
    <table>
        <tr class="highlight"><td>Estimated Price</td><td class="price">${estimation.get('estimated_price', 0):,.2f} {query_params.get('charge_unit', '')}</td></tr>
        <tr><td>Price Range</td><td>${estimation.get('min_price', 0):,.2f} ‚Äì ${estimation.get('max_price', 0):,.2f}</td></tr>
        <tr><td>Median Price</td><td>${estimation.get('median_price', 0):,.2f}</td></tr>
        <tr><td>Match Count</td><td>{estimation.get('match_count', 0)} products</td></tr>
        <tr><td>Reference Years</td><td>{estimation.get('years_used', 'N/A')}</td></tr>
        <tr><td>Confidence</td><td>{estimation.get('confidence', 'N/A')}</td></tr>
    </table>
"""
    
    # Add yearly adjustment if present
    if yearly_adjustment and yearly_adjustment.get('applied'):
        html += f"""
    <h2>üìà Yearly Price Adjustment</h2>
    <table>
        <tr><td>Yearly Increase Rate</td><td>{yearly_adjustment.get('rate', 0):.1f}%</td></tr>
        <tr><td>Average Reference Year</td><td>{yearly_adjustment.get('avg_year', 'N/A')}</td></tr>
        <tr><td>Years Difference</td><td>{yearly_adjustment.get('years_diff', 0)} years</td></tr>
        <tr class="highlight"><td>Adjusted Price ({now.year})</td><td class="price">${yearly_adjustment.get('adjusted_price', 0):,.2f}</td></tr>
    </table>
"""
    
    # Add customer price info if present
    if customer_price_info:
        html += f"""
    <h2>üë§ Customer Price Adjustment (Type {query_params.get('customer_type', 'C')})</h2>
    <table>
        <tr><td>Customer Description</td><td>{customer_price_info.get('customer_description', 'N/A')}</td></tr>
        <tr><td>Adjustment</td><td>{customer_price_info.get('adjustment_label', 'N/A')}</td></tr>
        <tr><td>Price Range</td><td>${customer_price_info.get('min_price', 0):,.2f} ‚Äì ${customer_price_info.get('max_price', 0):,.2f}</td></tr>
        <tr><td>Authority Range</td><td>{customer_price_info.get('authority_range', 'N/A')}</td></tr>
    </table>
"""
    
    # Add matched products summary
    if len(matched_products) > 0:
        html += """
    <h2>üì¶ Matched Products Used for Estimation</h2>
    <table>
        <tr><th>#</th><th>SKU</th><th>Dimensions</th><th>Price</th><th>Year</th></tr>
"""
        for i, (_, row) in enumerate(matched_products.head(15).iterrows(), 1):
            sku = row.get('sku', 'N/A')[:20]
            dims = f"{row.get('length_cm', 0):.0f}√ó{row.get('width_cm', 0):.0f}√ó{row.get('height_cm', 0):.0f}"
            price = row.get('sales_price', 0)
            year = row.get('fy_year', 'N/A')
            html += f"        <tr><td>{i}</td><td>{sku}</td><td>{dims}</td><td>${price:,.2f}</td><td>{year}</td></tr>\n"
        
        if len(matched_products) > 15:
            html += f"        <tr><td colspan='5'>... and {len(matched_products) - 15} more products</td></tr>\n"
        html += "    </table>\n"
    
    # Add formulas section
    html += """
    <h2>üìê Calculation Formulas</h2>
    <ul>
        <li><strong>Volume:</strong> m¬≥ = (Length √ó Width √ó Height) / 1,000,000</li>
        <li><strong>Area:</strong> m¬≤ = (Length √ó Width) / 10,000</li>
        <li><strong>Weight:</strong> Tons = m¬≥ √ó TLR √ó HS</li>
        <li><strong>Price Conversion:</strong> USD/m¬≤ = USD/m¬≥ √ó Height(m)</li>
        <li><strong>Yearly Adjustment:</strong> Adjusted = Base √ó (1 + Rate%)^Years</li>
    </ul>
    
    <div class="footer">
        <p>Generated by Stone Price Predictor | Report Date: """ + timestamp + """</p>
        <p>To save as PDF: Print this page (Ctrl+P) and select "Save as PDF"</p>
    </div>
</body>
</html>
"""
    return html

def find_similar_products(df: pd.DataFrame, query: Dict, top_n: int = 5) -> pd.DataFrame:
    """Find similar products based on attributes."""
    # Filter by basic criteria
    mask = pd.Series([True] * len(df))
    
    if query.get('stone_color_type'):
        mask &= df['stone_color_type'] == query['stone_color_type']
    
    if query.get('family'):
        mask &= df['family'] == query['family']
    
    filtered_df = df[mask].copy()
    
    if len(filtered_df) == 0:
        return pd.DataFrame()
    
    # Calculate similarity score based on dimensions
    if all(k in query for k in ['length_cm', 'width_cm', 'height_cm']):
        filtered_df['dim_diff'] = (
            abs(filtered_df['length_cm'] - query['length_cm']) +
            abs(filtered_df['width_cm'] - query['width_cm']) +
            abs(filtered_df['height_cm'] - query['height_cm'])
        )
        filtered_df = filtered_df.nsmallest(top_n, 'dim_diff')
    else:
        filtered_df = filtered_df.head(top_n)
    
    return filtered_df


# ============ Similarity-Based Price Predictor ============
class SimilarityPricePredictor:
    """
    Price estimation based on similarity search with priority levels.
    Matches products using criteria from notes.md.
    """
    
    def __init__(self):
        self.data = None
        self.recency_half_life_days = 365
        
    def load_data(self, df: pd.DataFrame):
        """Load and prepare data for similarity search."""
        self.data = df[df['sales_price'].notna() & (df['sales_price'] > 0)].copy()
        # Add stone family for priority 2 matching
        if 'stone_color_type' in self.data.columns:
            self.data['stone_family'] = self.data['stone_color_type'].map(STONE_FAMILY_MAP).fillna('OTHER')
        return len(self.data)
    
    def find_matching_products(
        self, 
        stone_color_type: str,
        processing_code: str,
        length_cm: float,
        width_cm: float,
        height_cm: float,
        application_codes: list,  # List of application codes (empty = all)
        customer_regional_group: str,
        charge_unit: str,
        stone_priority: str = '∆Øu ti√™n 1',  # Exact, Same Family, All
        processing_priority: str = '∆Øu ti√™n 1',  # Exact, Group, All
        dimension_priority: str = '∆Øu ti√™n 1 - ƒê√∫ng k√≠ch th∆∞·ªõc',
        region_priority: str = '∆Øu ti√™n 1',  # Billing Country, Regional Group, All
        no_length_limit: bool = False,  # For P3: unlimited length
        billing_country: str = None,  # For P1 market: specific country
        selected_processing_group: str = None,  # For P2: user-selected processing group
    ) -> pd.DataFrame:
        """
        Find matching products based on priority criteria from notes.md.
        
        Priority Levels:
        - ∆Øu ti√™n 1: Exact match
        - ∆Øu ti√™n 2: Same family / group / small tolerance
        - ∆Øu ti√™n 3: All / large tolerance
        """
        if self.data is None or len(self.data) == 0:
            return pd.DataFrame()
        
        df = self.data.copy()
        mask = pd.Series([True] * len(df), index=df.index)
        
        # 1. Stone Type Filter
        query_family = STONE_FAMILY_MAP.get(stone_color_type, 'OTHER')
        if stone_priority == '∆Øu ti√™n 1':
            mask &= df['stone_color_type'] == stone_color_type
        elif stone_priority == '∆Øu ti√™n 2':
            mask &= df['stone_family'] == query_family
        # ∆Øu ti√™n 3: No filter (All stones)
        
        # 2. Processing Filter with Group Support
        if processing_priority == '∆Øu ti√™n 1' and processing_code:
            # Exact match
            mask &= df['processing_code'] == processing_code
        elif processing_priority == '∆Øu ti√™n 2':
            # Group match: use user-selected group or derive from processing_code
            if selected_processing_group and selected_processing_group in PROCESSING_GROUPS:
                group_codes = PROCESSING_GROUPS.get(selected_processing_group, [])
            else:
                query_group = PROCESSING_CODE_TO_GROUP.get(processing_code)
                group_codes = PROCESSING_GROUPS.get(query_group, [processing_code]) if query_group else [processing_code]
            mask &= df['processing_code'].isin(group_codes)
        # ∆Øu ti√™n 3: No filter (All processing types)
        
        # 3. Application Filter (extracted from SKU positions 3-4)
        # If application_codes is not empty, filter by those codes
        if application_codes and len(application_codes) > 0 and 'application_code' in df.columns:
            # Handle comma-separated codes like "4.1,4.2" and "7.1,7.2,7.3"
            expanded_codes = []
            for code in application_codes:
                if ',' in code:
                    expanded_codes.extend(code.split(','))
                else:
                    expanded_codes.append(code)
            mask &= df['application_code'].isin(expanded_codes)
        
        # 4. Charge Unit Filter
        if charge_unit:
            mask &= df['charge_unit'] == charge_unit
        
        # 5. Market/Region Filter based on priority
        if region_priority == '∆Øu ti√™n 1':
            # P1: Filter by Billing Country
            if billing_country and 'billing_country' in df.columns:
                mask &= df['billing_country'] == billing_country
        elif region_priority == '∆Øu ti√™n 2':
            # P2: Filter by Regional Group
            if customer_regional_group and 'customer_regional_group' in df.columns:
                mask &= df['customer_regional_group'] == customer_regional_group
        # ∆Øu ti√™n 3: No filter (All markets)
        
        # Apply initial filters
        df_filtered = df[mask].copy()
        
        if len(df_filtered) == 0:
            return pd.DataFrame()
        
        # 6. Dimension Filter with tolerances
        tolerances = DIMENSION_PRIORITY_LEVELS.get(dimension_priority, {'height': 0, 'width': 0, 'length': 0})
        
        # Handle unlimited length for P3
        length_tolerance = 9999 if no_length_limit else tolerances['length']
        
        dim_mask = (
            (abs(df_filtered['height_cm'] - height_cm) <= tolerances['height']) &
            (abs(df_filtered['width_cm'] - width_cm) <= tolerances['width']) &
            (abs(df_filtered['length_cm'] - length_cm) <= length_tolerance)
        )
        
        df_matches = df_filtered[dim_mask].copy()
        
        return df_matches
    
    def get_match_diagnostics(
        self,
        stone_color_type: str,
        processing_code: str,
        length_cm: float,
        width_cm: float,
        height_cm: float,
        application_codes: list,
        customer_regional_group: str,
        charge_unit: str,
        stone_priority: str = '∆Øu ti√™n 1',
        processing_priority: str = '∆Øu ti√™n 1',
        dimension_priority: str = '∆Øu ti√™n 1 - ƒê√∫ng k√≠ch th∆∞·ªõc',
        region_priority: str = '∆Øu ti√™n 1',
        no_length_limit: bool = False,
        billing_country: str = None,
    ) -> Dict[str, Any]:
        """
        Analyze why no matches were found and return diagnostic information.
        Returns closest available dimensions and filter breakdown.
        """
        if self.data is None or len(self.data) == 0:
            return {'reason': 'Kh√¥ng c√≥ d·ªØ li·ªáu', 'suggestions': []}
        
        df = self.data.copy()
        diagnostics = {
            'reason': '',
            'suggestions': [],
            'closest_height': None,
            'closest_width': None,
            'closest_length': None,
            'filter_counts': {}
        }
        
        # Track filter stages
        mask = pd.Series([True] * len(df), index=df.index)
        diagnostics['filter_counts']['total'] = len(df)
        
        # 1. Stone type
        query_family = STONE_FAMILY_MAP.get(stone_color_type, 'OTHER')
        if stone_priority == '∆Øu ti√™n 1':
            stone_mask = df['stone_color_type'] == stone_color_type
        elif stone_priority == '∆Øu ti√™n 2':
            stone_mask = df['stone_family'] == query_family
        else:
            stone_mask = pd.Series([True] * len(df), index=df.index)
        mask &= stone_mask
        diagnostics['filter_counts']['after_stone'] = mask.sum()
        
        # 2. Processing
        if processing_priority == '∆Øu ti√™n 1' and processing_code:
            proc_mask = df['processing_code'] == processing_code
            mask &= proc_mask
        diagnostics['filter_counts']['after_processing'] = mask.sum()
        
        # 3. Application
        if application_codes and len(application_codes) > 0 and 'application_code' in df.columns:
            mask &= df['application_code'].isin(application_codes)
        diagnostics['filter_counts']['after_application'] = mask.sum()
        
        # 4. Charge unit
        if charge_unit:
            mask &= df['charge_unit'] == charge_unit
        diagnostics['filter_counts']['after_charge_unit'] = mask.sum()
        
        # 5. Region
        if 'customer_regional_group' in df.columns and region_priority == '∆Øu ti√™n 1' and customer_regional_group:
            mask &= df['customer_regional_group'] == customer_regional_group
        diagnostics['filter_counts']['after_region'] = mask.sum()
        
        df_filtered = df[mask].copy()
        
        if len(df_filtered) == 0:
            # Find which filter caused the problem
            if diagnostics['filter_counts']['after_stone'] == 0:
                diagnostics['reason'] = f"Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m lo·∫°i ƒë√° '{stone_color_type}'"
                diagnostics['suggestions'].append("Th·ª≠ ch·ªçn ∆Øu ti√™n 2 ho·∫∑c 3 cho Lo·∫°i ƒë√°")
            elif diagnostics['filter_counts']['after_processing'] == 0:
                diagnostics['reason'] = f"Kh√¥ng t√¨m th·∫•y gia c√¥ng '{processing_code}' cho lo·∫°i ƒë√° n√†y"
                diagnostics['suggestions'].append("Th·ª≠ ch·ªçn ∆Øu ti√™n 2 cho Gia c√¥ng")
            elif diagnostics['filter_counts']['after_application'] == 0:
                app_names = ', '.join(application_codes) if application_codes else ''
                diagnostics['reason'] = f"Kh√¥ng t√¨m th·∫•y ·ª©ng d·ª•ng '{app_names}' cho c√°c ti√™u ch√≠ ƒë√£ ch·ªçn"
                diagnostics['suggestions'].append("Th·ª≠ b·ªè ch·ªçn ·ª©ng d·ª•ng c·ª• th·ªÉ")
            elif diagnostics['filter_counts']['after_charge_unit'] == 0:
                diagnostics['reason'] = f"Kh√¥ng t√¨m th·∫•y ƒë∆°n v·ªã t√≠nh '{charge_unit}'"
                diagnostics['suggestions'].append("Th·ª≠ ƒë·ªïi ƒë∆°n v·ªã t√≠nh gi√°")
            else:
                diagnostics['reason'] = "Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m v·ªõi c√°c ti√™u ch√≠ ƒë√£ ch·ªçn"
            return diagnostics
        
        # 6. Check dimensions
        tolerances = DIMENSION_PRIORITY_LEVELS.get(dimension_priority, {'height': 0, 'width': 0, 'length': 0})
        
        # Find closest dimensions in filtered data
        closest_height = df_filtered.loc[(df_filtered['height_cm'] - height_cm).abs().idxmin(), 'height_cm']
        closest_width = df_filtered.loc[(df_filtered['width_cm'] - width_cm).abs().idxmin(), 'width_cm']
        closest_length = df_filtered.loc[(df_filtered['length_cm'] - length_cm).abs().idxmin(), 'length_cm']
        
        diagnostics['closest_height'] = closest_height
        diagnostics['closest_width'] = closest_width
        diagnostics['closest_length'] = closest_length
        
        height_diff = abs(closest_height - height_cm)
        width_diff = abs(closest_width - width_cm)
        length_diff = abs(closest_length - length_cm)
        
        # Check which dimension is blocking
        dim_issues = []
        if height_diff > tolerances['height']:
            dim_issues.append(f"Cao {height_cm}cm (g·∫ßn nh·∫•t: {closest_height}cm, sai l·ªách: {height_diff:.0f}cm > ¬±{tolerances['height']}cm)")
        if width_diff > tolerances['width']:
            dim_issues.append(f"R·ªông {width_cm}cm (g·∫ßn nh·∫•t: {closest_width}cm, sai l·ªách: {width_diff:.0f}cm > ¬±{tolerances['width']}cm)")
        if length_diff > tolerances['length']:
            dim_issues.append(f"D√†i {length_cm}cm (g·∫ßn nh·∫•t: {closest_length}cm, sai l·ªách: {length_diff:.0f}cm > ¬±{tolerances['length']}cm)")
        
        if dim_issues:
            diagnostics['reason'] = "Kh√¥ng t√¨m th·∫•y k√≠ch th∆∞·ªõc ph√π h·ª£p:\n‚Ä¢ " + "\n‚Ä¢ ".join(dim_issues)
            diagnostics['suggestions'].append("Th·ª≠ ch·ªçn ∆Øu ti√™n 3 cho K√≠ch th∆∞·ªõc (sai l·ªách l·ªõn)")
        
        diagnostics['filter_counts']['after_dimensions'] = len(self.find_matching_products(
            stone_color_type, processing_code, length_cm, width_cm, height_cm,
            application_codes, customer_regional_group, charge_unit,
            stone_priority, processing_priority, dimension_priority, region_priority
        ))
        
        return diagnostics
    
    def calculate_recency_weights(self, df: pd.DataFrame) -> pd.Series:
        """Calculate recency weights for price averaging."""
        if 'created_date' not in df.columns or len(df) == 0:
            return pd.Series([1.0] * len(df), index=df.index)
        
        dates = pd.to_datetime(df['created_date'], errors='coerce', utc=True)
        reference_date = pd.Timestamp.now(tz='UTC')
        days_ago = (reference_date - dates).dt.total_seconds() / (24 * 3600)
        
        max_days = days_ago.max()
        if pd.isna(max_days):
            max_days = 365 * 5
        days_ago = days_ago.fillna(max_days)
        
        weights = np.power(2, -days_ago / self.recency_half_life_days)
        return weights
    
    def estimate_price(self, matches: pd.DataFrame, use_recent_only: bool = True, recent_count: int = 10,
                        query_length_cm: float = None, query_width_cm: float = None, query_height_cm: float = None,
                        target_charge_unit: str = 'USD/M3', stone_color_type: str = None, processing_code: str = None) -> Dict[str, Any]:
        """
        Estimate price from matching products.
        Uses recency-weighted average, optionally filtering to most recent products.
        
        IMPORTANT: Normalizes all prices to USD/M3 before averaging to account for 
        different product sizes. Then converts back to target_charge_unit using 
        query dimensions. This ensures that larger products are priced proportionally 
        higher than smaller similar products.
        
        Args:
            matches: DataFrame of matching products
            use_recent_only: If True, filter to only the most recent products
            recent_count: Number of most recent products to use (if use_recent_only=True)
            query_length_cm: Length of the product being quoted (for unit conversion)
            query_width_cm: Width of the product being quoted (for unit conversion)
            query_height_cm: Height of the product being quoted (for unit conversion)
            target_charge_unit: The unit to return the price in (USD/PC, USD/M2, USD/M3, USD/TON)
            stone_color_type: Stone type for TLR calculation
            processing_code: Processing code for TLR/HS calculation
        """
        if len(matches) == 0:
            return {
                'estimated_price': None,
                'min_price': None,
                'max_price': None,
                'median_price': None,
                'match_count': 0,
                'total_matches': 0,
                'confidence': 'none',
                'years_used': '',
                'price_m3': None
            }
        
        total_matches = len(matches)
        
        # Filter to most recent products based on fy_year and created_date
        if use_recent_only and len(matches) > recent_count:
            # Sort by fy_year (desc) then created_date (desc)
            sorted_matches = matches.copy()
            if 'fy_year' in sorted_matches.columns:
                # Convert fy_year to numeric for proper sorting
                sorted_matches['_fy_year_numeric'] = pd.to_numeric(sorted_matches['fy_year'], errors='coerce')
                sorted_matches = sorted_matches.sort_values(
                    by=['_fy_year_numeric', 'created_date'], 
                    ascending=[False, False],
                    na_position='last'
                )
                sorted_matches = sorted_matches.drop(columns=['_fy_year_numeric'])
            elif 'created_date' in sorted_matches.columns:
                sorted_matches = sorted_matches.sort_values(
                    by=['created_date'], 
                    ascending=[False],
                    na_position='last'
                )
            # Take only the top N most recent
            matches = sorted_matches.head(recent_count)
        
        # Get years used for display
        years_used = ''
        if 'fy_year' in matches.columns:
            unique_years = matches['fy_year'].dropna().unique()
            unique_years = sorted([int(y) for y in unique_years if pd.notna(y)], reverse=True)
            if len(unique_years) > 0:
                years_used = ', '.join(str(y) for y in unique_years[:3])
        
        # Calculate weights
        weights = self.calculate_recency_weights(matches)
        
        # Normalize all prices to USD/M3 before averaging
        # This ensures fair comparison across different product sizes
        prices_m3 = []
        for idx, row in matches.iterrows():
            price = row['sales_price']
            unit = row.get('charge_unit', 'USD/M3')
            match_length = row.get('length_cm', 10)
            match_width = row.get('width_cm', 10)
            match_height = row.get('height_cm', 3)
            match_stone = row.get('stone_color_type', stone_color_type or 'ABSOLUTE BASALT')
            match_proc = row.get('processing_code', processing_code)
            
            # Get TLR and HS for this product
            tlr = get_tlr(match_stone, match_proc)
            hs = get_hs_factor((match_length, match_width, match_height), match_proc)
            
            # Convert to USD/M3
            price_m3 = convert_price(
                price, unit, 'USD/M3',
                height_cm=match_height,
                length_cm=match_length,
                width_cm=match_width,
                tlr=tlr,
                hs=hs
            )
            prices_m3.append(price_m3)
        
        prices_m3 = pd.Series(prices_m3, index=matches.index)
        
        # Weighted average in USD/M3 (the normalized unit)
        weighted_price_m3 = np.average(prices_m3, weights=weights)
        
        # Convert from USD/M3 to target unit using QUERY dimensions
        # This is the key: we use the NEW product's dimensions, not the matched products'
        if query_length_cm is not None and query_width_cm is not None and query_height_cm is not None:
            query_tlr = get_tlr(stone_color_type or 'ABSOLUTE BASALT', processing_code)
            query_hs = get_hs_factor((query_length_cm, query_width_cm, query_height_cm), processing_code)
            
            estimated_price = convert_price(
                weighted_price_m3, 'USD/M3', target_charge_unit,
                height_cm=query_height_cm,
                length_cm=query_length_cm,
                width_cm=query_width_cm,
                tlr=query_tlr,
                hs=query_hs
            )
            
            # Also convert min/max/median to target unit
            min_price = convert_price(
                prices_m3.min(), 'USD/M3', target_charge_unit,
                height_cm=query_height_cm, length_cm=query_length_cm, width_cm=query_width_cm,
                tlr=query_tlr, hs=query_hs
            )
            max_price = convert_price(
                prices_m3.max(), 'USD/M3', target_charge_unit,
                height_cm=query_height_cm, length_cm=query_length_cm, width_cm=query_width_cm,
                tlr=query_tlr, hs=query_hs
            )
            median_price = convert_price(
                prices_m3.median(), 'USD/M3', target_charge_unit,
                height_cm=query_height_cm, length_cm=query_length_cm, width_cm=query_width_cm,
                tlr=query_tlr, hs=query_hs
            )
        else:
            # Fallback: use original method (direct averaging) if no query dimensions
            prices = matches['sales_price']
            estimated_price = np.average(prices, weights=weights)
            min_price = prices.min()
            max_price = prices.max()
            median_price = prices.median()
        
        # Confidence based on match count
        if len(matches) >= 10:
            confidence = 'high'
        elif len(matches) >= 5:
            confidence = 'medium'
        elif len(matches) >= 2:
            confidence = 'low'
        else:
            confidence = 'very_low'
        
        # Calculate price trend based on fy_year
        price_trend = None
        trend_pct = None
        if 'fy_year' in matches.columns and len(matches) >= 3:
            # Group by year and calculate average price_m3
            yearly_data = pd.DataFrame({
                'fy_year': matches['fy_year'],
                'price_m3': prices_m3
            })
            yearly_avg = yearly_data.groupby('fy_year')['price_m3'].mean()
            if len(yearly_avg) >= 2:
                sorted_years = sorted(yearly_avg.index, reverse=True)
                if len(sorted_years) >= 2:
                    this_year_price = yearly_avg[sorted_years[0]]
                    last_year_price = yearly_avg[sorted_years[1]]
                    if last_year_price > 0:
                        trend_pct = ((this_year_price - last_year_price) / last_year_price) * 100
                        if trend_pct > 0:
                            price_trend = 'up'
                        elif trend_pct < 0:
                            price_trend = 'down'
                        else:
                            price_trend = 'stable'
        
        # Calculate average fiscal year for price adjustment
        avg_fy_year = None
        if 'fy_year' in matches.columns:
            fy_years_numeric = pd.to_numeric(matches['fy_year'], errors='coerce')
            fy_years_valid = fy_years_numeric.dropna()
            if len(fy_years_valid) > 0:
                avg_fy_year = fy_years_valid.mean()
        
        return {
            'estimated_price': round(estimated_price, 2),
            'min_price': round(min_price, 2),
            'max_price': round(max_price, 2),
            'median_price': round(median_price, 2),
            'match_count': len(matches),
            'total_matches': total_matches,
            'confidence': confidence,
            'years_used': years_used,
            'price_m3': round(weighted_price_m3, 2),
            'price_trend': price_trend,
            'trend_pct': round(trend_pct, 1) if trend_pct is not None else None,
            'avg_fy_year': round(avg_fy_year, 1) if avg_fy_year is not None else None
        }
    
    def predict_with_escalation(
        self,
        stone_color_type: str,
        processing_code: str,
        length_cm: float,
        width_cm: float,
        height_cm: float,
        application_codes: list,  # List of application codes (empty = all)
        customer_regional_group: str,
        charge_unit: str,
    ) -> Tuple[Dict[str, Any], pd.DataFrame, str]:
        """
        Try to find matches with automatic priority escalation.
        Starts with ∆Øu ti√™n 1 and escalates if no matches found.
        
        Returns:
            - Price estimation dict
            - Matching products DataFrame
            - Priority level used
        """
        priority_levels = [
            ('∆Øu ti√™n 1', '∆Øu ti√™n 1', '∆Øu ti√™n 1 - ƒê√∫ng k√≠ch th∆∞·ªõc', '∆Øu ti√™n 1'),
            ('∆Øu ti√™n 1', '∆Øu ti√™n 1', '∆Øu ti√™n 2 - Sai l·ªách nh·ªè', '∆Øu ti√™n 1'),
            ('∆Øu ti√™n 1', '∆Øu ti√™n 2', '∆Øu ti√™n 2 - Sai l·ªách nh·ªè', '∆Øu ti√™n 2'),
            ('∆Øu ti√™n 2', '∆Øu ti√™n 2', '∆Øu ti√™n 2 - Sai l·ªách nh·ªè', '∆Øu ti√™n 2'),
            ('∆Øu ti√™n 2', '∆Øu ti√™n 2', '∆Øu ti√™n 3 - Sai l·ªách l·ªõn', '∆Øu ti√™n 2'),
            ('∆Øu ti√™n 3', '∆Øu ti√™n 2', '∆Øu ti√™n 3 - Sai l·ªách l·ªõn', '∆Øu ti√™n 2'),
        ]
        
        for stone_p, proc_p, dim_p, region_p in priority_levels:
            matches = self.find_matching_products(
                stone_color_type=stone_color_type,
                processing_code=processing_code,
                length_cm=length_cm,
                width_cm=width_cm,
                height_cm=height_cm,
                application_codes=application_codes,
                customer_regional_group=customer_regional_group,
                charge_unit=charge_unit,
                stone_priority=stone_p,
                processing_priority=proc_p,
                dimension_priority=dim_p,
                region_priority=region_p,
            )
            
            if len(matches) > 0:
                estimation = self.estimate_price(matches)
                priority_used = f"ƒê√°: {stone_p}, Gia c√¥ng: {proc_p}, K√≠ch th∆∞·ªõc: {dim_p}, Khu v·ª±c: {region_p}"
                return estimation, matches, priority_used
        
        return self.estimate_price(pd.DataFrame()), pd.DataFrame(), "Kh√¥ng t√¨m th·∫•y"


# ============ Streamlit App ============
def main():
    # Header
    st.markdown('<h1 class="main-header">üíé Stone Price Predictor</h1>', unsafe_allow_html=True)
    st.markdown('<p style="text-align: center; color: #666;">D·ª± ƒëo√°n gi√° s·∫£n ph·∫©m ƒë√° t·ª± nhi√™n v·ªõi AI v√† d·ªØ li·ªáu Salesforce</p>', unsafe_allow_html=True)
    
    # Initialize session state
    if 'data' not in st.session_state:
        st.session_state.data = None
    if 'model' not in st.session_state:
        st.session_state.model = None
    if 'model_metrics' not in st.session_state:
        st.session_state.model_metrics = None
    if 'data_loaded' not in st.session_state:
        st.session_state.data_loaded = False
    
    # Auto-load data on first app launch
    if not st.session_state.data_loaded and SALESFORCE_AVAILABLE:
        with st.spinner("üîÑ ƒêang t·∫£i d·ªØ li·ªáu t·ª´ Salesforce..."):
            try:
                loader = SalesforceDataLoader()
                df = loader.get_contract_products()
                if len(df) > 0:
                    st.session_state.data = df
                    predictor = SimilarityPricePredictor()
                    count = predictor.load_data(df)
                    st.session_state.model = predictor
                    st.session_state.model_metrics = {'loaded_samples': count}
                    st.session_state.data_loaded = True
            except Exception as e:
                st.error(f"‚ùå L·ªói t·ª± ƒë·ªông t·∫£i d·ªØ li·ªáu: {str(e)}")
    
    # Sidebar
    with st.sidebar:
        st.markdown("## üíé Stone Price Predictor")
        st.title("‚öôÔ∏è C·∫•u h√¨nh")
        
        # Data source - Salesforce only
        st.markdown("**Ngu·ªìn d·ªØ li·ªáu:** Salesforce Contract Products")
        
        # Optional account code filter for Salesforce
        account_filter = st.text_input(
            "M√£ kh√°ch h√†ng (t√πy ch·ªçn)",
            placeholder="e.g., X09",
            help="L·ªçc theo Account_Code_C__c"
        )
        
        if st.button("üîÑ T·∫£i / L√†m m·ªõi d·ªØ li·ªáu t·ª´ Salesforce", use_container_width=True):
            with st.spinner("ƒêang t·∫£i v√† x·ª≠ l√Ω d·ªØ li·ªáu..."):
                if SALESFORCE_AVAILABLE:
                    try:
                        # Step 1: Load data from Salesforce
                        loader = SalesforceDataLoader()
                        df = loader.get_contract_products(account_code=account_filter if account_filter else None)
                        if len(df) > 0:
                            st.session_state.data = df
                            
                            # Step 2: Auto-preprocess data
                            predictor = SimilarityPricePredictor()
                            count = predictor.load_data(df)
                            st.session_state.model = predictor
                            st.session_state.model_metrics = {'loaded_samples': count}
                            
                            st.success(f"‚úÖ ƒê√£ t·∫£i {len(df):,} s·∫£n ph·∫©m, s·∫µn s√†ng v·ªõi {count:,} s·∫£n ph·∫©m c√≥ gi√°!")
                        else:
                            st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu t·ª´ Salesforce.")
                    except Exception as e:
                        st.error(f"‚ùå L·ªói k·∫øt n·ªëi Salesforce: {str(e)}")
                else:
                    st.error("‚ùå Salesforce ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh. Vui l√≤ng ki·ªÉm tra file .env")
        
        # Show status
        if st.session_state.data is not None:
            count = len(st.session_state.data)
            ready_count = st.session_state.model_metrics.get('loaded_samples', 0) if st.session_state.model_metrics else 0
            st.success(f"‚úÖ ƒê√£ s·∫µn s√†ng v·ªõi {count:,} s·∫£n ph·∫©m ({ready_count:,} s·∫£n ph·∫©m c√≥ gi√°)")
        
        st.divider()
    
    # Main content
    if st.session_state.data is None:
        st.info("üëà Vui l√≤ng t·∫£i d·ªØ li·ªáu t·ª´ sidebar ƒë·ªÉ b·∫Øt ƒë·∫ßu")
        
        # Show sample pricing matrix
        st.subheader("üìä Ma tr·∫≠n gi√° theo ph√¢n kh√∫c v√† lo·∫°i s·∫£n ph·∫©m")
        
        matrix_data = {
            'Lo·∫°i s·∫£n ph·∫©m': ['ƒê√° l√°t m·ªèng 1-1.5cm', 'ƒê√° n·ªôi ngo·∫°i th·∫•t 2-5cm', 'ƒê√° b·∫≠c thang', 'ƒê√° c√¢y', 'ƒê√° m·ªπ ngh·ªá'],
            'Economy (<$400/m¬≥)': ['ƒê√° m·∫ª, ƒë√° g√µ tay', 'ƒê√° c∆° b·∫£n', '-', 'ƒê√° c√¢y c∆∞a l·ªôt', 'C∆° b·∫£n'],
            'Common ($400-800/m¬≥)': ['ƒê√° 1 m·∫∑t ƒë·ªët', 'ƒê√° l√°t th√¥ng d·ª•ng', 'ƒê√° nguy√™n kh·ªëi', 'ƒê·ªët ch·∫£i', 'Trung b√¨nh'],
            'Premium ($800-1500/m¬≥)': ['ƒê√° x·ª≠ l√Ω ƒë·∫∑c bi·ªát', 'ƒê√° cao c·∫•p', 'ƒê√° ·ªëp b·∫≠c thang', 'X·ª≠ l√Ω nhi·ªÅu m·∫∑t', 'Cao c·∫•p'],
            'Super Premium (>$1500/m¬≥)': ['ƒê√° m·ªèng ƒë·∫∑c bi·ªát', 'ƒê√° n·∫Øp t∆∞·ªùng, h·ªì b∆°i', 'ƒê·∫∑c bi·ªát', 'ƒê·∫∑c bi·ªát', 'M·ªπ ngh·ªá ƒë·∫∑c bi·ªát']
        }
        st.dataframe(pd.DataFrame(matrix_data), use_container_width=True)
        return
    
    # Tabs
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "üîÆ D·ª± ƒëo√°n gi√°", 
        "üìä Ph√¢n t√≠ch d·ªØ li·ªáu", 
        "üîç T√¨m s·∫£n ph·∫©m t∆∞∆°ng t·ª±",
        "üìê B·∫£ng tra c·ª©u",
        "üìã D·ªØ li·ªáu chi ti·∫øt"
    ])
    
    # Tab 1: Price Prediction
    with tab1:
        st.subheader("üîÆ ∆Ø·ªõc t√≠nh gi√° s·∫£n ph·∫©m (Similarity-Based)")
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.markdown("#### Th√¥ng tin s·∫£n ph·∫©m")
            
            # 1. M√†u ƒë√° (Stone Color) - FIRST per manager's notes
            stone_color = st.selectbox(
                "M√†u ƒë√° (Stone Color)",
                options=[code for code, label in STONE_COLOR_TYPES],
                format_func=lambda x: STONE_COLOR_LOOKUP.get(x, x)
            )
            
            # 2. K√≠ch th∆∞·ªõc (Dimensions) - SECOND
            st.markdown("##### K√≠ch th∆∞·ªõc")
            col_dim1, col_dim2, col_dim3 = st.columns(3)
            with col_dim1:
                length = st.number_input("D√†i (cm)", min_value=0.1, max_value=300.0, value=30.0, step=0.5)
            with col_dim2:
                width = st.number_input("R·ªông (cm)", min_value=0.1, max_value=300.0, value=30.0, step=0.5)
            with col_dim3:
                height = st.number_input("D√†y (cm)", min_value=0.5, max_value=50.0, value=3.0, step=0.5)
            
            # 3. Gia c√¥ng ch√≠nh (Main Processing) - THIRD
            processing_lookup = {code: (eng, vn) for code, eng, vn in PROCESSING_CODES}
            processing_code = st.selectbox(
                "Gia c√¥ng ch√≠nh (Main Processing)",
                options=[code for code, eng, vn in PROCESSING_CODES],
                format_func=lambda x: f"{x} - {processing_lookup.get(x, ('Other', 'Kh√°c'))[0]} ({processing_lookup.get(x, ('Other', 'Kh√°c'))[1]})",
                index=0
            )
            
            # 4. Khu v·ª±c (Region) - FOURTH
            customer_regional_group = st.selectbox(
                "Nh√≥m Khu v·ª±c KH (Regional Group)",
                options=[code for code, name in CUSTOMER_REGIONAL_GROUPS if code],
                format_func=lambda x: x,
                index=0,
                help="Nh√≥m ƒë·∫ßu 0-9 theo khu v·ª±c kh√°ch h√†ng"
            )
            
            # 5. ·ª®ng d·ª•ng (Application) - FIFTH
            application_lookup = {code: name for code, name in APPLICATION_CODES}
            selected_applications = st.multiselect(
                "·ª®ng d·ª•ng s·∫£n ph·∫©m (Application)",
                options=[code for code, name in APPLICATION_CODES],
                format_func=lambda x: application_lookup.get(x, 'Unknown'),
                default=[],
                help="Ch·ªçn m·ªôt ho·∫∑c nhi·ªÅu ·ª©ng d·ª•ng. ƒê·ªÉ tr·ªëng = T·∫•t c·∫£"
            )
            
            # 6. ƒê∆°n v·ªã t√≠nh (Unit) - SIXTH
            charge_unit = st.selectbox("ƒê∆°n v·ªã t√≠nh gi√°", CHARGE_UNITS)
            
            # 7. Ph√¢n lo·∫°i kh√°ch h√†ng (Customer Classification) - SEVENTH
            customer_type = st.selectbox(
                "Ph√¢n lo·∫°i kh√°ch h√†ng",
                ['C', 'A', 'B', 'D', 'E', 'F'],
                format_func=lambda x: f"{x} - {CUSTOMER_PRICING_RULES[x]['description']}"
            )
        
        with col2:
            # 8. M·ª©c ƒë·ªô ∆∞u ti√™n (Priority Levels) - EIGHTH
            st.markdown("#### üéöÔ∏è M·ª©c ƒë·ªô ∆∞u ti√™n t√¨m ki·∫øm")
            
            # Priority level selectors per notes.md
            col_p1, col_p2 = st.columns(2)
            with col_p1:
                stone_priority = st.selectbox(
                    "Lo·∫°i ƒë√°",
                    options=['∆Øu ti√™n 1', '∆Øu ti√™n 2', '∆Øu ti√™n 3'],
                    format_func=lambda x: {
                        '∆Øu ti√™n 1': '1 - ƒê√∫ng m√†u ƒë√°',
                        '∆Øu ti√™n 2': '2 - C√πng ch·ªßng lo·∫°i',
                        '∆Øu ti√™n 3': '3 - T·∫•t c·∫£ lo·∫°i ƒë√°',
                    }[x],
                    index=0  # Default: ∆Øu ti√™n 1 (ƒê√∫ng m√†u ƒë√°)
                )
                processing_priority = st.selectbox(
                    "Gia c√¥ng",
                    options=['∆Øu ti√™n 1', '∆Øu ti√™n 2', '∆Øu ti√™n 3'],
                    format_func=lambda x: {
                        '∆Øu ti√™n 1': '1 - ƒê√∫ng lo·∫°i gia c√¥ng',
                        '∆Øu ti√™n 2': '2 - ƒê√∫ng nh√≥m gia c√¥ng',
                        '∆Øu ti√™n 3': '3 - T·∫•t c·∫£ gia c√¥ng',
                    }[x],
                    index=1  # Default: ∆Øu ti√™n 2
                )
                # Show Processing Group dropdown when Priority 2 is selected
                selected_processing_group = None
                if processing_priority == '∆Øu ti√™n 2':
                    # Get default group for current processing code
                    default_group = PROCESSING_CODE_TO_GROUP.get(processing_code, 'GIA_CONG_MAY')
                    group_options = list(PROCESSING_GROUP_NAMES.keys())
                    default_index = group_options.index(default_group) if default_group in group_options else 0
                    
                    selected_processing_group = st.selectbox(
                        "Ch·ªçn nh√≥m gia c√¥ng",
                        options=group_options,
                        format_func=lambda x: f"{PROCESSING_GROUP_NAMES.get(x, x)} ({', '.join(PROCESSING_GROUPS.get(x, []))})",
                        index=default_index,
                        help="L·ªçc theo nh√≥m gia c√¥ng thay v√¨ lo·∫°i gia c√¥ng c·ª• th·ªÉ"
                    )
            with col_p2:
                dimension_priority = st.selectbox(
                    "K√≠ch th∆∞·ªõc",
                    options=list(DIMENSION_PRIORITY_LEVELS.keys()),
                    index=0  # Default: ∆Øu ti√™n 1 (ƒê√∫ng k√≠ch th∆∞·ªõc)
                )
                # Show "unlimited length" checkbox when Priority 3 is selected
                no_length_limit = False
                if '∆Øu ti√™n 3' in dimension_priority:
                    no_length_limit = st.checkbox(
                        "Kh√¥ng gi·ªõi h·∫°n chi·ªÅu d√†i",
                        value=False,
                        help="B·ªè gi·ªõi h·∫°n chi·ªÅu d√†i khi t√¨m ki·∫øm s·∫£n ph·∫©m t∆∞∆°ng t·ª±"
                    )
                
                region_priority = st.selectbox(
                    "Th·ªã tr∆∞·ªùng",
                    options=['∆Øu ti√™n 1', '∆Øu ti√™n 2', '∆Øu ti√™n 3'],
                    format_func=lambda x: {
                        '∆Øu ti√™n 1': '1 - ƒê√∫ng n∆∞·ªõc (Billing)',
                        '∆Øu ti√™n 2': '2 - ƒê√∫ng nh√≥m KH',
                        '∆Øu ti√™n 3': '3 - T·∫•t c·∫£ th·ªã tr∆∞·ªùng',
                    }[x],
                    index=2  # Default: ∆Øu ti√™n 3 
                )
            
            # Dynamic Market selector based on region_priority
            billing_country_selected = None
            regional_group_selected = customer_regional_group  # Use the existing regional group selection
            
            if region_priority == '∆Øu ti√™n 1':
                # Get unique billing countries from data
                billing_countries = ['']
                if st.session_state.data is not None and 'billing_country' in st.session_state.data.columns:
                    unique_countries = st.session_state.data['billing_country'].dropna().unique().tolist()
                    billing_countries = [''] + sorted([c for c in unique_countries if c])
                billing_country_selected = st.selectbox(
                    "Ch·ªçn n∆∞·ªõc (Billing Country)",
                    options=billing_countries,
                    format_func=lambda x: 'T·∫•t c·∫£' if x == '' else x,
                    help="L·ªçc theo qu·ªëc gia trong ƒë·ªãa ch·ªâ thanh to√°n"
                )
            
            st.divider()
            st.markdown("#### üìÖ C√†i ƒë·∫∑t t√≠nh to√°n gi√°")
            use_recent_only = st.checkbox(
                "Ch·ªâ s·ª≠ d·ª•ng d·ªØ li·ªáu g·∫ßn nh·∫•t",
                value=True,
                help="Ch·ªâ s·ª≠ d·ª•ng N s·∫£n ph·∫©m g·∫ßn nh·∫•t (theo nƒÉm t√†i ch√≠nh) ƒë·ªÉ ∆∞·ªõc t√≠nh gi√° ch√≠nh x√°c h∆°n. N√™n ƒë·∫∑t t·ª´ 5 ƒë·∫øn 10 s·∫£n ph·∫©m tham kh·∫£o!"
            )
            recent_count = st.number_input(
                "S·ªë l∆∞·ª£ng s·∫£n ph·∫©m tham kh·∫£o",
                min_value=5,
                max_value=35,
                value=10,
                step=5,
                help="S·ªë l∆∞·ª£ng s·∫£n ph·∫©m g·∫ßn nh·∫•t s·ª≠ d·ª•ng ƒë·ªÉ ∆∞·ªõc t√≠nh gi√°. N√™n ƒë·∫∑t t·ª´ 5 ƒë·∫øn 10 s·∫£n ph·∫©m tham kh·∫£o!",
                disabled=not use_recent_only
            )
            
            # Yearly price adjustment per manager's notes
            st.markdown("##### üìà ƒêi·ªÅu ch·ªânh gi√° theo nƒÉm")
            apply_yearly_adjustment = st.checkbox(
                "√Åp d·ª•ng ƒëi·ªÅu ch·ªânh gi√° theo nƒÉm",
                value=True,
                help="T·ª∑ l·ªá tƒÉng gi√° h√†ng nƒÉm do chi ph√≠ nguy√™n v·∫≠t li·ªáu v√† nh√¢n c√¥ng (th∆∞·ªùng 3-5%) ho·∫∑c ƒëi·ªÅu ch·ªânh theo l·∫°m ph√°t. Xem th√™m [t·∫°i ƒë√¢y](https://www.tradingview.com/markets/world-economy/charts-global-trends/)"
            )
            yearly_increase_pct = st.slider(
                "T·ª∑ l·ªá tƒÉng gi√° h√†ng nƒÉm (%)",
                min_value=0.0,
                max_value=10.0,
                value=0.5,
                step=0.5,
                format="%.1f%%",
                disabled=not apply_yearly_adjustment
            )
            
            predict_btn = st.button("üîç T√¨m ki·∫øm & ∆Ø·ªõc t√≠nh gi√°", type="primary", use_container_width=True)
        
        # ============ FULL WIDTH RESULTS SECTION ============
        if predict_btn and st.session_state.model is not None:
            st.divider()
            
            # Use similarity-based predictor
            predictor = st.session_state.model
            
            matches = predictor.find_matching_products(
                stone_color_type=stone_color,
                processing_code=processing_code,
                length_cm=length,
                width_cm=width,
                height_cm=height,
                application_codes=selected_applications,
                customer_regional_group=regional_group_selected,
                charge_unit=charge_unit,
                stone_priority=stone_priority,
                processing_priority=processing_priority,
                dimension_priority=dimension_priority,
                region_priority=region_priority,
                no_length_limit=no_length_limit,
                billing_country=billing_country_selected,
                selected_processing_group=selected_processing_group,
            )
            
            # Store matches in session state to persist across reruns
            st.session_state.last_matches = matches.copy()
            
            estimation = predictor.estimate_price(
                matches, 
                use_recent_only=use_recent_only, 
                recent_count=recent_count,
                query_length_cm=length,
                query_width_cm=width,
                query_height_cm=height,
                target_charge_unit=charge_unit,
                stone_color_type=stone_color,
                processing_code=processing_code
            )
            
            # Store estimation and query params in session state to persist across reruns
            st.session_state.last_estimation = estimation.copy()
            st.session_state.last_query_params = {
                'stone_color': stone_color,
                'length': length,
                'width': width,
                'height': height,
                'processing_code': processing_code,
                'regional_group': customer_regional_group,
                'applications': selected_applications,
                'charge_unit': charge_unit,
                'customer_type': customer_type,
                'use_recent_only': use_recent_only,
                'recent_count': recent_count,
                'apply_yearly_adjustment': apply_yearly_adjustment,
                'yearly_increase_pct': yearly_increase_pct,
            }
            
            st.markdown("#### üìä K·∫øt qu·∫£ ∆∞·ªõc t√≠nh")
            
            if estimation['estimated_price'] is not None:
                # Confidence indicator
                confidence_colors = {
                    'high': '#6bcb77',
                    'medium': '#ffd93d',
                    'low': '#ff6b6b',
                    'very_low': '#9e7cc1',
                }
                confidence_labels = {
                    'high': 'Cao (‚â•10 m·∫´u)',
                    'medium': 'Trung b√¨nh (5-9 m·∫´u)',
                    'low': 'Th·∫•p (2-4 m·∫´u)',
                    'very_low': 'R·∫•t th·∫•p (1 m·∫´u)',
                }
                conf_color = confidence_colors.get(estimation['confidence'], '#808080')
                conf_label = confidence_labels.get(estimation['confidence'], 'N/A')
                
                st.markdown(f"""
                <div style="background-color: {conf_color}; padding: 15px; border-radius: 10px; text-align: center; margin-bottom: 20px;">
                    <h3 style="color: white; margin: 0;">ƒê·ªô tin c·∫≠y: {conf_label}</h3>
                </div>
                """, unsafe_allow_html=True)
                
                # Main estimated price
                st.metric(f"üí∞ Gi√° ∆∞·ªõc t√≠nh ({charge_unit})", f"${estimation['estimated_price']:,.2f}")
                
                # Apply yearly price adjustment if enabled
                if apply_yearly_adjustment and yearly_increase_pct > 0:
                    # Calculate average year of matched products
                    current_year = datetime.now().year
                    avg_fy_year = estimation.get('avg_fy_year', current_year)
                    if avg_fy_year and avg_fy_year < current_year:
                        years_diff = current_year - int(avg_fy_year)
                        adjustment_factor = (1 + yearly_increase_pct / 100) ** years_diff
                        adjusted_price = estimation['estimated_price'] * adjustment_factor
                        adjusted_min = estimation['min_price'] * adjustment_factor
                        adjusted_max = estimation['max_price'] * adjustment_factor
                        
                        st.markdown(f"**üíµ Gi√° ƒëi·ªÅu ch·ªânh ({current_year}):** **\\${adjusted_price:,.2f}** (+{yearly_increase_pct:.1f}% √ó {years_diff} nƒÉm)")
                        st.markdown(f"Kho·∫£ng gi√° ƒëi·ªÅu ch·ªânh: **\\${adjusted_min:,.2f}** ‚Äì **\\${adjusted_max:,.2f}**")
                    else:
                        st.markdown(f"Kho·∫£ng gi√° th·ª±c t·∫ø: **\\${estimation['min_price']:,.2f}** ‚Äì **\\${estimation['max_price']:,.2f}**")
                else:
                    # Price range (no adjustment)
                    st.markdown(f"Kho·∫£ng gi√° th·ª±c t·∫ø: **\\${estimation['min_price']:,.2f}** ‚Äì **\\${estimation['max_price']:,.2f}**")
                
                st.markdown(f"**Gi√° trung v·ªã:** ${estimation['median_price']:,.2f}")
                
                # Show match count info with years if using recent only
                if use_recent_only and estimation.get('total_matches', 0) > estimation['match_count']:
                    st.markdown(f"**S·ªë m·∫´u kh·ªõp:** {estimation['match_count']} / {estimation['total_matches']} (s·ª≠ d·ª•ng {estimation['match_count']} m·∫´u g·∫ßn nh·∫•t)")
                    if estimation.get('years_used'):
                        st.markdown(f"**NƒÉm tham kh·∫£o:** {estimation['years_used']}")
                else:
                    st.markdown(f"**S·ªë m·∫´u kh·ªõp:** {estimation['match_count']}")
                
                # Show price trend if available
                if estimation.get('price_trend') and estimation.get('trend_pct') is not None:
                    trend_pct = estimation['trend_pct']
                    if estimation['price_trend'] == 'up':
                        st.markdown(f"üìà **Xu h∆∞·ªõng gi√°:** TƒÉng **+{abs(trend_pct):.1f}%** so v·ªõi nƒÉm tr∆∞·ªõc")
                    elif estimation['price_trend'] == 'down':
                        st.markdown(f"üìâ **Xu h∆∞·ªõng gi√°:** Gi·∫£m **-{abs(trend_pct):.1f}%** so v·ªõi nƒÉm tr∆∞·ªõc")
                    else:
                        st.markdown(f"‚û°Ô∏è **Xu h∆∞·ªõng gi√°:** ·ªîn ƒë·ªãnh")
                
                st.divider()
                
                # Calculate segment for pricing (use first selected application or empty for classify_segment)
                first_app = selected_applications[0] if selected_applications else ''
                est_price_m3 = convert_price(
                    estimation['estimated_price'], charge_unit, 'USD/M3',
                    height_cm=height, length_cm=length, width_cm=width,
                    tlr=get_tlr(stone_color, processing_code)
                )
                segment = classify_segment(est_price_m3, height_cm=height, family=first_app, processing_code=processing_code)
                
                # Customer price adjustment with segment awareness
                price_info = calculate_customer_price(
                    estimation['estimated_price'], customer_type, 
                    segment=segment, charge_unit=charge_unit
                )
                st.markdown(f"**üë§ Gi√° theo kh√°ch h√†ng lo·∫°i {customer_type}:**")
                st.markdown(f"- {price_info['customer_description']}")
                st.markdown(f"- Kho·∫£ng gi√°: **\\${price_info['min_price']:,.2f}** ‚Äì **\\${price_info['max_price']:,.2f}**")
                st.markdown(f"- ƒêi·ªÅu ch·ªânh: {price_info['adjustment_label']}")
                st.markdown(f"- Quy·ªÅn t·ª± quy·∫øt: {price_info['authority_range']}")
                
                # Export Report Button
                st.divider()
                st.markdown("#### üìÑ Xu·∫•t b√°o c√°o")
                
                # Prepare query params for report
                query_params = {
                    'stone_color': stone_color,
                    'length': length,
                    'width': width,
                    'height': height,
                    'processing_code': processing_code,
                    'regional_group': customer_regional_group,
                    'applications': selected_applications,
                    'charge_unit': charge_unit,
                    'customer_type': customer_type,
                }
                
                # Prepare yearly adjustment info
                yearly_adj_info = None
                if apply_yearly_adjustment and yearly_increase_pct > 0:
                    current_year = datetime.now().year
                    avg_fy_year = estimation.get('avg_fy_year', current_year)
                    if avg_fy_year and avg_fy_year < current_year:
                        years_diff = current_year - int(avg_fy_year)
                        adjustment_factor = (1 + yearly_increase_pct / 100) ** years_diff
                        adjusted_price = estimation['estimated_price'] * adjustment_factor
                        yearly_adj_info = {
                            'applied': True,
                            'rate': yearly_increase_pct,
                            'avg_year': avg_fy_year,
                            'years_diff': years_diff,
                            'adjusted_price': adjusted_price,
                        }
                
                # Generate HTML report
                report_html = generate_price_report(
                    query_params=query_params,
                    estimation=estimation,
                    matched_products=matches,
                    customer_price_info=price_info,
                    yearly_adjustment=yearly_adj_info
                )
                
                st.download_button(
                    label="üì• T·∫£i b√°o c√°o (HTML/PDF)",
                    data=report_html,
                    file_name=f"stone_price_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html",
                    mime="text/html",
                    help="T·∫£i b√°o c√°o HTML. M·ªü v√† in (Ctrl+P) ƒë·ªÉ l∆∞u PDF."
                )
                    
            else:
                # Get detailed diagnostics for why no matches found
                diagnostics = predictor.get_match_diagnostics(
                    stone_color_type=stone_color,
                    processing_code=processing_code,
                    length_cm=length,
                    width_cm=width,
                    height_cm=height,
                    application_codes=selected_applications,
                    customer_regional_group=regional_group_selected,
                    charge_unit=charge_unit,
                    stone_priority=stone_priority,
                    processing_priority=processing_priority,
                    dimension_priority=dimension_priority,
                    region_priority=region_priority,
                    no_length_limit=no_length_limit,
                    billing_country=billing_country_selected,
                )
                
                st.warning(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m ph√π h·ª£p")
                
                if diagnostics.get('reason'):
                    st.error(f"**L√Ω do:** {diagnostics['reason']}")
                
                if diagnostics.get('suggestions'):
                    st.info("**üí° G·ª£i √Ω:**\n" + "\n".join([f"‚Ä¢ {s}" for s in diagnostics['suggestions']]))
            
            # Product info summary with weight calculation (always show after search)
            st.divider()
            st.markdown("**üì¶ Th√¥ng tin s·∫£n ph·∫©m:**")
            volume_m3 = calculate_volume_m3(length, width, height)
            area_m2 = calculate_area_m2(length, width)
            tlr = get_tlr(stone_color, processing_code)
            first_app = selected_applications[0] if selected_applications else ''
            hs = get_hs_factor((length, width, height), processing_code, first_app)
            weight_tons = calculate_weight_tons(volume_m3, stone_color, processing_code, (length, width, height), first_app)
            
            col_info1, col_info2 = st.columns(2)
            with col_info1:
                st.markdown(f"- K√≠ch th∆∞·ªõc: {length} x {width} x {height} cm")
                st.markdown(f"- Th·ªÉ t√≠ch: {volume_m3:.6f} m¬≥")
                st.markdown(f"- Di·ªán t√≠ch: {area_m2:.4f} m¬≤")
            with col_info2:
                st.markdown(f"- TLR: {tlr} t·∫•n/m¬≥")
                st.markdown(f"- HS: {hs}")
                st.markdown(f"- Kh·ªëi l∆∞·ª£ng: **{weight_tons:.4f} t·∫•n**")
        
        # ============ SHOW PERSISTED ESTIMATION RESULTS (when page reruns e.g. checkbox click) ============
        # Show estimation results from session state when predict_btn is not pressed but we have cached results
        if not predict_btn and 'last_estimation' in st.session_state and st.session_state.last_estimation is not None:
            estimation = st.session_state.last_estimation
            query_params = st.session_state.get('last_query_params', {})
            
            # Only show if we have a valid estimation
            if estimation.get('estimated_price') is not None:
                st.divider()
                st.markdown("#### üìä K·∫øt qu·∫£ ∆∞·ªõc t√≠nh")
                
                # Confidence indicator
                confidence_colors = {
                    'high': '#6bcb77',
                    'medium': '#ffd93d',
                    'low': '#ff6b6b',
                    'very_low': '#9e7cc1',
                }
                confidence_labels = {
                    'high': 'Cao (‚â•10 m·∫´u)',
                    'medium': 'Trung b√¨nh (5-9 m·∫´u)',
                    'low': 'Th·∫•p (2-4 m·∫´u)',
                    'very_low': 'R·∫•t th·∫•p (1 m·∫´u)',
                }
                conf_color = confidence_colors.get(estimation.get('confidence', ''), '#808080')
                conf_label = confidence_labels.get(estimation.get('confidence', ''), 'N/A')
                
                st.markdown(f"""
                <div style="background-color: {conf_color}; padding: 15px; border-radius: 10px; text-align: center; margin-bottom: 20px;">
                    <h3 style="color: white; margin: 0;">ƒê·ªô tin c·∫≠y: {conf_label}</h3>
                </div>
                """, unsafe_allow_html=True)
                
                # Main estimated price
                cached_charge_unit = query_params.get('charge_unit', charge_unit)
                st.metric(f"üí∞ Gi√° ∆∞·ªõc t√≠nh ({cached_charge_unit})", f"${estimation['estimated_price']:,.2f}")
                
                # Apply yearly price adjustment if enabled (use current sidebar settings)
                if apply_yearly_adjustment and yearly_increase_pct > 0:
                    current_year = datetime.now().year
                    avg_fy_year = estimation.get('avg_fy_year', current_year)
                    if avg_fy_year and avg_fy_year < current_year:
                        years_diff = current_year - int(avg_fy_year)
                        adjustment_factor = (1 + yearly_increase_pct / 100) ** years_diff
                        adjusted_price = estimation['estimated_price'] * adjustment_factor
                        adjusted_min = estimation['min_price'] * adjustment_factor
                        adjusted_max = estimation['max_price'] * adjustment_factor
                        
                        st.markdown(f"**üíµ Gi√° ƒëi·ªÅu ch·ªânh ({current_year}):** **\\${adjusted_price:,.2f}** (+{yearly_increase_pct:.1f}% √ó {years_diff} nƒÉm)")
                        st.markdown(f"Kho·∫£ng gi√° ƒëi·ªÅu ch·ªânh: **\\${adjusted_min:,.2f}** ‚Äì **\\${adjusted_max:,.2f}**")
                    else:
                        st.markdown(f"Kho·∫£ng gi√° th·ª±c t·∫ø: **\\${estimation['min_price']:,.2f}** ‚Äì **\\${estimation['max_price']:,.2f}**")
                else:
                    st.markdown(f"Kho·∫£ng gi√° th·ª±c t·∫ø: **\\${estimation['min_price']:,.2f}** ‚Äì **\\${estimation['max_price']:,.2f}**")
                
                st.markdown(f"**Gi√° trung v·ªã:** ${estimation.get('median_price', estimation['estimated_price']):,.2f}")
                
                # Show match count info
                use_recent = query_params.get('use_recent_only', use_recent_only)
                if use_recent and estimation.get('total_matches', 0) > estimation.get('match_count', 0):
                    st.markdown(f"**S·ªë m·∫´u kh·ªõp:** {estimation['match_count']} / {estimation['total_matches']} (s·ª≠ d·ª•ng {estimation['match_count']} m·∫´u g·∫ßn nh·∫•t)")
                    if estimation.get('years_used'):
                        st.markdown(f"**NƒÉm tham kh·∫£o:** {estimation['years_used']}")
                else:
                    st.markdown(f"**S·ªë m·∫´u kh·ªõp:** {estimation.get('match_count', 0)}")
                
                # Show price trend if available
                if estimation.get('price_trend') and estimation.get('trend_pct') is not None:
                    trend_pct = estimation['trend_pct']
                    if estimation['price_trend'] == 'up':
                        st.markdown(f"üìà **Xu h∆∞·ªõng gi√°:** TƒÉng **+{abs(trend_pct):.1f}%** so v·ªõi nƒÉm tr∆∞·ªõc")
                    elif estimation['price_trend'] == 'down':
                        st.markdown(f"üìâ **Xu h∆∞·ªõng gi√°:** Gi·∫£m **-{abs(trend_pct):.1f}%** so v·ªõi nƒÉm tr∆∞·ªõc")
                    else:
                        st.markdown(f"‚û°Ô∏è **Xu h∆∞·ªõng gi√°:** ·ªîn ƒë·ªãnh")
                
                st.divider()
                
                # Calculate segment for pricing (use current sidebar settings)
                first_app = selected_applications[0] if selected_applications else ''
                cached_height = query_params.get('height', height)
                cached_length = query_params.get('length', length)
                cached_width = query_params.get('width', width)
                cached_stone_color = query_params.get('stone_color', stone_color)
                cached_processing_code = query_params.get('processing_code', processing_code)
                
                est_price_m3 = convert_price(
                    estimation['estimated_price'], cached_charge_unit, 'USD/M3',
                    height_cm=cached_height, length_cm=cached_length, width_cm=cached_width,
                    tlr=get_tlr(cached_stone_color, cached_processing_code)
                )
                segment = classify_segment(est_price_m3, height_cm=cached_height, family=first_app, processing_code=cached_processing_code)
                
                # Customer price adjustment with segment awareness (use current customer_type from sidebar)
                price_info = calculate_customer_price(
                    estimation['estimated_price'], customer_type, 
                    segment=segment, charge_unit=cached_charge_unit
                )
                st.markdown(f"**üë§ Gi√° theo kh√°ch h√†ng lo·∫°i {customer_type}:**")
                st.markdown(f"- {price_info['customer_description']}")
                st.markdown(f"- Kho·∫£ng gi√°: **\\${price_info['min_price']:,.2f}** ‚Äì **\\${price_info['max_price']:,.2f}**")
                st.markdown(f"- ƒêi·ªÅu ch·ªânh: {price_info['adjustment_label']}")
                st.markdown(f"- Quy·ªÅn t·ª± quy·∫øt: {price_info['authority_range']}")
                
                # Product info summary
                st.divider()
                st.markdown("**üì¶ Th√¥ng tin s·∫£n ph·∫©m:**")
                volume_m3 = calculate_volume_m3(cached_length, cached_width, cached_height)
                area_m2 = calculate_area_m2(cached_length, cached_width)
                tlr = get_tlr(cached_stone_color, cached_processing_code)
                hs = get_hs_factor((cached_length, cached_width, cached_height), cached_processing_code, first_app)
                weight_tons = calculate_weight_tons(volume_m3, cached_stone_color, cached_processing_code, (cached_length, cached_width, cached_height), first_app)
                
                col_info1, col_info2 = st.columns(2)
                with col_info1:
                    st.markdown(f"- K√≠ch th∆∞·ªõc: {cached_length} x {cached_width} x {cached_height} cm")
                    st.markdown(f"- Th·ªÉ t√≠ch: {volume_m3:.6f} m¬≥")
                    st.markdown(f"- Di·ªán t√≠ch: {area_m2:.4f} m¬≤")
                with col_info2:
                    st.markdown(f"- TLR: {tlr} t·∫•n/m¬≥")
                    st.markdown(f"- HS: {hs}")
                    st.markdown(f"- Kh·ªëi l∆∞·ª£ng: **{weight_tons:.4f} t·∫•n**")
        
        # ============ MATCHING PRODUCTS (Full Width) ============
        # Show matching products if we have stored matches from session state
        # This allows the table to persist when checkboxes are clicked (avoiding reload reset)
        if 'last_matches' in st.session_state and st.session_state.last_matches is not None and len(st.session_state.last_matches) > 0:
            matches = st.session_state.last_matches
            st.divider()
            st.markdown("#### üìã S·∫£n ph·∫©m trong h·ªá th·ªëng kh·ªõp ti√™u ch√≠")
            
            st.success(f"‚úÖ T√¨m th·∫•y **{len(matches)}** s·∫£n ph·∫©m kh·ªõp ti√™u ch√≠!")
            
            # Statistics
            match_prices = matches['sales_price']
            stat_col1, stat_col2, stat_col3, stat_col4 = st.columns(4)
            with stat_col1:
                st.metric("Th·∫•p nh·∫•t", f"${match_prices.min():,.2f}")
            with stat_col2:
                st.metric("Cao nh·∫•t", f"${match_prices.max():,.2f}")
            with stat_col3:
                st.metric("Trung b√¨nh", f"${match_prices.mean():,.2f}")
            with stat_col4:
                st.metric("Trung v·ªã", f"${match_prices.median():,.2f}")
            
            # Show table of ALL matches with Regional Group included
            display_cols = [
                'contract_product_name', 'contract_name', 'account_code',
                'customer_regional_group',  # Regional Group now visible
                'billing_country',  # Billing Country from Account.BillingAddress
                'sku', 'application_code', 'application',
                'processing_code', 'processing_name',
                'stone_color_type', 'segment',
                'length_cm', 'width_cm', 'height_cm',
                'charge_unit', 'sales_price', 'price_m3',
                'created_date', 'fy_year',
            ]
            available_cols = [col for col in display_cols if col in matches.columns]
            
            # Column config for headers
            col_config = {
                'select': st.column_config.CheckboxColumn('Ch·ªçn', default=False, help='Ch·ªçn s·∫£n ph·∫©m ƒë·ªÉ t√≠nh gi√°'),
                'sku': st.column_config.TextColumn('SKU'),
                'stone_color_type': st.column_config.TextColumn('Stone Color'),
                'application_code': st.column_config.TextColumn('App Code'),
                'application': st.column_config.TextColumn('Application'),
                'processing_code': st.column_config.TextColumn('Main Processing Code'),
                'processing_name': st.column_config.TextColumn('Main Processing'),
                'customer_regional_group': st.column_config.TextColumn('Regional Group'),
                'billing_country': st.column_config.TextColumn('Billing Country'),
                'sales_price': st.column_config.NumberColumn('Sales Price', format="$%.2f"),
                'price_m3': st.column_config.NumberColumn('Price/m¬≥', format="$%.2f"),
            }
            
            with st.expander(f"üìã Ch·ªçn s·∫£n ph·∫©m ƒë·ªÉ t√≠nh gi√° ({len(matches)} s·∫£n ph·∫©m kh·ªõp)", expanded=True):
                st.info("üí° **Ch·ªçn √≠t nh·∫•t 3 s·∫£n ph·∫©m** ƒë·ªÉ t√≠nh gi√° ch√≠nh x√°c h∆°n. B·∫•m 'T√≠nh l·∫°i gi√°' sau khi ch·ªçn.")
                
                # Add checkbox column for selection
                matches_display = matches[available_cols].copy()
                matches_display.insert(0, 'select', False)  # Add selection column at start
                
                # Use data_editor for editable checkboxes
                edited_df = st.data_editor(
                    matches_display, 
                    use_container_width=True, 
                    height=350, 
                    column_config=col_config,
                    hide_index=True,
                    key="product_selection_table"
                )
                
                # Calculate price from selected records
                selected_rows = edited_df[edited_df['select'] == True]
                selected_count = len(selected_rows)
                
                col_select_info, col_recalc = st.columns([2, 1])
                with col_select_info:
                    if selected_count == 0:
                        st.warning("‚ö†Ô∏è Ch∆∞a ch·ªçn s·∫£n ph·∫©m n√†o")
                    elif selected_count < 3:
                        st.warning(f"‚ö†Ô∏è ƒê√£ ch·ªçn {selected_count}/3 s·∫£n ph·∫©m (c·∫ßn t·ªëi thi·ªÉu 3)")
                    else:
                        st.success(f"‚úÖ ƒê√£ ch·ªçn {selected_count} s·∫£n ph·∫©m")
                
                with col_recalc:
                    recalc_btn = st.button("üîÑ T√≠nh l·∫°i gi√° t·ª´ s·∫£n ph·∫©m ƒë√£ ch·ªçn", disabled=(selected_count < 3))
                
                # Recalculate price from selected records
                if recalc_btn and selected_count >= 3:
                    selected_prices = selected_rows['sales_price']
                    
                    # Calculate average FY year from selected products for yearly adjustment
                    avg_fy_year = None
                    if 'fy_year' in selected_rows.columns:
                        fy_years = pd.to_numeric(selected_rows['fy_year'], errors='coerce').dropna()
                        if len(fy_years) > 0:
                            avg_fy_year = int(fy_years.mean())
                    
                    manual_estimation = {
                        'estimated_price': selected_prices.mean(),
                        'min_price': selected_prices.min(),
                        'max_price': selected_prices.max(),
                        'median_price': selected_prices.median(),
                        'match_count': selected_count,
                        'avg_fy_year': avg_fy_year,
                        'total_matches': len(matches),
                    }
                    
                    st.divider()
                    st.markdown("#### üìä K·∫øt qu·∫£ t√≠nh gi√° t·ª´ s·∫£n ph·∫©m ƒë√£ ch·ªçn")
                    
                    # Main estimated price
                    st.metric(f"üí∞ Gi√° trung b√¨nh ({charge_unit})", f"${manual_estimation['estimated_price']:,.2f}")
                    
                    # Apply yearly price adjustment if enabled
                    if apply_yearly_adjustment and yearly_increase_pct > 0:
                        current_year = datetime.now().year
                        if avg_fy_year and avg_fy_year < current_year:
                            years_diff = current_year - int(avg_fy_year)
                            adjustment_factor = (1 + yearly_increase_pct / 100) ** years_diff
                            adjusted_price = manual_estimation['estimated_price'] * adjustment_factor
                            adjusted_min = manual_estimation['min_price'] * adjustment_factor
                            adjusted_max = manual_estimation['max_price'] * adjustment_factor
                            
                            st.markdown(f"**üíµ Gi√° ƒëi·ªÅu ch·ªânh ({current_year}):** **\\${adjusted_price:,.2f}** (+{yearly_increase_pct:.1f}% √ó {years_diff} nƒÉm)")
                            st.markdown(f"Kho·∫£ng gi√° ƒëi·ªÅu ch·ªânh: **\\${adjusted_min:,.2f}** ‚Äì **\\${adjusted_max:,.2f}**")
                        else:
                            st.markdown(f"Kho·∫£ng gi√° th·ª±c t·∫ø: **\\${manual_estimation['min_price']:,.2f}** ‚Äì **\\${manual_estimation['max_price']:,.2f}**")
                    else:
                        st.markdown(f"Kho·∫£ng gi√° th·ª±c t·∫ø: **\\${manual_estimation['min_price']:,.2f}** ‚Äì **\\${manual_estimation['max_price']:,.2f}**")
                    
                    st.markdown(f"**Gi√° trung v·ªã:** ${manual_estimation['median_price']:,.2f}")
                    st.markdown(f"**S·ªë m·∫´u:** {manual_estimation['match_count']} s·∫£n ph·∫©m ƒë∆∞·ª£c ch·ªçn")
                    
                    st.divider()
                    
                    # Calculate segment for pricing
                    first_app = selected_applications[0] if selected_applications else ''
                    est_price_m3 = convert_price(
                        manual_estimation['estimated_price'], charge_unit, 'USD/M3',
                        height_cm=height, length_cm=length, width_cm=width,
                        tlr=get_tlr(stone_color, processing_code)
                    )
                    segment = classify_segment(est_price_m3, height_cm=height, family=first_app, processing_code=processing_code)
                    
                    # Customer price adjustment with segment awareness
                    price_info = calculate_customer_price(
                        manual_estimation['estimated_price'], customer_type, 
                        segment=segment, charge_unit=charge_unit
                    )
                    st.markdown(f"**üë§ Gi√° theo kh√°ch h√†ng lo·∫°i {customer_type}:**")
                    st.markdown(f"- {price_info['customer_description']}")
                    st.markdown(f"- Kho·∫£ng gi√°: **\\${price_info['min_price']:,.2f}** ‚Äì **\\${price_info['max_price']:,.2f}**")
                    st.markdown(f"- ƒêi·ªÅu ch·ªânh: {price_info['adjustment_label']}")
                    st.markdown(f"- Quy·ªÅn t·ª± quy·∫øt: {price_info['authority_range']}")
                    
                    # Export Report Button
                    st.divider()
                    st.markdown("#### üìÑ Xu·∫•t b√°o c√°o")
                    
                    # Prepare query params for report
                    query_params = {
                        'stone_color': stone_color,
                        'length': length,
                        'width': width,
                        'height': height,
                        'processing_code': processing_code,
                        'regional_group': customer_regional_group,
                        'applications': selected_applications,
                        'charge_unit': charge_unit,
                        'customer_type': customer_type,
                    }
                    
                    # Prepare yearly adjustment info
                    yearly_adj_info = None
                    if apply_yearly_adjustment and yearly_increase_pct > 0:
                        current_year = datetime.now().year
                        if avg_fy_year and avg_fy_year < current_year:
                            years_diff = current_year - int(avg_fy_year)
                            adjustment_factor = (1 + yearly_increase_pct / 100) ** years_diff
                            adjusted_price = manual_estimation['estimated_price'] * adjustment_factor
                            yearly_adj_info = {
                                'applied': True,
                                'rate': yearly_increase_pct,
                                'avg_year': avg_fy_year,
                                'years_diff': years_diff,
                                'adjusted_price': adjusted_price,
                            }
                    
                    # Generate HTML report (use selected products only)
                    selected_matches = matches[matches.index.isin(selected_rows.index)]
                    report_html = generate_price_report(
                        query_params=query_params,
                        estimation=manual_estimation,
                        matched_products=selected_matches,
                        customer_price_info=price_info,
                        yearly_adjustment=yearly_adj_info
                    )
                    
                    st.download_button(
                        label="üì• T·∫£i b√°o c√°o (HTML/PDF)",
                        data=report_html,
                        file_name=f"stone_price_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html",
                        mime="text/html",
                        help="T·∫£i b√°o c√°o HTML. M·ªü v√† in (Ctrl+P) ƒë·ªÉ l∆∞u PDF."
                    )
                    
                    # Product info summary
                    st.divider()
                    st.markdown("**üì¶ Th√¥ng tin s·∫£n ph·∫©m:**")
                    volume_m3 = calculate_volume_m3(length, width, height)
                    area_m2 = calculate_area_m2(length, width)
                    tlr = get_tlr(stone_color, processing_code)
                    hs = get_hs_factor((length, width, height), processing_code, first_app)
                    weight_tons = calculate_weight_tons(volume_m3, stone_color, processing_code, (length, width, height), first_app)
                    
                    col_info1, col_info2 = st.columns(2)
                    with col_info1:
                        st.markdown(f"- K√≠ch th∆∞·ªõc: {length} x {width} x {height} cm")
                        st.markdown(f"- Th·ªÉ t√≠ch: {volume_m3:.6f} m¬≥")
                        st.markdown(f"- Di·ªán t√≠ch: {area_m2:.4f} m¬≤")
                    with col_info2:
                        st.markdown(f"- TLR: {tlr} t·∫•n/m¬≥")
                        st.markdown(f"- HS: {hs}")
                        st.markdown(f"- Kh·ªëi l∆∞·ª£ng: **{weight_tons:.4f} t·∫•n**")
        
        elif predict_btn and st.session_state.model is None:
            st.warning("‚ö†Ô∏è Vui l√≤ng chu·∫©n b·ªã t√¨m ki·∫øm tr∆∞·ªõc (n√∫t üîç ·ªü sidebar)")
        
        # ============ REFERENCE MATERIALS (Full Width, Always at End) ============
        st.divider()
        st.markdown("#### üìñ T√†i li·ªáu tham kh·∫£o")
        
        with st.expander("üîß Nh√≥m gia c√¥ng (Priority 2)"):
            st.markdown("""
**Nh√≥m gia c√¥ng theo c√°ch x·ª≠ l√Ω:**

| Nh√≥m | M√£ gia c√¥ng | M√¥ t·∫£ |
|------|-------------|-------|
| **Gia c√¥ng Tay** | CTA, TLO, TDE | Ch·∫ª tay, T·ª± nhi√™n l·ªìi, T∆∞·ªõc ƒë·∫Ωo |
| **Gia c√¥ng M√°y + Tay** | CUA, CLO, QME, GCT | C∆∞a, C∆∞a l·ªôt, Quay m·∫ª, Gi·∫£ c·ªï tay |
| **Gia c√¥ng M√°y** | DOT, DOC, DOX, GCR, MGI, PCA, BAM | ƒê·ªët, ƒê·ªët ch·∫£i, ƒê·ªët x·ªãt, Gi·∫£ c·ªï rung, M√†i gi·∫•y, Phun c√°t, BƒÉm |
| **Gia c√¥ng M√°y Cao c·∫•p** | HON, BON, CHA | Hone, B√≥ng, Ch·∫£i |

*Khi ch·ªçn ∆Øu ti√™n 2 cho Gia c√¥ng, h·ªá th·ªëng s·∫Ω t√¨m c√°c s·∫£n ph·∫©m c√πng nh√≥m gia c√¥ng.*
            """)
        
        with st.expander("üìã Quy t·∫Øc ƒë·ªãnh gi√°"):
            st.markdown("""
**Ph√¢n kh√∫c gi√° (USD/m¬≥):**
| Ph√¢n kh√∫c | Gi√° | S·∫£n ph·∫©m |
|-----------|-----|----------|
| üü£ Super Premium | ‚â• $1,500 | ƒê√° m·ªèng 1-1.5cm, n·∫Øp t∆∞·ªùng, m·ªπ ngh·ªá |
| üî¥ Premium | ‚â• $800 | ƒê√° l√°t 2-5cm, slab, b·∫≠c thang |
| üü° Common | ‚â• $400 | ƒê√° c√¢y, cubic ƒë·ªët, quay m·∫ª |
| üü¢ Economy | < $400 | ƒê√° g√µ tay, cubic ch·∫ª tay |
            """)
        
        with st.expander("üë• Ph√¢n lo·∫°i kh√°ch h√†ng"):
            st.markdown("""
| Lo·∫°i | M√¥ t·∫£ | ƒêi·ªÅu ch·ªânh |
|------|-------|------------|
| **A** | Th√¢n thi·∫øt >10 nƒÉm | -1.5% ƒë·∫øn -3% |
| **B** | L·ªõn 3-10 nƒÉm | -2% ƒë·∫øn -4% |
| **C** | Ph·ªï th√¥ng | Gi√° chu·∫©n |
| **D** | M·ªõi, nh·ªè | +3% ƒë·∫øn +6% |
| **E** | S·∫£n ph·∫©m m·ªõi | √ó1.08-1.15 |
| **F** | D·ª± √°n | √ó1.08-1.15 |
            """)
        
        with st.expander("üìê C√¥ng th·ª©c t√≠nh to√°n"):
            st.markdown("""
**Th·ªÉ t√≠ch:** `m¬≥ = (D√óR√óC) / 1.000.000 √ó SL`

**Di·ªán t√≠ch:** `m¬≤ = (D√óR) / 10.000 √ó SL`

**Tr·ªçng l∆∞·ª£ng:** `T·∫•n = m¬≥ √ó TLR √ó HS`

**Quy ƒë·ªïi gi√°:**
- `Gi√°/m¬≤ = Gi√°/m¬≥ √ó Cao(m)`
- `Gi√°/T·∫•n = Gi√°/m¬≥ √∑ TLR √∑ HS`

**TLR tham kh·∫£o:**
- Absolute Basalt: 2.95
- Black Basalt: 2.65-2.70
- Granite th∆∞·ªùng: 2.70
- Dark Grey Granite: 2.90
            """)
        
        with st.expander("üéØ Ti√™u ch√≠ t√¨m ki·∫øm"):
            st.markdown("""
| Ti√™u ch√≠ | ∆Øu ti√™n 1 | ∆Øu ti√™n 2 | ∆Øu ti√™n 3 |
|----------|-----------|-----------|-----------| 
| **Lo·∫°i ƒë√°** | ƒê√∫ng m√†u ƒë√° | C√πng ch·ªßng lo·∫°i | T·∫•t c·∫£ lo·∫°i ƒë√° |
| **Gia c√¥ng** | ƒê√∫ng lo·∫°i gia c√¥ng | ƒê√∫ng nh√≥m gia c√¥ng | T·∫•t c·∫£ gia c√¥ng |
| **Cao (cm)** | ¬±0 | ¬±1 | ¬±5 |
| **R·ªông (cm)** | ¬±0 | ¬±5 | ¬±20 |
| **D√†i (cm)** | ¬±0 | ¬±10 | ¬±30 (ho·∫∑c kh√¥ng gi·ªõi h·∫°n) |
| **Th·ªã tr∆∞·ªùng** | ƒê√∫ng n∆∞·ªõc (Billing) | ƒê√∫ng nh√≥m KH | T·∫•t c·∫£ th·ªã tr∆∞·ªùng |
            """)
        
        with st.expander("üì¶ Quy t·∫Øc ·ª©ng d·ª•ng s·∫£n ph·∫©m"):
            st.markdown("""
| ·ª®NG D·ª§NG | Code | Name (English) | Name (Vietnamese) |
|----------|------|----------------|-------------------|
| CUBE | 1.1 | Cubes / Cobbles | Cubic (ƒê√° vu√¥ng) |
| PAVING | 1.3 | Paving stone | ƒê√° l√°t ngo√†i tr·ªùi |
| WALL_STONE | 2.1 | Wall stone | ƒê√° x√¢y t∆∞·ªùng r√†o |
| PALISADE | 3.1 | Palisades | ƒê√° c√¢y |
| KERB | 3.2 | Border / Kerbs | ƒê√° b√≥ v·ªâa h√® |
| STEP | 4.1, 4.2 | Stair / Step | ƒê√° b·∫≠c thang |
| POOL | 6.1 | Pool surrounding | ƒê√° gh√©p h·ªì b∆°i |
| TILE | 7.1-7.3 | Tile / Paver | ƒê√° l√°t quy c√°ch |
| SLAB | 9.1 | Slab | ƒê√° slab kh·ªï l·ªõn |
            """)
        
        with st.expander("üè∑Ô∏è Quy ƒë·ªãnh m√£ SKU s·∫£n ph·∫©m"):
            st.markdown("""
**C·∫•u tr√∫c m√£ SKU:**

| V·ªã tr√≠ | ƒê·ªãnh d·∫°ng | M√¥ t·∫£ |
|--------|-----------|-------|
| 1-2 | 2 ch·ªØ c√°i | **Nguy√™n v·∫≠t li·ªáu** (M√£ lo·∫°i ƒë√°) |
| 3-4 | 2 s·ªë | **M·ª•c ƒë√≠ch s·ª≠ d·ª•ng** |
| 5-7 | 3 ch·ªØ c√°i | **Gia c√¥ng b·ªÅ m·∫∑t ch√≠nh** |
| 8 | 1 s·ªë | **Gia c√¥ng ph·ª•** |
| 9-12 | 4 s·ªë (mm) | **Chi·ªÅu d√†i** |
| 13 | 1 s·ªë/ch·ªØ | **Chi·ªÅu r·ªông** |
| 14-16 | 3 s·ªë (mm) | **Chi·ªÅu cao** |

---

**Nguy√™n v·∫≠t li·ªáu (V·ªã tr√≠ 1-2):**

| M√£ | Ti·∫øng Vi·ªát | English |
|----|-----------|---------|
| BD | ƒê√° Bazan ƒêen | Basalt Black |
| BX | ƒê√° Bazan X√°m | Basalt Grey |
| BT | ƒê√° Bazan T·ªï ong | Basalt Hive |
| GX | ƒê√° Granite X√°m | Granite Grey |
| GT | ƒê√° Granite Tr·∫Øng | Granite White |
| GV | ƒê√° Granite V√†ng | Granite Yellow |
| GD | ƒê√° Granite ƒê·ªè | Granite Red |
| GH | ƒê√° Granite H·ªìng | Granite Pink |
| MB | Marble Bluestone | Marble Blue |
| MT | Marble Tr·∫Øng | Marble White |
| MV | Marble V√†ng | Marble Yellow |

---

**M·ª•c ƒë√≠ch s·ª≠ d·ª•ng (V·ªã tr√≠ 3-4):**

| M√£ | M√¥ t·∫£ |
|----|-------|
| 01 | ƒê√° l√°t n·ªÅn ngo·∫°i th·∫•t (Cubic, t·∫•m) |
| 02 | T∆∞·ªùng r√†o (ƒê√° kh·ªëi, NTR) |
| 03 | ƒê√° c√¢y |
| 04 | ƒê√° b·∫≠c thang (Nguy√™n kh·ªëi, ·ªëp BT) |
| 05 | ƒê√° m·ªπ ngh·ªá |
| 06 | Cao c·∫•p h·ªì b∆°i, b·ªô c·ª≠a |
| 07 | L√°t n·ªÅn b√™n trong, ƒë√° b·ªô |
| 08 | ·ªêp t∆∞·ªùng |
| 09 | Slab, b√†n b·∫øp, cao c·∫•p |

---

**Gia c√¥ng b·ªÅ m·∫∑t ch√≠nh (V·ªã tr√≠ 5-7):**

| M√£ | Gia c√¥ng | M√£ | Gia c√¥ng |
|----|----------|----|----------|
| CTA | Ch·∫ª tay t·ª± nhi√™n | HON | M·∫∑t hon |
| CUA | M·∫∑t c∆∞a | BON | M·∫∑t b√≥ng |
| CLO | C∆∞a l·ªôt tay | BAM | M·∫∑t bƒÉm |
| TDE | T·∫©y ƒë·∫πp | GCR | Gi·∫£ c·ªï rung |
| DOT | M·∫∑t ƒë·ªët | GCT | Gi·∫£ c·ªï tay |
| DOC | ƒê·ªët ch·∫£i | MGI | M√†i gi·∫•y |
| DOX | ƒê·ªët x·ªãt | PCA | Phun c√°t |
| TLO | T√°ch l·ªìi | QME | Quay m·∫ª |

---

**Gia c√¥ng ph·ª• (V·ªã tr√≠ 8):**

| M√£ | M√¥ t·∫£ |
|----|-------|
| 0 | Kh√¥ng c√≥ gia c√¥ng ph·ª• |
| 1 | C·∫°nh c∆∞a |
| 2 | C·∫°nh ch·∫ª tay t·ª± nhi√™n |
| 3 | C·∫°nh hone |
| 4 | C·∫°nh ƒë·ªët |
| 5 | C·∫°nh bƒÉm |
| 6 | C·∫°nh bo tr√≤n R |
| 7 | ƒê√°y bƒÉm |
| 8 | G√µ m·∫ª |
| 9 | Gia c√¥ng kh√°c (C√≥ ch√∫ th√≠ch) |

---

**V√≠ d·ª•:** `BD01DOT2-06004060`
- **BD:** Bazan ƒêen
- **01:** ƒê√° l√°t n·ªÅn
- **DOT:** M·∫∑t ƒë·ªët
- **2:** C·∫°nh ch·∫ª tay
- **0600:** 600mm d√†i
- **4:** 400mm r·ªông
- **060:** 60mm cao

‚Üí *Bazan ƒêen L√°t n·ªÅn, m·∫∑t ƒê·ªët, c·∫°nh Ch·∫ª tay, KT 600√ó400√ó60mm*
            """)
        
        with st.expander("üîó Nh√≥m lo·∫°i ƒë√° (Stone Family)"):
            st.markdown("""
**D√πng cho ∆Øu ti√™n 2 - C√πng ch·ªßng lo·∫°i:**

| Nh√≥m | M√£ lo·∫°i ƒë√° |
|------|------------|
| **BASALT** | BD (Black), BX (Grey), BT (Hive) |
| **GRANITE** | GX, GT, GV, GD, GH |
| **MARBLE** | MB, MT, MV |
            """)
    
    # Tab 2: Data Analysis
    with tab2:
        st.subheader("üìä Ph√¢n t√≠ch d·ªØ li·ªáu gi√°")
        
        df = st.session_state.data.copy()
        
        # Clean data: remove products with price 0, missing, or negative
        df_clean = df[df['sales_price'].notna() & (df['sales_price'] > 0)]
        
        # Show data quality info
        total_products = len(df)
        valid_products = len(df_clean)
        excluded_products = total_products - valid_products
        
        if excluded_products > 0:
            st.info(f"üìä ƒê√£ lo·∫°i b·ªè {excluded_products:,} s·∫£n ph·∫©m c√≥ gi√° = 0, √¢m ho·∫∑c thi·∫øu. Ph√¢n t√≠ch v·ªõi {valid_products:,} / {total_products:,} s·∫£n ph·∫©m.")
        
        # Summary metrics using sales_price (clean data)
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("üì¶ S·∫£n ph·∫©m h·ª£p l·ªá", f"{valid_products:,}")
        with col2:
            st.metric("üí∞ Gi√° TB (Sales Price)", f"${df_clean['sales_price'].mean():,.2f}")
        with col3:
            st.metric("üìà Gi√° cao nh·∫•t", f"${df_clean['sales_price'].max():,.2f}")
        with col4:
            st.metric("üìâ Gi√° th·∫•p nh·∫•t", f"${df_clean['sales_price'].min():,.2f}")
        
        st.divider()
        
        # Charts
        chart_col1, chart_col2 = st.columns(2)
        
        with chart_col1:
            # Price distribution by segment (using clean data)
            segment_counts = df_clean['segment'].value_counts()
            fig_segment = px.pie(
                values=segment_counts.values,
                names=segment_counts.index,
                title="Ph√¢n b·ªë theo ph√¢n kh√∫c",
                color=segment_counts.index,
                color_discrete_map={
                    'Super premium': '#9e7cc1',
                    'Premium': '#ff6b6b',
                    'Common': '#ffd93d',
                    'Economy': '#6bcb77'
                }
            )
            st.plotly_chart(fig_segment, use_container_width=True)
        
        with chart_col2:
            # Average sales_price by family (using clean data)
            avg_by_family = df_clean.groupby('family')['sales_price'].mean().sort_values(ascending=True)
            fig_family = px.bar(
                x=avg_by_family.values,
                y=avg_by_family.index,
                orientation='h',
                title="Gi√° b√°n trung b√¨nh theo lo·∫°i s·∫£n ph·∫©m",
                labels={'x': 'Sales Price (USD)', 'y': 'Lo·∫°i s·∫£n ph·∫©m'}
            )
            fig_family.update_traces(marker_color='#667eea')
            st.plotly_chart(fig_family, use_container_width=True)
        
        # Price by stone type (using clean data)
        st.markdown("#### üíé Gi√° b√°n theo lo·∫°i ƒë√°")
        fig_stone = px.box(
            df_clean,
            x='stone_color_type',
            y='sales_price',
            color='stone_color_type',
            title="Ph√¢n b·ªë gi√° b√°n theo m√†u ƒë√°",
            labels={'sales_price': 'Sales Price (USD)', 'stone_color_type': 'Stone Color Type'}
        )
        st.plotly_chart(fig_stone, use_container_width=True)
        
        # Price vs dimensions (using clean data)
        st.markdown("#### üìê Gi√° b√°n theo k√≠ch th∆∞·ªõc")
        fig_scatter = px.scatter(
            df_clean,
            x='volume_m3',
            y='sales_price',
            color='segment',
            size='height_cm',
            hover_data=['contract_product_name', 'family'],
            title="Sales Price vs Th·ªÉ t√≠ch",
            labels={'sales_price': 'Sales Price (USD)', 'volume_m3': 'Volume (m¬≥)'},
            color_discrete_map={
                'Super premium': '#9e7cc1',
                'Premium': '#ff6b6b',
                'Common': '#ffd93d',
                'Economy': '#6bcb77'
            }
        )
        st.plotly_chart(fig_scatter, use_container_width=True)
        
        st.divider()
        
        # New charts section
        st.markdown("### üìä Ph√¢n t√≠ch n√¢ng cao")
        
        chart_col3, chart_col4 = st.columns(2)
        
        with chart_col3:
            # Price by Application (new column)
            if 'application' in df_clean.columns:
                app_prices = df_clean.groupby('application').agg({
                    'sales_price': ['mean', 'count']
                }).round(2)
                app_prices.columns = ['Gi√° TB', 'S·ªë l∆∞·ª£ng']
                app_prices = app_prices.sort_values('Gi√° TB', ascending=True)
                
                fig_app = px.bar(
                    x=app_prices['Gi√° TB'].values,
                    y=app_prices.index,
                    orientation='h',
                    title="üí∞ Gi√° trung b√¨nh theo ·ª®ng d·ª•ng (Application)",
                    labels={'x': 'Gi√° TB (USD)', 'y': 'Application'},
                    text=app_prices['S·ªë l∆∞·ª£ng'].values
                )
                fig_app.update_traces(marker_color='#48bb78', texttemplate='n=%{text}', textposition='inside')
                st.plotly_chart(fig_app, use_container_width=True)
        
        with chart_col4:
            # Price by Processing type
            if 'processing_name' in df_clean.columns:
                proc_prices = df_clean.groupby('processing_name').agg({
                    'sales_price': ['mean', 'count']
                }).round(2)
                proc_prices.columns = ['Gi√° TB', 'S·ªë l∆∞·ª£ng']
                proc_prices = proc_prices.sort_values('Gi√° TB', ascending=True)
                
                fig_proc = px.bar(
                    x=proc_prices['Gi√° TB'].values,
                    y=proc_prices.index,
                    orientation='h',
                    title="üîß Gi√° trung b√¨nh theo Gia c√¥ng (Processing)",
                    labels={'x': 'Gi√° TB (USD)', 'y': 'Processing'},
                    text=proc_prices['S·ªë l∆∞·ª£ng'].values
                )
                fig_proc.update_traces(marker_color='#ed8936', texttemplate='n=%{text}', textposition='inside')
                st.plotly_chart(fig_proc, use_container_width=True)
        
        chart_col5, chart_col6 = st.columns(2)
        
        with chart_col5:
            # Price trend by year
            if 'fy_year' in df_clean.columns:
                yearly_data = df_clean.groupby('fy_year').agg({
                    'sales_price': ['mean', 'median', 'count'],
                    'price_m3': 'mean'
                }).round(2)
                yearly_data.columns = ['Gi√° TB', 'Gi√° Trung v·ªã', 'S·ªë ƒë∆°n h√†ng', 'Gi√°/m¬≥ TB']
                yearly_data = yearly_data.reset_index()
                yearly_data = yearly_data[yearly_data['fy_year'].notna()]
                
                fig_trend = px.line(
                    yearly_data,
                    x='fy_year',
                    y=['Gi√° TB', 'Gi√° Trung v·ªã'],
                    title="üìà Xu h∆∞·ªõng gi√° theo nƒÉm",
                    labels={'value': 'Gi√° (USD)', 'fy_year': 'NƒÉm', 'variable': 'Lo·∫°i gi√°'},
                    markers=True
                )
                fig_trend.update_layout(legend=dict(orientation="h", yanchor="bottom", y=1.02))
                st.plotly_chart(fig_trend, use_container_width=True)
        
        with chart_col6:
            # Regional Group analysis
            if 'customer_regional_group' in df_clean.columns:
                region_data = df_clean[df_clean['customer_regional_group'].notna()]
                if len(region_data) > 0:
                    region_prices = region_data.groupby('customer_regional_group').agg({
                        'sales_price': ['mean', 'count'],
                        'price_m3': 'mean'
                    }).round(2)
                    region_prices.columns = ['Gi√° TB', 'S·ªë ƒë∆°n h√†ng', 'Gi√°/m¬≥ TB']
                    region_prices = region_prices.sort_values('Gi√° TB', ascending=True).reset_index()
                    
                    fig_region = px.bar(
                        region_prices,
                        x='customer_regional_group',
                        y='Gi√° TB',
                        color='Gi√°/m¬≥ TB',
                        title="üåç Gi√° trung b√¨nh theo Khu v·ª±c kh√°ch h√†ng",
                        labels={'customer_regional_group': 'Nh√≥m Khu v·ª±c', 'Gi√° TB': 'Gi√° TB (USD)'},
                        text='S·ªë ƒë∆°n h√†ng',
                        color_continuous_scale='Blues'
                    )
                    fig_region.update_traces(texttemplate='n=%{text}', textposition='outside')
                    st.plotly_chart(fig_region, use_container_width=True)
        
        # Correlation heatmap for numeric columns
        st.markdown("#### üîó T∆∞∆°ng quan gi·ªØa c√°c y·∫øu t·ªë")
        numeric_cols = ['length_cm', 'width_cm', 'height_cm', 'volume_m3', 'area_m2', 'sales_price', 'price_m3']
        available_numeric = [col for col in numeric_cols if col in df_clean.columns]
        if len(available_numeric) >= 3:
            corr_matrix = df_clean[available_numeric].corr().round(2)
            fig_corr = px.imshow(
                corr_matrix,
                text_auto=True,
                title="Ma tr·∫≠n t∆∞∆°ng quan (Correlation Matrix)",
                color_continuous_scale='RdBu_r',
                aspect='auto'
            )
            st.plotly_chart(fig_corr, use_container_width=True)
    
    # Tab 3: Similar Products
    with tab3:
        st.subheader("üîç T√¨m s·∫£n ph·∫©m t∆∞∆°ng t·ª±")
        
        col1, col2 = st.columns([1, 2])
        
        with col1:
            st.markdown("#### Ti√™u ch√≠ t√¨m ki·∫øm")
            search_family = st.selectbox("Lo·∫°i s·∫£n ph·∫©m", [''] + PRODUCT_FAMILIES, key='search_family')
            search_stone = st.selectbox(
                "M√†u ƒë√°",
                options=[''] + [code for code, label in STONE_COLOR_TYPES],
                format_func=lambda x: STONE_COLOR_LOOKUP.get(x, 'T·∫•t c·∫£') if x else 'T·∫•t c·∫£',
                key='search_stone'
            )
            
            # Processing code dropdown with Vietnamese
            search_processing_lookup = {code: (eng, vn) for code, eng, vn in PROCESSING_CODES_SEARCH}
            search_processing = st.selectbox(
                "Gia c√¥ng ch√≠nh (Main Processing)",
                options=[code for code, eng, vn in PROCESSING_CODES_SEARCH],
                format_func=lambda x: f"{x} - {search_processing_lookup.get(x, ('All', 'T·∫•t c·∫£'))[0]} ({search_processing_lookup.get(x, ('All', 'T·∫•t c·∫£'))[1]})" if x else "All (T·∫•t c·∫£)",
                key='search_processing'
            )
            
            # Customer Regional Group filter
            search_regional_group = st.selectbox(
                "Nh√≥m Khu v·ª±c KH (Regional Group)",
                options=[code for code, name in CUSTOMER_REGIONAL_GROUPS],
                format_func=lambda x: x if x else "All",
                key='search_regional_group',
                help="L·ªçc theo nh√≥m khu v·ª±c kh√°ch h√†ng"
            )
            
            search_col1, search_col2, search_col3 = st.columns(3)
            with search_col1:
                search_length = st.number_input("D√†i (cm)", min_value=0.0, value=30.0, step=0.5, key='search_l')
            with search_col2:
                search_width = st.number_input("R·ªông (cm)", min_value=0.0, value=30.0, step=0.5, key='search_w')
            with search_col3:
                search_height = st.number_input("D√†y (cm)", min_value=0.0, value=3.0, key='search_h')
            
            st.divider()
            
            # Show related checkbox and slider
            show_related = st.checkbox("üìã Hi·ªÉn th·ªã s·∫£n ph·∫©m li√™n quan", value=False, 
                                       help="Hi·ªÉn th·ªã c√°c s·∫£n ph·∫©m c√≥ ƒë·∫∑c ƒëi·ªÉm t∆∞∆°ng t·ª± n·∫øu kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£ ch√≠nh x√°c")
            
            if show_related:
                related_count = st.slider("S·ªë s·∫£n ph·∫©m li√™n quan", 5, 50, 20)
            
            search_btn = st.button("üîç T√¨m ki·∫øm", type="primary", use_container_width=True)
        
        with col2:
            if search_btn:
                df = st.session_state.data.copy()
                
                # Clean data for searching
                df_clean = df[df['sales_price'].notna() & (df['sales_price'] > 0)].copy()
                df_clean = df_clean.reset_index(drop=True)  # Reset index to avoid alignment issues
                
                # Step 1: Find EXACT matches
                exact_mask = pd.Series([True] * len(df_clean), index=df_clean.index)
                
                if search_family:
                    exact_mask &= df_clean['family'] == search_family
                if search_stone:
                    exact_mask &= df_clean['stone_color_type'] == search_stone
                if search_processing and 'processing_code' in df_clean.columns:
                    exact_mask &= df_clean['processing_code'] == search_processing
                if search_regional_group and 'customer_regional_group' in df_clean.columns:
                    exact_mask &= df_clean['customer_regional_group'] == search_regional_group
                if search_length > 0:
                    exact_mask &= df_clean['length_cm'] == search_length
                if search_width > 0:
                    exact_mask &= df_clean['width_cm'] == search_width
                if search_height > 0:
                    exact_mask &= df_clean['height_cm'] == search_height
                
                exact_matches = df_clean[exact_mask]
                
                # Include application and processing columns in display
                display_cols = ['contract_product_name', 'stone_color_type', 
                                'sku', 'application_code', 'application',
                                'processing_code', 'processing_name',
                                'customer_regional_group',
                                'billing_country',
                                'length_cm', 'width_cm', 'height_cm', 'charge_unit', 'sales_price', 'price_m3', 'segment']
                available_cols = [col for col in display_cols if col in df_clean.columns]
                
                # Column config for English headers
                col_config = {
                    'sku': st.column_config.TextColumn('SKU'),
                    'application_code': st.column_config.TextColumn('App Code'),
                    'application': st.column_config.TextColumn('Application'),
                    'processing_code': st.column_config.TextColumn('Main Processing Code'),
                    'processing_name': st.column_config.TextColumn('Main Processing'),
                    'customer_regional_group': st.column_config.TextColumn('Regional Group'),
                    'billing_country': st.column_config.TextColumn('Billing Country'),
                }
                
                # Display exact matches
                if len(exact_matches) > 0:
                    st.markdown(f"#### ‚úÖ T√¨m th·∫•y {len(exact_matches)} s·∫£n ph·∫©m kh·ªõp ch√≠nh x√°c")
                    st.dataframe(exact_matches[available_cols], use_container_width=True, height=300, column_config=col_config)
                    
                    # Statistics for exact matches
                    valid_prices = exact_matches['sales_price']
                    if len(valid_prices) > 0:
                        st.markdown("##### üìä Th·ªëng k√™ gi√° (kh·ªõp ch√≠nh x√°c)")
                        stat_col1, stat_col2, stat_col3, stat_col4 = st.columns(4)
                        with stat_col1:
                            st.metric("Th·∫•p nh·∫•t", f"${valid_prices.min():,.2f}")
                        with stat_col2:
                            st.metric("Cao nh·∫•t", f"${valid_prices.max():,.2f}")
                        with stat_col3:
                            st.metric("Trung b√¨nh", f"${valid_prices.mean():,.2f}")
                        with stat_col4:
                            st.metric("Trung v·ªã", f"${valid_prices.median():,.2f}")
                else:
                    st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m kh·ªõp ch√≠nh x√°c v·ªõi ti√™u ch√≠.")
                
                # Step 2: Show related products if checkbox is checked
                if show_related:
                    st.divider()
                    st.markdown(f"#### üîó S·∫£n ph·∫©m li√™n quan (top {related_count})")
                    
                    # Find related products based on partial criteria
                    related_mask = pd.Series([False] * len(df_clean), index=df_clean.index)
                    
                    if search_family:
                        related_mask |= df_clean['family'] == search_family
                    if search_stone:
                        related_mask |= df_clean['stone_color_type'] == search_stone
                    if search_processing and 'processing_code' in df_clean.columns:
                        related_mask |= df_clean['processing_code'] == search_processing
                    if search_regional_group and 'customer_regional_group' in df_clean.columns:
                        related_mask |= df_clean['customer_regional_group'] == search_regional_group
                    
                    # Exclude exact matches
                    related_mask &= ~exact_mask
                    
                    related_products = df_clean[related_mask].copy()
                    
                    # Sort by dimension similarity if dimensions provided
                    if search_length > 0 and search_width > 0 and search_height > 0:
                        related_products['dim_diff'] = (
                            abs(related_products['length_cm'] - search_length) +
                            abs(related_products['width_cm'] - search_width) +
                            abs(related_products['height_cm'] - search_height)
                        )
                        related_products = related_products.nsmallest(related_count, 'dim_diff')
                    else:
                        related_products = related_products.head(related_count)
                    
                    if len(related_products) > 0:
                        st.dataframe(related_products[available_cols], use_container_width=True, height=300, column_config=col_config)
                        
                        # Statistics for related products
                        valid_prices = related_products['sales_price']
                        if len(valid_prices) > 0:
                            st.markdown("##### üìä Th·ªëng k√™ gi√° (s·∫£n ph·∫©m li√™n quan)")
                            stat_col1, stat_col2, stat_col3, stat_col4 = st.columns(4)
                            with stat_col1:
                                st.metric("Th·∫•p nh·∫•t", f"${valid_prices.min():,.2f}")
                            with stat_col2:
                                st.metric("Cao nh·∫•t", f"${valid_prices.max():,.2f}")
                            with stat_col3:
                                st.metric("Trung b√¨nh", f"${valid_prices.mean():,.2f}")
                            with stat_col4:
                                st.metric("Trung v·ªã", f"${valid_prices.median():,.2f}")
                            
                            # Summary
                            price_range = valid_prices.max() - valid_prices.min()
                            st.caption(f"Kho·∫£ng gi√°: ${price_range:,.2f} | ƒê·ªô l·ªách chu·∫©n: ${valid_prices.std():,.2f}")
                    else:
                        st.info("Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m li√™n quan.")
    
    # Tab 4: Weight & Conversion Reference
    with tab4:
        st.subheader("üìê B·∫£ng tra c·ª©u TLR & H·ªá s·ªë")
        
        if st.session_state.model_metrics is not None:
            metrics = st.session_state.model_metrics
            loaded = metrics.get('loaded_samples', 0)
            st.success(f"‚úÖ ƒê√£ t·∫£i **{loaded:,}** s·∫£n ph·∫©m c√≥ gi√°")
        
        st.divider()
        
        # TLR Reference Table
        st.markdown("#### ‚öñÔ∏è Tr·ªçng L∆∞·ª£ng Ri√™ng (TLR)")
        tlr_data = {
            'S·∫£n ph·∫©m': [
                'ƒê√° ƒëen ƒêak N√¥ng (Absolute Basalt)',
                'ƒê√° Ph∆∞·ªõc H√≤a/Qui Nh∆°n (c∆∞a c·∫Øt m√°y)',
                'ƒê√° Ph∆∞·ªõc H√≤a/Qui Nh∆°n (ch·∫ª tay)',
                'Dark Grey Granite',
                'Granite th∆∞·ªùng',
                'Bluestone (Thanh H√≥a)',
                'ƒê√° t·ªï ong'
            ],
            'TLR (t·∫•n/m¬≥)': ['2.95', '2.70', '2.65', '2.90', '2.70', '2.70', '2.20'],
            'Ghi ch√∫': [
                'H√†ng Dak N√¥ng m·ªói cont 9.3-9.6 m¬≥',
                '',
                '',
                '',
                '',
                '',
                ''
            ]
        }
        st.dataframe(pd.DataFrame(tlr_data), use_container_width=True, hide_index=True)
        
        st.divider()
        
        # HS Factors Table
        st.markdown("#### üìä H·ªá S·ªë ·ªêp ƒê√°y (HS)")
        hs_data = {
            'S·∫£n ph·∫©m': [
                'ƒê√° l√°t 6cm m·∫∑t ƒë·ªët, c·∫°nh s·ªô',
                'ƒê√° cubic ch·∫ª tay 5√ó5√ó5cm',
                'ƒê√° cubic ch·∫ª tay 8√ó8√ó8cm',
                'ƒê√° cubic ch·∫ª tay 10√ó10√ó8cm, 20√ó10√ó8cm',
                'ƒê√° cubic ch·∫ª tay 15√ó15√ó12cm',
                'ƒê√° cubic m·∫∑t ƒë·ªët, c·∫°nh ch·∫ª tay',
                'ƒê√° c√¢y c∆∞a l·ªôt'
            ],
            'HS': ['0.97', '1.00', '0.95', '0.875', '0.85', '0.95', '1.05'],
            'Ghi ch√∫': [
                '·ªêp ƒë√°y gi·∫£m 3%',
                '',
                '',
                '',
                '',
                '',
                'D√†y th·ª±c t·∫ø 10.5cm, +5%'
            ]
        }
        st.dataframe(pd.DataFrame(hs_data), use_container_width=True, hide_index=True)
        
        st.divider()
        
        # Formulas
        st.markdown("#### üìù C√¥ng th·ª©c t√≠nh to√°n")
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("""
**T√≠nh m¬≥ (Th·ªÉ t√≠ch):**
```
m¬≥ = (D√†i √ó R·ªông √ó Cao) / 1.000.000 √ó S·ªë vi√™n
```

**T√≠nh m¬≤ (Di·ªán t√≠ch):**
```
m¬≤ = (D√†i √ó R·ªông) / 10.000 √ó S·ªë vi√™n
```

**T√≠nh T·∫•n (Tr·ªçng l∆∞·ª£ng):**
```
T·∫•n = m¬≥ √ó TLR √ó HS
```
            """)
        with col2:
            st.markdown("""
**Quy ƒë·ªïi gi√° t·ª´ Vi√™n:**
- `Gi√°/m¬≤ = Gi√° Vi√™n √∑ D(m) √∑ R(m)`
- `Gi√°/m¬≥ = Gi√° Vi√™n √∑ D(m) √∑ R(m) √∑ C(m)`
- `Gi√°/T·∫•n = Gi√° Vi√™n √∑ D √∑ R √∑ C √∑ TLR √∑ HS`

**Quy ƒë·ªïi gi·ªØa ƒë∆°n v·ªã:**
- `Gi√°/m¬≤ = Gi√°/m¬≥ √ó Cao(m)`
- `Gi√°/m¬≥ = Gi√°/T·∫•n √ó TLR √ó HS`
            """)
        
        st.divider()
        
        # Container weight reference
        st.markdown("#### üö¢ Quy chu·∫©n tr·ªçng l∆∞·ª£ng Container")
        container_data = {
            'Th·ªã tr∆∞·ªùng': ['M·ªπ', 'Ch√¢u √Çu', '√öc', 'Nh·∫≠t'],
            'Tr·ªçng l∆∞·ª£ng (t·∫•n)': ['20-21', '27-28', '24-26', '27.5-28']
        }
        st.dataframe(pd.DataFrame(container_data), use_container_width=True, hide_index=True)
    
    # Tab 5: Detailed Data
    with tab5:
        st.subheader("üìã D·ªØ li·ªáu chi ti·∫øt")
        
        # Filters
        filter_col1, filter_col2, filter_col3, filter_col4 = st.columns(4)
        with filter_col1:
            filter_family = st.multiselect("Lo·∫°i s·∫£n ph·∫©m", PRODUCT_FAMILIES)
        with filter_col2:
            filter_segment = st.multiselect("Ph√¢n kh√∫c", ['Economy', 'Common', 'Premium', 'Super premium'])
        with filter_col3:
            filter_regional_group = st.multiselect(
                "Nh√≥m Khu v·ª±c KH", 
                [code for code, name in CUSTOMER_REGIONAL_GROUPS if code]
            )
        with filter_col4:
            price_range = st.slider("Kho·∫£ng gi√° (USD/m¬≥)", 0, 2000, (0, 2000))
        
        # Apply filters
        filtered_df = st.session_state.data.copy()
        if filter_family:
            filtered_df = filtered_df[filtered_df['family'].isin(filter_family)]
        if filter_segment:
            filtered_df = filtered_df[filtered_df['segment'].isin(filter_segment)]
        if filter_regional_group and 'customer_regional_group' in filtered_df.columns:
            filtered_df = filtered_df[filtered_df['customer_regional_group'].isin(filter_regional_group)]
        filtered_df = filtered_df[
            (filtered_df['price_m3'] >= price_range[0]) & 
            (filtered_df['price_m3'] <= price_range[1])
        ]
        
        st.markdown(f"**Hi·ªÉn th·ªã {len(filtered_df):,} / {len(st.session_state.data):,} s·∫£n ph·∫©m**")
        
        # Define all columns from the contract query in logical order
        # These match the fields from contract_query.txt and salesforce_loader.py
        all_contract_columns = [
            'contract_product_name',   # Name
            'contract_name',           # Contract__r.Name
            'account_code',            # Account_Code_C__c
            'customer_regional_group', # Contract__r.Account__r.Nhom_Khu_vuc_KH__c
            'billing_country',         # Billing Country from Account.BillingAddress
            'stone_color_type',        # Product__r.STONE_Color_Type__c
            'sku',                     # Product__r.StockKeepingUnit (SKU)
            'application_code',        # Application code (from SKU positions 3-5)
            'application',             # Application name (English)
            'application_vn',          # Application name (Vietnamese)
            'processing_code',         # Main processing code (from SKU)
            'processing_name',         # Main processing name (English)
            'family',                  # Product__r.Family (legacy)
            'segment',                 # Segment__c
            'created_date',            # Created_Date__c
            'fy_year',                 # Fiscal Year (calculated)
            'product_description',     # Product_Discription__c
            'product_description_vn',  # Product__r.Product_description_in_Vietnamese__c
            'length_cm',               # Length__c
            'width_cm',                # Width__c
            'height_cm',               # Height__c
            'quantity',                # Quantity__c
            'crates',                  # Crates__c
            'm2',                      # m2__c
            'm3',                      # m3__c
            'ml',                      # ml__c
            'tons',                    # Tons__c
            'sales_price',             # Sales_Price__c
            'charge_unit',             # Charge_Unit__c
            'total_price_usd',         # Total_Price_USD__c
            'price_m3',                # Calculated price per m3
            'volume_m3',               # Calculated volume
            'area_m2',                 # Calculated area
        ]
        
        # Filter to only columns that exist in the dataframe
        available_columns = [col for col in all_contract_columns if col in filtered_df.columns]
        
        # Add any remaining columns not in the predefined list
        remaining_columns = [col for col in filtered_df.columns if col not in available_columns]
        display_columns = available_columns + remaining_columns
        
        # Column configuration for English headers on specific columns
        column_config = {
            'sku': st.column_config.TextColumn('SKU', help='Product Stock Keeping Unit'),
            'application_code': st.column_config.TextColumn('App Code', help='Application code from SKU'),
            'application': st.column_config.TextColumn('Application', help='Application name (English)'),
            'application_vn': st.column_config.TextColumn('Application (VN)', help='Application name (Vietnamese)'),
            'processing_code': st.column_config.TextColumn('Main Processing Code', help='K√Ω hi·ªáu gia c√¥ng ch√≠nh'),
            'processing_name': st.column_config.TextColumn('Main Processing', help='Nh√≥m m√£ gia c√¥ng ch√≠nh'),
            'customer_regional_group': st.column_config.TextColumn('Regional Group', help='Nh√≥m Khu v·ª±c KH'),
            'billing_country': st.column_config.TextColumn('Billing Country', help='Billing country from Account.BillingAddress'),
        }
        
        # Display data with all columns
        st.dataframe(
            filtered_df[display_columns],
            use_container_width=True,
            height=500,
            column_config=column_config
        )
        
        # Download button
        csv = filtered_df[display_columns].to_csv(index=False)
        st.download_button(
            "üì• T·∫£i xu·ªëng CSV",
            csv,
            "stone_price_data.csv",
            "text/csv",
            use_container_width=True
        )


if __name__ == "__main__":
    main()
