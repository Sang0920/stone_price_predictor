"""
Stone Price Predictor - Web Application
Dá»± Ä‘oÃ¡n giÃ¡ sáº£n pháº©m Ä‘Ã¡ tá»± nhiÃªn dá»±a trÃªn dá»¯ liá»‡u Salesforce

Features:
- Load dá»¯ liá»‡u tá»« Salesforce (PricebookEntry, Contract_Product__c)
- Machine Learning model Ä‘á»ƒ dá»± Ä‘oÃ¡n giÃ¡
- PhÃ¢n tÃ­ch giÃ¡ theo phÃ¢n khÃºc (Economy, Common, Premium, Super Premium)
- TÃ¬m sáº£n pháº©m tÆ°Æ¡ng tá»± vá»›i giÃ¡ Ä‘Ã£ biáº¿t
"""

import streamlit as st
import pandas as pd
import numpy as np
from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import mean_absolute_error, r2_score
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import json
import os
from typing import Optional, Dict, Any, List, Tuple
import requests
from io import StringIO

# Import Salesforce data loader
from dotenv import load_dotenv
load_dotenv()  # Load .env file for Salesforce credentials

try:
    from salesforce_loader import SalesforceDataLoader
    SALESFORCE_AVAILABLE = True
except ImportError:
    SALESFORCE_AVAILABLE = False

# ============ Configuration ============
st.set_page_config(
    page_title="Stone Price Predictor",
    page_icon="ğŸ’",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f4e79;
        text-align: center;
        margin-bottom: 2rem;
    }
    .segment-economy { background-color: #c6efce; color: #006100; padding: 5px 10px; border-radius: 5px; }
    .segment-common { background-color: #ffeb9c; color: #9c5700; padding: 5px 10px; border-radius: 5px; }
    .segment-premium { background-color: #ffc7ce; color: #9c0006; padding: 5px 10px; border-radius: 5px; }
    .segment-super { background-color: #9e7cc1; color: white; padding: 5px 10px; border-radius: 5px; }
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 20px;
        border-radius: 10px;
        color: white;
        text-align: center;
    }
    .stTabs [data-baseweb="tab-list"] {
        gap: 24px;
    }
</style>
""", unsafe_allow_html=True)

# ============ Pricing Rules Constants ============
SEGMENT_THRESHOLDS = {
    'Super premium': 1500,  # >= 1500 USD/m3
    'Premium': 800,         # >= 800 USD/m3
    'Common': 400,          # >= 400 USD/m3
    'Economy': 0            # < 400 USD/m3
}

# TLR (Trá»ng LÆ°á»£ng RiÃªng - Specific Weight) per TÃNH TOÃN & BÃO GIÃ documentation
TLR_CONSTANTS = {
    # ÄÃ¡ Ä‘en khu vá»±c Äak NÃ´ng
    'ABSOLUTE BASALT': 2.95,
    'DAK_NONG_BASALT': 2.95,
    # ÄÃ¡ khu vá»±c PhÆ°á»›c HÃ²a vÃ  Qui NhÆ¡n
    'BLACK BASALT': 2.65,  # Cháº» tay: 2.65, cáº¯t mÃ¡y: 2.7
    'BLACK BASALT_SAWN': 2.70,
    'HIVE BASALT': 2.20,  # ÄÃ¡ tá»• ong
    # Granite
    'GREY GRANITE': 2.70,
    'DARK GREY GRANITE': 2.90,
    'WHITE GRANITE': 2.70,
    'YELLOW GRANITE': 2.70,
    'RED GRANITE': 2.70,
    'PINK GRANITE': 2.70,
    # Bluestone
    'BLUESTONE': 2.70,
    # Marble
    'WHITE MARBLE': 2.70,
    'YELLOW MARBLE': 2.70,
    # Default
    'DEFAULT': 2.70,
}

# HS (Há»‡ Sá»‘ á»p ÄÃ¡y - Coating Factor) per TÃNH TOÃN & BÃO GIÃ documentation
HS_FACTORS = {
    # ÄÃ¡ lÃ¡t 6cm máº·t Ä‘á»‘t, cáº¡nh sá»™ (á»‘p Ä‘Ã¡y giáº£m 3%)
    'FLAMED_TILE_6CM': 0.97,
    # ÄÃ¡ cubic cháº» tay
    'CUBE_5X5X5': 1.00,
    'CUBE_8X8X8': 0.95,
    'CUBE_10X10X8': 0.875,
    'CUBE_20X10X8': 0.875,
    'CUBE_15X15X12': 0.85,
    # ÄÃ¡ cubic máº·t Ä‘á»‘t, cáº¡nh cháº» tay
    'CUBE_FLAMED_10X10X8': 0.95,
    'CUBE_FLAMED_20X10X8': 0.95,
    # ÄÃ¡ cÃ¢y cÆ°a lá»™t (thÃªm 5% do dÃ y 10.5cm thá»±c táº¿)
    'PALISADE_SAWN': 1.05,
    # Default
    'DEFAULT': 1.00,
}

# Customer Pricing Rules (A-F) per NGUYÃŠN Táº®C ÃP Dá»¤NG Báº¢NG GIÃ documentation
# Segment-aware adjustments
CUSTOMER_PRICING_RULES = {
    'A': {
        'description': 'KhÃ¡ch thÃ¢n thiáº¿t Ä‘áº·c biá»‡t (>10 nÄƒm, 50-150 cont)',
        'base_adjustment': {'min': -0.03, 'max': -0.015},  # -1.5% to -3% vs B
        'label': 'Bá»›t 1.5-3% so vá»›i B',
        'years': '>10',
        'volume': '50-150 cont',
        'authority': 'Tháº£o luáº­n chiáº¿n lÆ°á»£c'
    },
    'B': {
        'description': 'KhÃ¡ch lá»›n, chuyÃªn nghiá»‡p (3-10 nÄƒm, 20-50 cont)',
        'base_adjustment': {'min': -0.04, 'max': -0.02},  # -2% to -4% vs C
        'usd_adjustment': {'min': -30, 'max': -10},  # -10 to -30 USD/mÂ³ vs C
        'label': 'Tháº¥p hÆ¡n C: 2-4% (10-30 USD/mÂ³)',
        'years': '3-10',
        'volume': '20-50 cont',
        'authority': 'Tháº£o luáº­n chiáº¿n lÆ°á»£c'
    },
    'C': {
        'description': 'KhÃ¡ch hÃ ng phá»• thÃ´ng (1-5 nÄƒm, 5-20 cont)',
        'base_adjustment': {'min': 0, 'max': 0},  # Base price
        'label': 'GiÃ¡ chuáº©n',
        'years': '1-5',
        'volume': '5-20 cont',
        'authority': {
            'Economy': 10,      # Â±10 USD/mÂ³
            'Common': 15,       # Â±15 USD/mÂ³
            'Premium': 20,      # Â±20 USD/mÂ³ or Â±0.5 USD/mÂ²
        }
    },
    'D': {
        'description': 'KhÃ¡ch má»›i, khu vá»±c chi tráº£ cao, size nhá» (1 nÄƒm, 1-10 cont)',
        'base_adjustment': {'min': 0.03, 'max': 0.06},  # +3% to +6%
        'usd_adjustment': {'min': 15, 'max': 45},  # +15 to +45 USD/mÂ³
        'label': 'Cao hÆ¡n C: 3-6% (15-45 USD/mÂ³)',
        'years': '1',
        'volume': '1-10 cont',
        'authority': {
            'Premium': 30,       # Â±30 USD/mÂ³ or Â±1.0 USD/mÂ²
            'Super premium': 40, # Â±40 USD/mÂ³ or Â±1.5 USD/mÂ²
        }
    },
    'E': {
        'description': 'Sáº£n pháº©m má»›i, sÃ¡ng táº¡o, cao cáº¥p (1 nÄƒm, 1-10 cont)',
        'base_adjustment': {'min': 0.08, 'max': 0.15},  # Ã—1.08 to Ã—1.15
        'label': 'GiÃ¡ cao cáº¥p: Ã—1.08-1.15 (+5-10%)',
        'years': '1',
        'volume': '1-10 cont',
        'authority': {
            'Premium': 30,       # Â±30 USD/mÂ³ or Â±1.0 USD/mÂ²
            'Super premium': 40, # Â±40 USD/mÂ³ or Â±1.5 USD/mÂ²
        }
    },
    'F': {
        'description': 'KhÃ¡ch hÃ ng dá»± Ã¡n, cao cáº¥p (1-5 nÄƒm, 1-50 cont)',
        'base_adjustment': {'min': 0.08, 'max': 0.15},  # Ã—1.08 to Ã—1.15
        'label': 'Dá»± Ã¡n: Ã—1.08-1.15',
        'years': '1-5',
        'volume': '1-50 cont',
        'authority': {
            'Premium': 30,       # Â±30 USD/mÂ³ or Â±1.0 USD/mÂ²
            'Super premium': 40, # Â±40 USD/mÂ³ or Â±1.5 USD/mÂ²
        }
    },
}

PRODUCT_FAMILIES = [
    'Exterior_Tiles', 'Interior_Tiles', 'WALLSTONE', 'PALISADE', 
    'STAIR', 'ART', 'High-Class', 'SKIRTING', 'SLAB'
]

# Stone Color Types and their family groupings
STONE_COLOR_TYPES = [
    'BLACK BASALT', 'BLUESTONE', 'GREY GRANITE', 'ABSOLUTE BASALT',
    'WHITE GRANITE', 'YELLOW GRANITE', 'RED GRANITE', 'PINK GRANITE',
    'WHITE MARBLE', 'YELLOW MARBLE', 'HIVE BASALT'
]

# Stone family mapping (for Priority 2 matching - same family)
STONE_FAMILY_MAP = {
    'BLACK BASALT': 'BASALT',
    'ABSOLUTE BASALT': 'BASALT',
    'HIVE BASALT': 'BASALT',
    'GREY GRANITE': 'GRANITE',
    'WHITE GRANITE': 'GRANITE',
    'YELLOW GRANITE': 'GRANITE',
    'RED GRANITE': 'GRANITE',
    'PINK GRANITE': 'GRANITE',
    'BLUESTONE': 'BLUESTONE',
    'WHITE MARBLE': 'MARBLE',
    'YELLOW MARBLE': 'MARBLE',
}

# Dimension tolerance levels per notes.md
DIMENSION_PRIORITY_LEVELS = {
    'Æ¯u tiÃªn 1 - ÄÃºng kÃ­ch thÆ°á»›c': {'height': 0, 'width': 0, 'length': 0},
    'Æ¯u tiÃªn 2 - Sai lá»‡ch nhá»': {'height': 1, 'width': 5, 'length': 10},
    'Æ¯u tiÃªn 3 - Sai lá»‡ch lá»›n': {'height': 2, 'width': 10, 'length': 20},
}

CHARGE_UNITS = ['USD/PC', 'USD/M2', 'USD/TON', 'USD/ML', 'USD/M3']

# Customer Regional Groups (NhÃ³m Khu vá»±c KH)
CUSTOMER_REGIONAL_GROUPS = [
    ('', 'All'),
    ('NhÃ³m Ä‘áº§u 0', 'NhÃ³m Ä‘áº§u 0'),
    ('NhÃ³m Ä‘áº§u 1', 'NhÃ³m Ä‘áº§u 1'),
    ('NhÃ³m Ä‘áº§u 2', 'NhÃ³m Ä‘áº§u 2'),
    ('NhÃ³m Ä‘áº§u 3', 'NhÃ³m Ä‘áº§u 3'),
    ('NhÃ³m Ä‘áº§u 4', 'NhÃ³m Ä‘áº§u 4'),
    ('NhÃ³m Ä‘áº§u 5', 'NhÃ³m Ä‘áº§u 5'),
    ('NhÃ³m Ä‘áº§u 6', 'NhÃ³m Ä‘áº§u 6'),
    ('NhÃ³m Ä‘áº§u 7', 'NhÃ³m Ä‘áº§u 7'),
    ('NhÃ³m Ä‘áº§u 8', 'NhÃ³m Ä‘áº§u 8'),
    ('NhÃ³m Ä‘áº§u 9', 'NhÃ³m Ä‘áº§u 9'),
]

# Processing codes with English names (for search dropdown) - no empty/OTHER option
PROCESSING_CODES = [
    ('CUA', 'Sawn'),
    ('DOT', 'Flamed'),
    ('DOC', 'Flamed Brush'),
    ('DOX', 'Flamed Water'),
    ('HON', 'Honed'),
    ('CTA', 'Split Handmade'),
    ('CLO', 'Sawn then Cleaved'),
    ('TDE', 'Chiseled'),
    ('GCR', 'Vibrated Honed Tumbled'),
    ('GCT', 'Old Imitation'),
    ('MGI', 'Scraped'),
    ('PCA', 'Sandblasted'),
    ('QME', 'Tumbled'),
    ('TLO', 'Cleaved'),
    ('BON', 'Polished'),
    ('BAM', 'Bush Hammered'),
    ('CHA', 'Brush'),
]

# Processing codes for search (includes 'All' option)
PROCESSING_CODES_SEARCH = [('', 'All')] + PROCESSING_CODES


# ============ Data Generation (Simulated Salesforce Data) ============
@st.cache_data(ttl=3600)
def generate_sample_data(n_samples: int = 500) -> pd.DataFrame:
    """
    Generate sample product pricing data for demonstration.
    In production, this would be replaced with Salesforce API calls.
    """
    np.random.seed(42)
    
    data = []
    for i in range(n_samples):
        # Product attributes
        family = np.random.choice(PRODUCT_FAMILIES)
        stone_class = np.random.choice(STONE_CLASSES)
        stone_color = np.random.choice(STONE_COLOR_TYPES)
        
        # Dimensions in cm
        length = np.random.choice([10, 15, 20, 30, 40, 50, 60, 80, 100, 120])
        width = np.random.choice([5, 8, 10, 15, 20, 30, 40, 60])
        height = np.random.choice([2, 2.5, 3, 5, 6, 7, 8, 10, 12, 15, 20])
        
        # Calculate volume in m3
        volume_m3 = (length * width * height) / 1000000
        area_m2 = (length * width) / 10000
        
        # Base price calculation based on product complexity
        base_price_m3 = 350 + np.random.normal(0, 50)
        
        # Adjustments based on product type
        if family in ['STAIR', 'ART', 'High-Class']:
            base_price_m3 *= 2.5
        elif family in ['Interior_Tiles', 'SLAB']:
            base_price_m3 *= 1.8
        elif family == 'Exterior_Tiles':
            base_price_m3 *= 1.2
            
        # Stone type adjustment
        if stone_color in ['ABSOLUTE BASALT', 'WHITE MARBLE']:
            base_price_m3 *= 1.5
        elif stone_color in ['YELLOW MARBLE', 'RED GRANITE']:
            base_price_m3 *= 1.3
            
        # Size adjustment (smaller pieces = higher price per m3)
        if length <= 15 and width <= 15:
            base_price_m3 *= 1.4
        elif length >= 60 or width >= 60:
            base_price_m3 *= 0.9
            
        # Thickness adjustment
        if height <= 2:
            base_price_m3 *= 2.0  # Thin slices are more expensive
        elif height >= 10:
            base_price_m3 *= 0.85
            
        # Add noise
        price_m3 = max(200, base_price_m3 + np.random.normal(0, 80))
        
        # Calculate segment
        if price_m3 >= 1500:
            segment = 'Super premium'
        elif price_m3 >= 800:
            segment = 'Premium'
        elif price_m3 >= 400:
            segment = 'Common'
        else:
            segment = 'Economy'
            
        # Charge unit
        if family in ['PALISADE', 'STAIR']:
            charge_unit = 'USD/ML'
        elif height <= 3:
            charge_unit = 'USD/M2'
        elif length <= 20 and width <= 20:
            charge_unit = 'USD/PC'
        else:
            charge_unit = np.random.choice(['USD/M3', 'USD/TON'])
            
        # Convert price to selected unit
        if charge_unit == 'USD/M2':
            unit_price = price_m3 * height / 100
        elif charge_unit == 'USD/PC':
            unit_price = price_m3 * volume_m3
        elif charge_unit == 'USD/TON':
            specific_gravity = 2.8 if stone_class == 'BASALT' else 2.65
            unit_price = price_m3 / (specific_gravity * 1.1)
        elif charge_unit == 'USD/ML':
            unit_price = price_m3 * width * height / 10000
        else:
            unit_price = price_m3
            
        # Customer type
        customer_type = np.random.choice(['A', 'B', 'C', 'D', 'E', 'F'], 
                                         p=[0.05, 0.15, 0.35, 0.20, 0.10, 0.15])
        
        # Apply customer discount
        if customer_type == 'A':
            discount = np.random.uniform(0.015, 0.03)
        elif customer_type == 'B':
            discount = np.random.uniform(0.02, 0.04)
        elif customer_type == 'C':
            discount = 0
        elif customer_type == 'D':
            discount = -np.random.uniform(0.03, 0.06)  # Premium price
        elif customer_type == 'E':
            discount = -np.random.uniform(0.05, 0.10)
        else:
            discount = np.random.uniform(-0.02, 0.02)
            
        final_price = unit_price * (1 - discount)
        
        data.append({
            'product_id': f'PROD-{i+1:04d}',
            'product_name': f'{stone_color} {family.replace("_", " ")} {length}x{width}x{height}',
            'family': family,
            'stone_class': stone_class,
            'stone_color_type': stone_color,
            'length_cm': length,
            'width_cm': width,
            'height_cm': height,
            'volume_m3': volume_m3,
            'area_m2': area_m2,
            'charge_unit': charge_unit,
            'list_price': round(unit_price, 2),
            'price_m3': round(price_m3, 2),
            'segment': segment,
            'customer_type': customer_type,
            'discount_pct': round(discount * 100, 2),
            'final_price': round(final_price, 2),
            'created_date': pd.Timestamp.now() - pd.Timedelta(days=np.random.randint(1, 365))
        })
    
    return pd.DataFrame(data)


# ============ Machine Learning Model ============
class StonePricePredictor:
    """Machine Learning model for stone sales price prediction."""
    
    def __init__(self):
        self.model = None
        self.encoders = {}
        self.scaler = StandardScaler()
        self.feature_columns = []
        # NOTE: segment is EXCLUDED to prevent data leakage (segment is derived from price)
        # processing_code is the main surface processing type (e.g., DOT=Flamed, HON=Honed)
        # customer_regional_group is the customer's regional group (NhÃ³m Ä‘áº§u 0-9) as per notes.md
        self.categorical_columns = ['family', 'stone_color_type', 'charge_unit', 'processing_code', 'customer_regional_group']
        self.numerical_columns = ['length_cm', 'width_cm', 'height_cm', 'volume_m3', 'area_m2']
        # Recency weight decay factor (prices decay by half every 365 days)
        self.recency_half_life_days = 365
        
    def clean_data(self, df: pd.DataFrame, target_col: str = 'sales_price') -> pd.DataFrame:
        """Clean data for training: remove invalid, missing, and outlier data."""
        df_clean = df.copy()
        
        # Remove rows with missing or invalid target
        df_clean = df_clean[df_clean[target_col].notna() & (df_clean[target_col] > 0)]
        
        # Clean processing_code: replace empty/Unknown with 'OTHER'
        if 'processing_code' in df_clean.columns:
            df_clean['processing_code'] = df_clean['processing_code'].fillna('OTHER')
            df_clean['processing_code'] = df_clean['processing_code'].replace('', 'OTHER')
            # Keep 'Unknown' as a valid category but standardize empty strings
        
        # Clean customer_regional_group: replace empty/None with 'Unknown'
        if 'customer_regional_group' in df_clean.columns:
            df_clean['customer_regional_group'] = df_clean['customer_regional_group'].fillna('Unknown')
            df_clean['customer_regional_group'] = df_clean['customer_regional_group'].replace('', 'Unknown')
        
        # Remove rows with missing critical features (excluding columns handled above)
        handled_cols = ['processing_code', 'customer_regional_group']
        for col in self.categorical_columns:
            if col in df_clean.columns and col not in handled_cols:
                df_clean = df_clean[df_clean[col].notna()]
        
        for col in self.numerical_columns:
            if col in df_clean.columns:
                df_clean = df_clean[df_clean[col].notna() & (df_clean[col] >= 0)]
        
        # Remove extreme outliers using IQR method for target variable
        Q1 = df_clean[target_col].quantile(0.01)
        Q3 = df_clean[target_col].quantile(0.99)
        df_clean = df_clean[(df_clean[target_col] >= Q1) & (df_clean[target_col] <= Q3)]
        
        return df_clean
    
    def calculate_recency_weights(self, df: pd.DataFrame) -> np.ndarray:
        """
        Calculate sample weights based on recency (more recent prices have higher weight).
        Uses exponential time decay with configurable half-life.
        
        This helps improve accuracy for new products by prioritizing recent price data,
        accounting for annual cost increases in raw materials and labor.
        """
        if 'created_date' not in df.columns:
            return np.ones(len(df))
        
        # Convert created_date to datetime
        dates = pd.to_datetime(df['created_date'], errors='coerce', utc=True)
        
        # Calculate days since each transaction
        reference_date = pd.Timestamp.now(tz='UTC')
        days_ago = (reference_date - dates).dt.total_seconds() / (24 * 3600)
        
        # Handle NaT values - fill with a large number (oldest date equivalent)
        max_days = days_ago.max()
        if pd.isna(max_days):
            max_days = 365 * 5  # Default to 5 years if all dates are NaT
        days_ago = days_ago.fillna(max_days)
        
        # Exponential time decay: weight = 2^(-days_ago / half_life)
        # Recent prices (days_ago=0) get weight=1, prices from 1 year ago get weight=0.5
        weights = np.power(2, -days_ago / self.recency_half_life_days)
        
        # Normalize weights to have mean of 1 (preserves sample count influence)
        weights = weights / weights.mean()
        
        return weights.values
        
    def prepare_features(self, df: pd.DataFrame, fit: bool = False) -> np.ndarray:
        """Prepare features for ML model."""
        features = df.copy()
        
        # Encode categorical variables
        for col in self.categorical_columns:
            if col in features.columns:
                if fit:
                    self.encoders[col] = LabelEncoder()
                    features[f'{col}_encoded'] = self.encoders[col].fit_transform(features[col].astype(str))
                else:
                    # Handle unseen categories
                    features[f'{col}_encoded'] = features[col].apply(
                        lambda x: self.encoders[col].transform([str(x)])[0] 
                        if str(x) in self.encoders[col].classes_ else -1
                    )
        
        # Select feature columns
        encoded_cols = [f'{col}_encoded' for col in self.categorical_columns if col in df.columns]
        available_numerical = [col for col in self.numerical_columns if col in df.columns]
        self.feature_columns = available_numerical + encoded_cols
        
        X = features[self.feature_columns].values
        
        if fit:
            X = self.scaler.fit_transform(X)
        else:
            X = self.scaler.transform(X)
            
        return X
    
    def train(self, df: pd.DataFrame, target_col: str = 'sales_price') -> Dict[str, float]:
        """Train the sales price prediction model with proper data cleaning and recency weighting."""
        # Clean data: remove invalid, missing, and outlier data
        df_clean = self.clean_data(df, target_col)
        
        if len(df_clean) < 50:
            raise ValueError(f"KhÃ´ng Ä‘á»§ dá»¯ liá»‡u há»£p lá»‡ Ä‘á»ƒ huáº¥n luyá»‡n model (chá»‰ cÃ³ {len(df_clean)} máº«u, cáº§n Ã­t nháº¥t 50)")
        
        # Calculate recency weights (recent prices have higher weight)
        sample_weights = self.calculate_recency_weights(df_clean)
        
        # Prepare features
        X = self.prepare_features(df_clean, fit=True)
        y = df_clean[target_col].values
        
        # Split data with stratification based on charge_unit if possible
        # Also split sample weights to use during training
        X_train, X_test, y_train, y_test, weights_train, weights_test = train_test_split(
            X, y, sample_weights, test_size=0.2, random_state=42
        )
        
        # Optimized Gradient Boosting model for price prediction
        # - subsample < 1.0 helps prevent overfitting
        # - n_iter_no_change enables early stopping
        # - lower learning rate with more estimators for better generalization
        self.model = GradientBoostingRegressor(
            n_estimators=200,
            learning_rate=0.05,        # Lower learning rate for better generalization
            max_depth=4,               # Shallower trees to prevent overfitting
            min_samples_split=10,      # Require more samples to split
            min_samples_leaf=5,        # Require more samples in leaves
            subsample=0.8,             # Use 80% of data per tree (stochastic GB)
            max_features='sqrt',       # Use sqrt of features for each split
            n_iter_no_change=10,       # Early stopping if no improvement
            validation_fraction=0.1,   # Use 10% for validation
            random_state=42
        )
        # Use sample weights during training to prioritize recent prices
        self.model.fit(X_train, y_train, sample_weight=weights_train)
        
        # Evaluate on test set (weighted by recency)
        y_pred = self.model.predict(X_test)
        mae = mean_absolute_error(y_test, y_pred, sample_weight=weights_test)
        r2 = r2_score(y_test, y_pred, sample_weight=weights_test)
        
        # Cross-validation for more robust metrics (unweighted for comparison)
        cv_scores = cross_val_score(self.model, X, y, cv=5, scoring='neg_mean_absolute_error')
        cv_r2_scores = cross_val_score(self.model, X, y, cv=5, scoring='r2')
        
        return {
            'mae': mae,
            'r2': r2,
            'cv_mae_mean': -cv_scores.mean(),
            'cv_mae_std': cv_scores.std(),
            'cv_r2_mean': cv_r2_scores.mean(),
            'cv_r2_std': cv_r2_scores.std(),
            'train_samples': len(df_clean),
            'removed_samples': len(df) - len(df_clean),
            'target_col': target_col,
            'n_estimators_used': self.model.n_estimators_,
            'recency_weighted': True
        }
    
    def predict(self, df: pd.DataFrame) -> np.ndarray:
        """Predict sales prices for new data."""
        if self.model is None:
            raise ValueError("Model not trained. Please train the model first.")
        
        X = self.prepare_features(df, fit=False)
        return self.model.predict(X)
    
    def get_feature_importance(self) -> pd.DataFrame:
        """Get feature importance from the model."""
        if self.model is None:
            return pd.DataFrame()
        
        importance = pd.DataFrame({
            'feature': self.feature_columns,
            'importance': self.model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        return importance


# ============ Helper Functions ============
def get_tlr(stone_color_type: str, processing_code: str = None) -> float:
    """
    Get TLR (Specific Weight) for stone type.
    Per TÃNH TOÃN & BÃO GIÃ documentation.
    """
    # Check for sawn processing (cáº¯t mÃ¡y = higher TLR)
    if processing_code in ['CUA', 'HON', 'BON'] and 'BASALT' in stone_color_type.upper():
        return TLR_CONSTANTS.get(stone_color_type + '_SAWN', TLR_CONSTANTS.get(stone_color_type, 2.70))
    return TLR_CONSTANTS.get(stone_color_type, TLR_CONSTANTS['DEFAULT'])


def get_hs_factor(dimensions: tuple = None, processing_code: str = None, family: str = None) -> float:
    """
    Get HS (Coating Factor) for product dimensions/type.
    Per TÃNH TOÃN & BÃO GIÃ documentation.
    """
    if dimensions:
        l, w, h = dimensions
        # Check for cube dimensions
        if l == 5 and w == 5 and h == 5:
            return HS_FACTORS['CUBE_5X5X5']
        if l == 8 and w == 8 and h == 8:
            return HS_FACTORS['CUBE_8X8X8']
        if (l == 10 and w == 10 and h == 8) or (l == 20 and w == 10 and h == 8):
            if processing_code in ['DOT', 'DOC', 'DOX']:  # Flamed
                return HS_FACTORS['CUBE_FLAMED_10X10X8']
            return HS_FACTORS['CUBE_10X10X8']
        if l == 15 and w == 15 and h == 12:
            return HS_FACTORS['CUBE_15X15X12']
        # Flamed tile 6cm
        if h == 6 and processing_code in ['DOT', 'DOC', 'DOX']:
            return HS_FACTORS['FLAMED_TILE_6CM']
    
    # Check for palisade
    if family == 'PALISADE' and processing_code in ['CLO', 'CUA']:
        return HS_FACTORS['PALISADE_SAWN']
    
    return HS_FACTORS['DEFAULT']


def calculate_volume_m3(length_cm: float, width_cm: float, height_cm: float, quantity: int = 1) -> float:
    """Calculate volume in mÂ³. Formula: (LÃ—WÃ—H)/1,000,000 Ã— qty"""
    return (length_cm * width_cm * height_cm) / 1_000_000 * quantity


def calculate_area_m2(length_cm: float, width_cm: float, quantity: int = 1) -> float:
    """Calculate area in mÂ². Formula: (LÃ—W)/10,000 Ã— qty"""
    return (length_cm * width_cm) / 10_000 * quantity


def calculate_weight_tons(volume_m3: float, stone_color_type: str, processing_code: str = None,
                          dimensions: tuple = None, family: str = None) -> float:
    """
    Calculate weight in tons.
    Formula: mÂ³ Ã— TLR Ã— HS
    """
    tlr = get_tlr(stone_color_type, processing_code)
    hs = get_hs_factor(dimensions, processing_code, family)
    return volume_m3 * tlr * hs


def convert_price(price: float, from_unit: str, to_unit: str, 
                  height_cm: float = None, tlr: float = 2.70, hs: float = 1.0,
                  length_cm: float = None, width_cm: float = None) -> float:
    """
    Convert price between units (USD/PC, USD/M2, USD/M3, USD/TON).
    Per TÃNH TOÃN & BÃO GIÃ documentation.
    """
    height_m = (height_cm / 100) if height_cm else 0.03
    
    # First convert to price per mÂ³
    if from_unit == 'USD/M3':
        price_m3 = price
    elif from_unit == 'USD/M2':
        price_m3 = price / height_m
    elif from_unit == 'USD/TON':
        price_m3 = price * tlr * hs
    elif from_unit == 'USD/PC':
        if length_cm and width_cm and height_cm:
            vol = (length_cm * width_cm * height_cm) / 1_000_000
            price_m3 = price / vol if vol > 0 else price
        else:
            price_m3 = price * 100  # Rough estimate
    else:
        price_m3 = price
    
    # Then convert from mÂ³ to target unit
    if to_unit == 'USD/M3':
        return price_m3
    elif to_unit == 'USD/M2':
        return price_m3 * height_m
    elif to_unit == 'USD/TON':
        return price_m3 / tlr / hs if tlr > 0 else price_m3
    elif to_unit == 'USD/PC':
        if length_cm and width_cm and height_cm:
            vol = (length_cm * width_cm * height_cm) / 1_000_000
            return price_m3 * vol
        else:
            return price_m3 / 100  # Rough estimate
    else:
        return price_m3


def classify_segment(price_m3: float, height_cm: float = None, family: str = None, 
                     processing_code: str = None) -> str:
    """
    Classify price into segment.
    Per PHÃ‚N KHÃšC Dá»°A TRÃŠN GIÃ VÃ€ Sáº¢N PHáº¨M documentation.
    
    Considers both price AND product characteristics:
    - Super premium: â‰¥$1500/mÂ³ OR thin paving (1-1.5cm), wall/pool covering, decorative
    - Premium: â‰¥$800/mÂ³ OR tiles (2-5cm), slabs, steps
    - Common: â‰¥$400/mÂ³ OR palisades, cubes, tumbled
    - Economy: <$400/mÂ³ OR natural split, thick pavers
    """
    # Check product-based rules first
    if height_cm is not None:
        # Thin paving (1.0-1.5cm) = Super premium
        if height_cm <= 1.5 and family in ['Exterior_Tiles', 'Interior_Tiles']:
            return 'Super premium'
        # Tiles 2-5cm with quality processing = Premium
        if 2.0 <= height_cm <= 5.0 and processing_code in ['DOT', 'DOC', 'DOX', 'HON', 'BON']:
            if price_m3 >= 600:  # Slightly lower threshold for processed tiles
                return 'Premium'
        # Thick natural split (â‰¥6cm) = Economy
        if height_cm >= 6 and processing_code in ['CTA', 'TLO']:
            return 'Economy'
    
    # Check family-based rules
    if family:
        if family in ['ART', 'High-Class']:
            return 'Super premium'
        if family in ['SLAB', 'STAIR']:
            return 'Premium' if price_m3 >= 600 else 'Common'
        if family == 'PALISADE' and processing_code in ['CLO', 'CUA']:
            return 'Common'
    
    # Fall back to price-based classification
    if price_m3 >= 1500:
        return 'Super premium'
    elif price_m3 >= 800:
        return 'Premium'
    elif price_m3 >= 400:
        return 'Common'
    else:
        return 'Economy'

def get_segment_color(segment: str) -> str:
    """Get color for segment."""
    colors = {
        'Super premium': '#9e7cc1',
        'Premium': '#ff6b6b',
        'Common': '#ffd93d',
        'Economy': '#6bcb77'
    }
    return colors.get(segment, '#808080')

def calculate_customer_price(base_price: float, customer_type: str, 
                             segment: str = None, charge_unit: str = 'USD/M3') -> Dict[str, Any]:
    """
    Calculate price adjustments for different customer types.
    Per NGUYÃŠN Táº®C ÃP Dá»¤NG Báº¢NG GIÃ ABCDEF documentation.
    
    Args:
        base_price: The reference price
        customer_type: Customer classification (A-F)
        segment: Product segment for authority range
        charge_unit: Price unit for displaying USD adjustments
    """
    rules = CUSTOMER_PRICING_RULES.get(customer_type, CUSTOMER_PRICING_RULES['C'])
    adj = rules.get('base_adjustment', {'min': 0, 'max': 0})
    
    min_price = round(base_price * (1 + adj['min']), 2)
    max_price = round(base_price * (1 + adj['max']), 2)
    
    # Get authority range based on segment
    authority_range = None
    authority = rules.get('authority')
    if isinstance(authority, dict) and segment:
        authority_range = authority.get(segment)
    
    # Format authority display
    if authority_range:
        if charge_unit == 'USD/M2':
            auth_display = f"Â±{authority_range * 0.05:.1f} USD/mÂ²"  # Approximate mÂ² conversion
        else:
            auth_display = f"Â±{authority_range} USD/mÂ³"
    elif isinstance(authority, str):
        auth_display = authority
    else:
        auth_display = rules.get('label', 'N/A')
    
    return {
        'base_price': base_price,
        'min_price': min_price,
        'max_price': max_price,
        'adjustment_label': rules.get('label', 'N/A'),
        'customer_description': rules.get('description', ''),
        'authority_range': auth_display,
        'volume': rules.get('volume', ''),
        'years': rules.get('years', ''),
    }

def find_similar_products(df: pd.DataFrame, query: Dict, top_n: int = 5) -> pd.DataFrame:
    """Find similar products based on attributes."""
    # Filter by basic criteria
    mask = pd.Series([True] * len(df))
    
    if query.get('stone_color_type'):
        mask &= df['stone_color_type'] == query['stone_color_type']
    
    if query.get('family'):
        mask &= df['family'] == query['family']
    
    filtered_df = df[mask].copy()
    
    if len(filtered_df) == 0:
        return pd.DataFrame()
    
    # Calculate similarity score based on dimensions
    if all(k in query for k in ['length_cm', 'width_cm', 'height_cm']):
        filtered_df['dim_diff'] = (
            abs(filtered_df['length_cm'] - query['length_cm']) +
            abs(filtered_df['width_cm'] - query['width_cm']) +
            abs(filtered_df['height_cm'] - query['height_cm'])
        )
        filtered_df = filtered_df.nsmallest(top_n, 'dim_diff')
    else:
        filtered_df = filtered_df.head(top_n)
    
    return filtered_df


# ============ Similarity-Based Price Predictor ============
class SimilarityPricePredictor:
    """
    Price estimation based on similarity search with priority levels.
    Matches products using criteria from notes.md.
    """
    
    def __init__(self):
        self.data = None
        self.recency_half_life_days = 365
        
    def load_data(self, df: pd.DataFrame):
        """Load and prepare data for similarity search."""
        self.data = df[df['sales_price'].notna() & (df['sales_price'] > 0)].copy()
        # Add stone family for priority 2 matching
        if 'stone_color_type' in self.data.columns:
            self.data['stone_family'] = self.data['stone_color_type'].map(STONE_FAMILY_MAP).fillna('OTHER')
        return len(self.data)
    
    def find_matching_products(
        self, 
        stone_color_type: str,
        processing_code: str,
        length_cm: float,
        width_cm: float,
        height_cm: float,
        family: str,
        customer_regional_group: str,
        charge_unit: str,
        stone_priority: str = 'Æ¯u tiÃªn 1',  # Exact, Same Family, All
        processing_priority: str = 'Æ¯u tiÃªn 1',  # Exact, All
        dimension_priority: str = 'Æ¯u tiÃªn 1 - ÄÃºng kÃ­ch thÆ°á»›c',
        region_priority: str = 'Æ¯u tiÃªn 1',  # Exact, All
    ) -> pd.DataFrame:
        """
        Find matching products based on priority criteria from notes.md.
        
        Priority Levels:
        - Æ¯u tiÃªn 1: Exact match
        - Æ¯u tiÃªn 2: Same family / small tolerance
        - Æ¯u tiÃªn 3: All / large tolerance
        """
        if self.data is None or len(self.data) == 0:
            return pd.DataFrame()
        
        df = self.data.copy()
        mask = pd.Series([True] * len(df), index=df.index)
        
        # 1. Stone Type Filter
        query_family = STONE_FAMILY_MAP.get(stone_color_type, 'OTHER')
        if stone_priority == 'Æ¯u tiÃªn 1':
            mask &= df['stone_color_type'] == stone_color_type
        elif stone_priority == 'Æ¯u tiÃªn 2':
            mask &= df['stone_family'] == query_family
        # Æ¯u tiÃªn 3: No filter (All stones)
        
        # 2. Processing Filter
        if processing_priority == 'Æ¯u tiÃªn 1' and processing_code:
            mask &= df['processing_code'] == processing_code
        # Æ¯u tiÃªn 2+: No filter (All processing types)
        
        # 3. Family (Application) Filter
        if family:
            mask &= df['family'] == family
        
        # 4. Charge Unit Filter
        if charge_unit:
            mask &= df['charge_unit'] == charge_unit
        
        # 5. Regional Group Filter
        if 'customer_regional_group' in df.columns:
            if region_priority == 'Æ¯u tiÃªn 1' and customer_regional_group:
                mask &= df['customer_regional_group'] == customer_regional_group
            # Æ¯u tiÃªn 2+: No filter (All regions)
        
        # Apply initial filters
        df_filtered = df[mask].copy()
        
        if len(df_filtered) == 0:
            return pd.DataFrame()
        
        # 6. Dimension Filter with tolerances
        tolerances = DIMENSION_PRIORITY_LEVELS.get(dimension_priority, {'height': 0, 'width': 0, 'length': 0})
        
        dim_mask = (
            (abs(df_filtered['height_cm'] - height_cm) <= tolerances['height']) &
            (abs(df_filtered['width_cm'] - width_cm) <= tolerances['width']) &
            (abs(df_filtered['length_cm'] - length_cm) <= tolerances['length'])
        )
        
        df_matches = df_filtered[dim_mask].copy()
        
        return df_matches
    
    def calculate_recency_weights(self, df: pd.DataFrame) -> pd.Series:
        """Calculate recency weights for price averaging."""
        if 'created_date' not in df.columns or len(df) == 0:
            return pd.Series([1.0] * len(df), index=df.index)
        
        dates = pd.to_datetime(df['created_date'], errors='coerce', utc=True)
        reference_date = pd.Timestamp.now(tz='UTC')
        days_ago = (reference_date - dates).dt.total_seconds() / (24 * 3600)
        
        max_days = days_ago.max()
        if pd.isna(max_days):
            max_days = 365 * 5
        days_ago = days_ago.fillna(max_days)
        
        weights = np.power(2, -days_ago / self.recency_half_life_days)
        return weights
    
    def estimate_price(self, matches: pd.DataFrame) -> Dict[str, Any]:
        """
        Estimate price from matching products.
        Uses recency-weighted average.
        """
        if len(matches) == 0:
            return {
                'estimated_price': None,
                'min_price': None,
                'max_price': None,
                'median_price': None,
                'match_count': 0,
                'confidence': 'none'
            }
        
        prices = matches['sales_price']
        weights = self.calculate_recency_weights(matches)
        
        # Weighted average
        weighted_price = np.average(prices, weights=weights)
        
        # Confidence based on match count
        if len(matches) >= 10:
            confidence = 'high'
        elif len(matches) >= 5:
            confidence = 'medium'
        elif len(matches) >= 2:
            confidence = 'low'
        else:
            confidence = 'very_low'
        
        return {
            'estimated_price': round(weighted_price, 2),
            'min_price': round(prices.min(), 2),
            'max_price': round(prices.max(), 2),
            'median_price': round(prices.median(), 2),
            'match_count': len(matches),
            'confidence': confidence
        }
    
    def predict_with_escalation(
        self,
        stone_color_type: str,
        processing_code: str,
        length_cm: float,
        width_cm: float,
        height_cm: float,
        family: str,
        customer_regional_group: str,
        charge_unit: str,
    ) -> Tuple[Dict[str, Any], pd.DataFrame, str]:
        """
        Try to find matches with automatic priority escalation.
        Starts with Æ¯u tiÃªn 1 and escalates if no matches found.
        
        Returns:
            - Price estimation dict
            - Matching products DataFrame
            - Priority level used
        """
        priority_levels = [
            ('Æ¯u tiÃªn 1', 'Æ¯u tiÃªn 1', 'Æ¯u tiÃªn 1 - ÄÃºng kÃ­ch thÆ°á»›c', 'Æ¯u tiÃªn 1'),
            ('Æ¯u tiÃªn 1', 'Æ¯u tiÃªn 1', 'Æ¯u tiÃªn 2 - Sai lá»‡ch nhá»', 'Æ¯u tiÃªn 1'),
            ('Æ¯u tiÃªn 1', 'Æ¯u tiÃªn 2', 'Æ¯u tiÃªn 2 - Sai lá»‡ch nhá»', 'Æ¯u tiÃªn 2'),
            ('Æ¯u tiÃªn 2', 'Æ¯u tiÃªn 2', 'Æ¯u tiÃªn 2 - Sai lá»‡ch nhá»', 'Æ¯u tiÃªn 2'),
            ('Æ¯u tiÃªn 2', 'Æ¯u tiÃªn 2', 'Æ¯u tiÃªn 3 - Sai lá»‡ch lá»›n', 'Æ¯u tiÃªn 2'),
            ('Æ¯u tiÃªn 3', 'Æ¯u tiÃªn 2', 'Æ¯u tiÃªn 3 - Sai lá»‡ch lá»›n', 'Æ¯u tiÃªn 2'),
        ]
        
        for stone_p, proc_p, dim_p, region_p in priority_levels:
            matches = self.find_matching_products(
                stone_color_type=stone_color_type,
                processing_code=processing_code,
                length_cm=length_cm,
                width_cm=width_cm,
                height_cm=height_cm,
                family=family,
                customer_regional_group=customer_regional_group,
                charge_unit=charge_unit,
                stone_priority=stone_p,
                processing_priority=proc_p,
                dimension_priority=dim_p,
                region_priority=region_p,
            )
            
            if len(matches) > 0:
                estimation = self.estimate_price(matches)
                priority_used = f"ÄÃ¡: {stone_p}, Gia cÃ´ng: {proc_p}, KÃ­ch thÆ°á»›c: {dim_p}, Khu vá»±c: {region_p}"
                return estimation, matches, priority_used
        
        return self.estimate_price(pd.DataFrame()), pd.DataFrame(), "KhÃ´ng tÃ¬m tháº¥y"


# ============ Streamlit App ============
def main():
    # Header
    st.markdown('<h1 class="main-header">ğŸ’ Stone Price Predictor</h1>', unsafe_allow_html=True)
    st.markdown('<p style="text-align: center; color: #666;">Dá»± Ä‘oÃ¡n giÃ¡ sáº£n pháº©m Ä‘Ã¡ tá»± nhiÃªn vá»›i AI vÃ  dá»¯ liá»‡u Salesforce</p>', unsafe_allow_html=True)
    
    # Initialize session state
    if 'data' not in st.session_state:
        st.session_state.data = None
    if 'model' not in st.session_state:
        st.session_state.model = None
    if 'model_metrics' not in st.session_state:
        st.session_state.model_metrics = None
    
    # Sidebar
    with st.sidebar:
        st.markdown("## ğŸ’ Stone Price Predictor")
        st.title("âš™ï¸ Cáº¥u hÃ¬nh")
        
        # Data source - Salesforce only
        st.markdown("**Nguá»“n dá»¯ liá»‡u:** Salesforce Contract Products")
        
        # Optional account code filter for Salesforce
        account_filter = st.text_input(
            "MÃ£ khÃ¡ch hÃ ng (tÃ¹y chá»n)",
            placeholder="e.g., ACC-001",
            help="Lá»c theo Account_Code_C__c"
        )
        
        if st.button("ğŸ”„ Táº£i / LÃ m má»›i dá»¯ liá»‡u tá»« Salesforce", use_container_width=True):
            with st.spinner("Äang táº£i dá»¯ liá»‡u tá»« Salesforce..."):
                if SALESFORCE_AVAILABLE:
                    try:
                        loader = SalesforceDataLoader()
                        df = loader.get_contract_products(account_code=account_filter if account_filter else None)
                        if len(df) > 0:
                            st.session_state.data = df
                            st.success(f"âœ… ÄÃ£ táº£i {len(df)} sáº£n pháº©m tá»« Salesforce!")
                        else:
                            st.warning("âš ï¸ KhÃ´ng tÃ¬m tháº¥y dá»¯ liá»‡u tá»« Salesforce.")
                    except Exception as e:
                        st.error(f"âŒ Lá»—i káº¿t ná»‘i Salesforce: {str(e)}")
                else:
                    st.error("âŒ Salesforce chÆ°a Ä‘Æ°á»£c cáº¥u hÃ¬nh. Vui lÃ²ng kiá»ƒm tra file .env")
        
        if st.session_state.data is not None:
            if st.button("âš™ï¸ Tiá»n xá»­ lÃ½ dá»¯ liá»‡u", use_container_width=True):
                with st.spinner("Äang tiá»n xá»­ lÃ½ dá»¯ liá»‡u..."):
                    predictor = SimilarityPricePredictor()
                    count = predictor.load_data(st.session_state.data)
                    st.session_state.model = predictor
                    st.session_state.model_metrics = {'loaded_samples': count}
                    st.success(f"âœ… ÄÃ£ sáºµn sÃ ng vá»›i {count:,} sáº£n pháº©m cÃ³ giÃ¡!")
        
        st.divider()
    
    # Main content
    if st.session_state.data is None:
        st.info("ğŸ‘ˆ Vui lÃ²ng táº£i dá»¯ liá»‡u tá»« sidebar Ä‘á»ƒ báº¯t Ä‘áº§u")
        
        # Show sample pricing matrix
        st.subheader("ğŸ“Š Ma tráº­n giÃ¡ theo phÃ¢n khÃºc vÃ  loáº¡i sáº£n pháº©m")
        
        matrix_data = {
            'Loáº¡i sáº£n pháº©m': ['ÄÃ¡ lÃ¡t má»ng 1-1.5cm', 'ÄÃ¡ ná»™i ngoáº¡i tháº¥t 2-5cm', 'ÄÃ¡ báº­c thang', 'ÄÃ¡ cÃ¢y', 'ÄÃ¡ má»¹ nghá»‡'],
            'Economy (<$400/mÂ³)': ['ÄÃ¡ máº», Ä‘Ã¡ gÃµ tay', 'ÄÃ¡ cÆ¡ báº£n', '-', 'ÄÃ¡ cÃ¢y cÆ°a lá»™t', 'CÆ¡ báº£n'],
            'Common ($400-800/mÂ³)': ['ÄÃ¡ 1 máº·t Ä‘á»‘t', 'ÄÃ¡ lÃ¡t thÃ´ng dá»¥ng', 'ÄÃ¡ nguyÃªn khá»‘i', 'Äá»‘t cháº£i', 'Trung bÃ¬nh'],
            'Premium ($800-1500/mÂ³)': ['ÄÃ¡ xá»­ lÃ½ Ä‘áº·c biá»‡t', 'ÄÃ¡ cao cáº¥p', 'ÄÃ¡ á»‘p báº­c thang', 'Xá»­ lÃ½ nhiá»u máº·t', 'Cao cáº¥p'],
            'Super Premium (>$1500/mÂ³)': ['ÄÃ¡ má»ng Ä‘áº·c biá»‡t', 'ÄÃ¡ náº¯p tÆ°á»ng, há»“ bÆ¡i', 'Äáº·c biá»‡t', 'Äáº·c biá»‡t', 'Má»¹ nghá»‡ Ä‘áº·c biá»‡t']
        }
        st.dataframe(pd.DataFrame(matrix_data), use_container_width=True)
        return
    
    # Tabs
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "ğŸ”® Dá»± Ä‘oÃ¡n giÃ¡", 
        "ğŸ“Š PhÃ¢n tÃ­ch dá»¯ liá»‡u", 
        "ğŸ” TÃ¬m sáº£n pháº©m tÆ°Æ¡ng tá»±",
        "ğŸ“ Báº£ng tra cá»©u",
        "ğŸ“‹ Dá»¯ liá»‡u chi tiáº¿t"
    ])
    
    # Tab 1: Price Prediction
    with tab1:
        st.subheader("ğŸ”® Æ¯á»›c tÃ­nh giÃ¡ sáº£n pháº©m (Similarity-Based)")
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.markdown("#### ThÃ´ng tin sáº£n pháº©m")
            
            family = st.selectbox("Loáº¡i sáº£n pháº©m (Family)", PRODUCT_FAMILIES)
            stone_color = st.selectbox("MÃ u Ä‘Ã¡ (Stone Color)", STONE_COLOR_TYPES)
            
            # Main Processing dropdown (no empty/OTHER option)
            processing_code = st.selectbox(
                "Main Processing",
                options=[code for code, name in PROCESSING_CODES],
                format_func=lambda x: f"{x} - {dict(PROCESSING_CODES).get(x, 'Other')}",
                index=0
            )
            
            col_dim1, col_dim2, col_dim3 = st.columns(3)
            with col_dim1:
                length = st.number_input("DÃ i (cm)", min_value=1, max_value=300, value=30)
            with col_dim2:
                width = st.number_input("Rá»™ng (cm)", min_value=1, max_value=300, value=30)
            with col_dim3:
                height = st.number_input("DÃ y (cm)", min_value=0.5, max_value=50.0, value=3.0, step=0.5)
            
            charge_unit = st.selectbox("ÄÆ¡n vá»‹ tÃ­nh giÃ¡", CHARGE_UNITS)
            
            # Customer Regional Group (NhÃ³m Khu vá»±c KH)
            customer_regional_group = st.selectbox(
                "NhÃ³m Khu vá»±c KH (Regional Group)",
                options=[code for code, name in CUSTOMER_REGIONAL_GROUPS if code],
                format_func=lambda x: x,
                index=0,
                help="NhÃ³m Ä‘áº§u 0-9 theo khu vá»±c khÃ¡ch hÃ ng"
            )
            
            st.divider()
            
            # Rules and Formulas expanders
            with st.expander("ğŸ“‹ Quy táº¯c Ä‘á»‹nh giÃ¡"):
                st.markdown("""
**PhÃ¢n khÃºc giÃ¡ (USD/mÂ³):**
| PhÃ¢n khÃºc | GiÃ¡ | Sáº£n pháº©m |
|-----------|-----|----------|
| ğŸŸ£ Super Premium | â‰¥ $1,500 | ÄÃ¡ má»ng 1-1.5cm, náº¯p tÆ°á»ng, má»¹ nghá»‡ |
| ğŸ”´ Premium | â‰¥ $800 | ÄÃ¡ lÃ¡t 2-5cm, slab, báº­c thang |
| ğŸŸ¡ Common | â‰¥ $400 | ÄÃ¡ cÃ¢y, cubic Ä‘á»‘t, quay máº» |
| ğŸŸ¢ Economy | < $400 | ÄÃ¡ gÃµ tay, cubic cháº» tay |
                """)
            
            with st.expander("ğŸ‘¥ PhÃ¢n loáº¡i khÃ¡ch hÃ ng"):
                st.markdown("""
| Loáº¡i | MÃ´ táº£ | Äiá»u chá»‰nh |
|------|-------|------------|
| **A** | ThÃ¢n thiáº¿t >10 nÄƒm | -1.5% Ä‘áº¿n -3% |
| **B** | Lá»›n 3-10 nÄƒm | -2% Ä‘áº¿n -4% |
| **C** | Phá»• thÃ´ng | GiÃ¡ chuáº©n |
| **D** | Má»›i, nhá» | +3% Ä‘áº¿n +6% |
| **E** | Sáº£n pháº©m má»›i | Ã—1.08-1.15 |
| **F** | Dá»± Ã¡n | Ã—1.08-1.15 |
                """)
            
            with st.expander("ğŸ“ CÃ´ng thá»©c tÃ­nh toÃ¡n"):
                st.markdown("""
**Thá»ƒ tÃ­ch:** `mÂ³ = (DÃ—RÃ—C) / 1.000.000 Ã— SL`

**Diá»‡n tÃ­ch:** `mÂ² = (DÃ—R) / 10.000 Ã— SL`

**Trá»ng lÆ°á»£ng:** `Táº¥n = mÂ³ Ã— TLR Ã— HS`

**Quy Ä‘á»•i giÃ¡:**
- `GiÃ¡/mÂ² = GiÃ¡/mÂ³ Ã— Cao(m)`
- `GiÃ¡/Táº¥n = GiÃ¡/mÂ³ Ã· TLR Ã· HS`

**TLR tham kháº£o:**
- Absolute Basalt: 2.95
- Black Basalt: 2.65-2.70
- Granite thÆ°á»ng: 2.70
- Dark Grey Granite: 2.90
                """)
            
            with st.expander("ğŸ¯ TiÃªu chÃ­ tÃ¬m kiáº¿m"):
                st.markdown("""
| TiÃªu chÃ­ | Æ¯u tiÃªn 1 | Æ¯u tiÃªn 2 | Æ¯u tiÃªn 3 |
|----------|-----------|-----------|-----------|
| **Loáº¡i Ä‘Ã¡** | ÄÃºng mÃ u Ä‘Ã¡ | CÃ¹ng chá»§ng loáº¡i | Táº¥t cáº£ loáº¡i Ä‘Ã¡ |
| **Gia cÃ´ng** | ÄÃºng loáº¡i gia cÃ´ng | Táº¥t cáº£ gia cÃ´ng | - |
| **Cao (cm)** | Â±0 | Â±1 | Â±2 |
| **Rá»™ng (cm)** | Â±0 | Â±5 | Â±10 |
| **DÃ i (cm)** | Â±0 | Â±10 | Â±20 |
| **Khu vá»±c** | ÄÃºng khu vá»±c | Táº¥t cáº£ khu vá»±c | - |
                """)
            
            customer_type = st.selectbox(
                "PhÃ¢n loáº¡i khÃ¡ch hÃ ng",
                ['C', 'A', 'B', 'D', 'E', 'F'],
                format_func=lambda x: f"{x} - {CUSTOMER_PRICING_RULES[x]['description']}"
            )
            
            st.divider()
            st.markdown("#### ğŸšï¸ Má»©c Ä‘á»™ Æ°u tiÃªn tÃ¬m kiáº¿m")
            
            # Priority level selectors per notes.md
            col_p1, col_p2 = st.columns(2)
            with col_p1:
                stone_priority = st.selectbox(
                    "Loáº¡i Ä‘Ã¡",
                    options=['Æ¯u tiÃªn 1', 'Æ¯u tiÃªn 2', 'Æ¯u tiÃªn 3'],
                    format_func=lambda x: {
                        'Æ¯u tiÃªn 1': '1 - ÄÃºng mÃ u Ä‘Ã¡',
                        'Æ¯u tiÃªn 2': '2 - CÃ¹ng chá»§ng loáº¡i',
                        'Æ¯u tiÃªn 3': '3 - Táº¥t cáº£ loáº¡i Ä‘Ã¡',
                    }[x],
                    index=2  # Default: Æ¯u tiÃªn 3 (Táº¥t cáº£ loáº¡i Ä‘Ã¡)
                )
                processing_priority = st.selectbox(
                    "Gia cÃ´ng",
                    options=['Æ¯u tiÃªn 1', 'Æ¯u tiÃªn 2'],
                    format_func=lambda x: {
                        'Æ¯u tiÃªn 1': '1 - ÄÃºng loáº¡i gia cÃ´ng',
                        'Æ¯u tiÃªn 2': '2 - Táº¥t cáº£ gia cÃ´ng',
                    }[x],
                    index=1  # Default: Æ¯u tiÃªn 2 (Táº¥t cáº£ gia cÃ´ng)
                )
            with col_p2:
                dimension_priority = st.selectbox(
                    "KÃ­ch thÆ°á»›c",
                    options=list(DIMENSION_PRIORITY_LEVELS.keys()),
                    index=0  # Default: Æ¯u tiÃªn 1 (ÄÃºng kÃ­ch thÆ°á»›c)
                )
                region_priority = st.selectbox(
                    "Khu vá»±c KH",
                    options=['Æ¯u tiÃªn 1', 'Æ¯u tiÃªn 2'],
                    format_func=lambda x: {
                        'Æ¯u tiÃªn 1': '1 - ÄÃºng khu vá»±c',
                        'Æ¯u tiÃªn 2': '2 - Táº¥t cáº£ khu vá»±c',
                    }[x],
                    index=1  # Default: Æ¯u tiÃªn 2 (Táº¥t cáº£ khu vá»±c)
                )
            
            predict_btn = st.button("ğŸ” TÃ¬m kiáº¿m & Æ¯á»›c tÃ­nh giÃ¡", type="primary", use_container_width=True)
        
        with col2:
            if predict_btn and st.session_state.model is not None:
                # Use similarity-based predictor
                predictor = st.session_state.model
                
                matches = predictor.find_matching_products(
                    stone_color_type=stone_color,
                    processing_code=processing_code,
                    length_cm=length,
                    width_cm=width,
                    height_cm=height,
                    family=family,
                    customer_regional_group=customer_regional_group,
                    charge_unit=charge_unit,
                    stone_priority=stone_priority,
                    processing_priority=processing_priority,
                    dimension_priority=dimension_priority,
                    region_priority=region_priority,
                )
                
                estimation = predictor.estimate_price(matches)
                
                st.markdown("#### ğŸ“Š Káº¿t quáº£ Æ°á»›c tÃ­nh")
                
                if estimation['estimated_price'] is not None:
                    # Confidence indicator
                    confidence_colors = {
                        'high': '#6bcb77',
                        'medium': '#ffd93d',
                        'low': '#ff6b6b',
                        'very_low': '#9e7cc1',
                    }
                    confidence_labels = {
                        'high': 'Cao (â‰¥10 máº«u)',
                        'medium': 'Trung bÃ¬nh (5-9 máº«u)',
                        'low': 'Tháº¥p (2-4 máº«u)',
                        'very_low': 'Ráº¥t tháº¥p (1 máº«u)',
                    }
                    conf_color = confidence_colors.get(estimation['confidence'], '#808080')
                    conf_label = confidence_labels.get(estimation['confidence'], 'N/A')
                    
                    st.markdown(f"""
                    <div style="background-color: {conf_color}; padding: 15px; border-radius: 10px; text-align: center; margin-bottom: 20px;">
                        <h3 style="color: white; margin: 0;">Äá»™ tin cáº­y: {conf_label}</h3>
                    </div>
                    """, unsafe_allow_html=True)
                    
                    # Main estimated price
                    st.metric(f"ğŸ’° GiÃ¡ Æ°á»›c tÃ­nh ({charge_unit})", f"${estimation['estimated_price']:,.2f}")
                    
                    # Price range
                    st.markdown(f"Khoáº£ng giÃ¡ thá»±c táº¿: **\\${estimation['min_price']:,.2f}** â€“ **\\${estimation['max_price']:,.2f}**")
                    st.markdown(f"**GiÃ¡ trung vá»‹:** ${estimation['median_price']:,.2f}")
                    st.markdown(f"**Sá»‘ máº«u khá»›p:** {estimation['match_count']}")
                    
                    st.divider()
                    
                    # Calculate segment for pricing
                    est_price_m3 = convert_price(
                        estimation['estimated_price'], charge_unit, 'USD/M3',
                        height_cm=height, length_cm=length, width_cm=width,
                        tlr=get_tlr(stone_color, processing_code)
                    )
                    segment = classify_segment(est_price_m3, height_cm=height, family=family, processing_code=processing_code)
                    
                    # Customer price adjustment with segment awareness
                    price_info = calculate_customer_price(
                        estimation['estimated_price'], customer_type, 
                        segment=segment, charge_unit=charge_unit
                    )
                    st.markdown(f"**ğŸ‘¤ GiÃ¡ theo khÃ¡ch hÃ ng loáº¡i {customer_type}:**")
                    st.markdown(f"- {price_info['customer_description']}")
                    st.markdown(f"- Khoáº£ng giÃ¡: **\\${price_info['min_price']:,.2f}** â€“ **\\${price_info['max_price']:,.2f}**")
                    st.markdown(f"- Äiá»u chá»‰nh: {price_info['adjustment_label']}")
                    st.markdown(f"- Quyá»n tá»± quyáº¿t: {price_info['authority_range']}")
                    
                else:
                    st.warning("âš ï¸ KhÃ´ng tÃ¬m tháº¥y sáº£n pháº©m phÃ¹ há»£p. Thá»­ má»Ÿ rá»™ng tiÃªu chÃ­ tÃ¬m kiáº¿m (Æ¯u tiÃªn 2 hoáº·c 3).")
                
                st.divider()
                
                # Product info summary with weight calculation
                st.markdown("**ğŸ“¦ ThÃ´ng tin sáº£n pháº©m:**")
                volume_m3 = calculate_volume_m3(length, width, height)
                area_m2 = calculate_area_m2(length, width)
                tlr = get_tlr(stone_color, processing_code)
                hs = get_hs_factor((length, width, height), processing_code, family)
                weight_tons = calculate_weight_tons(volume_m3, stone_color, processing_code, (length, width, height), family)
                
                col_info1, col_info2 = st.columns(2)
                with col_info1:
                    st.markdown(f"- KÃ­ch thÆ°á»›c: {length} x {width} x {height} cm")
                    st.markdown(f"- Thá»ƒ tÃ­ch: {volume_m3:.6f} mÂ³")
                    st.markdown(f"- Diá»‡n tÃ­ch: {area_m2:.4f} mÂ²")
                with col_info2:
                    st.markdown(f"- TLR: {tlr} táº¥n/mÂ³")
                    st.markdown(f"- HS: {hs}")
                    st.markdown(f"- Khá»‘i lÆ°á»£ng: **{weight_tons:.4f} táº¥n**")
                
        # ============ MATCHING PRODUCTS (Full Width) ============
        if predict_btn and st.session_state.model is not None:
            st.divider()
            st.markdown("#### ğŸ“‹ Sáº£n pháº©m trong há»‡ thá»‘ng khá»›p tiÃªu chÃ­")
            
            if len(matches) > 0:
                st.success(f"âœ… TÃ¬m tháº¥y **{len(matches)}** sáº£n pháº©m khá»›p tiÃªu chÃ­!")
                
                # Statistics
                match_prices = matches['sales_price']
                stat_col1, stat_col2, stat_col3, stat_col4 = st.columns(4)
                with stat_col1:
                    st.metric("Tháº¥p nháº¥t", f"${match_prices.min():,.2f}")
                with stat_col2:
                    st.metric("Cao nháº¥t", f"${match_prices.max():,.2f}")
                with stat_col3:
                    st.metric("Trung bÃ¬nh", f"${match_prices.mean():,.2f}")
                with stat_col4:
                    st.metric("Trung vá»‹", f"${match_prices.median():,.2f}")
                
                # Show table of ALL matches with Regional Group included
                display_cols = [
                    'contract_product_name', 'contract_name', 'account_code',
                    'customer_regional_group',  # Regional Group now visible
                    'sku', 'processing_code', 'processing_name',
                    'stone_color_type', 'family', 'segment',
                    'length_cm', 'width_cm', 'height_cm',
                    'charge_unit', 'sales_price', 'price_m3',
                    'created_date', 'fy_year',
                ]
                available_cols = [col for col in display_cols if col in matches.columns]
                
                # Column config for headers
                col_config = {
                    'sku': st.column_config.TextColumn('SKU'),
                    'processing_code': st.column_config.TextColumn('Main Processing Code'),
                    'processing_name': st.column_config.TextColumn('Main Processing'),
                    'customer_regional_group': st.column_config.TextColumn('Regional Group'),
                }
                
                with st.expander(f"ğŸ“‹ Xem danh sÃ¡ch {len(matches)} sáº£n pháº©m khá»›p", expanded=True):
                    st.dataframe(matches[available_cols], use_container_width=True, height=300, column_config=col_config)
            else:
                st.info("âš ï¸ KhÃ´ng tÃ¬m tháº¥y sáº£n pháº©m phÃ¹ há»£p. Thá»­ má»Ÿ rá»™ng tiÃªu chÃ­ (Æ¯u tiÃªn 2 hoáº·c 3).")
        
        elif predict_btn and st.session_state.model is None:
            st.warning("âš ï¸ Vui lÃ²ng chuáº©n bá»‹ tÃ¬m kiáº¿m trÆ°á»›c (nÃºt ğŸ” á»Ÿ sidebar)")
        elif not predict_btn:
            pass  # User hasn't clicked yet
    
    # Tab 2: Data Analysis
    with tab2:
        st.subheader("ğŸ“Š PhÃ¢n tÃ­ch dá»¯ liá»‡u giÃ¡")
        
        df = st.session_state.data.copy()
        
        # Clean data: remove products with price 0, missing, or negative
        df_clean = df[df['sales_price'].notna() & (df['sales_price'] > 0)]
        
        # Show data quality info
        total_products = len(df)
        valid_products = len(df_clean)
        excluded_products = total_products - valid_products
        
        if excluded_products > 0:
            st.info(f"ğŸ“Š ÄÃ£ loáº¡i bá» {excluded_products:,} sáº£n pháº©m cÃ³ giÃ¡ = 0, Ã¢m hoáº·c thiáº¿u. PhÃ¢n tÃ­ch vá»›i {valid_products:,} / {total_products:,} sáº£n pháº©m.")
        
        # Summary metrics using sales_price (clean data)
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ğŸ“¦ Sáº£n pháº©m há»£p lá»‡", f"{valid_products:,}")
        with col2:
            st.metric("ğŸ’° GiÃ¡ TB (Sales Price)", f"${df_clean['sales_price'].mean():,.2f}")
        with col3:
            st.metric("ğŸ“ˆ GiÃ¡ cao nháº¥t", f"${df_clean['sales_price'].max():,.2f}")
        with col4:
            st.metric("ğŸ“‰ GiÃ¡ tháº¥p nháº¥t", f"${df_clean['sales_price'].min():,.2f}")
        
        st.divider()
        
        # Charts
        chart_col1, chart_col2 = st.columns(2)
        
        with chart_col1:
            # Price distribution by segment (using clean data)
            segment_counts = df_clean['segment'].value_counts()
            fig_segment = px.pie(
                values=segment_counts.values,
                names=segment_counts.index,
                title="PhÃ¢n bá»‘ theo phÃ¢n khÃºc",
                color=segment_counts.index,
                color_discrete_map={
                    'Super premium': '#9e7cc1',
                    'Premium': '#ff6b6b',
                    'Common': '#ffd93d',
                    'Economy': '#6bcb77'
                }
            )
            st.plotly_chart(fig_segment, use_container_width=True)
        
        with chart_col2:
            # Average sales_price by family (using clean data)
            avg_by_family = df_clean.groupby('family')['sales_price'].mean().sort_values(ascending=True)
            fig_family = px.bar(
                x=avg_by_family.values,
                y=avg_by_family.index,
                orientation='h',
                title="GiÃ¡ bÃ¡n trung bÃ¬nh theo loáº¡i sáº£n pháº©m",
                labels={'x': 'Sales Price (USD)', 'y': 'Loáº¡i sáº£n pháº©m'}
            )
            fig_family.update_traces(marker_color='#667eea')
            st.plotly_chart(fig_family, use_container_width=True)
        
        # Price by stone type (using clean data)
        st.markdown("#### ğŸ’ GiÃ¡ bÃ¡n theo loáº¡i Ä‘Ã¡")
        fig_stone = px.box(
            df_clean,
            x='stone_color_type',
            y='sales_price',
            color='stone_color_type',
            title="PhÃ¢n bá»‘ giÃ¡ bÃ¡n theo mÃ u Ä‘Ã¡",
            labels={'sales_price': 'Sales Price (USD)', 'stone_color_type': 'Stone Color Type'}
        )
        st.plotly_chart(fig_stone, use_container_width=True)
        
        # Price vs dimensions (using clean data)
        st.markdown("#### ğŸ“ GiÃ¡ bÃ¡n theo kÃ­ch thÆ°á»›c")
        fig_scatter = px.scatter(
            df_clean,
            x='volume_m3',
            y='sales_price',
            color='segment',
            size='height_cm',
            hover_data=['contract_product_name', 'family'],
            title="Sales Price vs Thá»ƒ tÃ­ch",
            labels={'sales_price': 'Sales Price (USD)', 'volume_m3': 'Volume (mÂ³)'},
            color_discrete_map={
                'Super premium': '#9e7cc1',
                'Premium': '#ff6b6b',
                'Common': '#ffd93d',
                'Economy': '#6bcb77'
            }
        )
        st.plotly_chart(fig_scatter, use_container_width=True)
    
    # Tab 3: Similar Products
    with tab3:
        st.subheader("ğŸ” TÃ¬m sáº£n pháº©m tÆ°Æ¡ng tá»±")
        
        col1, col2 = st.columns([1, 2])
        
        with col1:
            st.markdown("#### TiÃªu chÃ­ tÃ¬m kiáº¿m")
            search_family = st.selectbox("Loáº¡i sáº£n pháº©m", [''] + PRODUCT_FAMILIES, key='search_family')
            search_stone = st.selectbox("MÃ u Ä‘Ã¡", [''] + STONE_COLOR_TYPES, key='search_stone')
            
            # Processing code dropdown
            search_processing = st.selectbox(
                "Main Processing",
                options=[code for code, name in PROCESSING_CODES_SEARCH],
                format_func=lambda x: f"{x} - {dict(PROCESSING_CODES_SEARCH).get(x, 'All')}" if x else "All",
                key='search_processing'
            )
            
            # Customer Regional Group filter
            search_regional_group = st.selectbox(
                "NhÃ³m Khu vá»±c KH (Regional Group)",
                options=[code for code, name in CUSTOMER_REGIONAL_GROUPS],
                format_func=lambda x: x if x else "All",
                key='search_regional_group',
                help="Lá»c theo nhÃ³m khu vá»±c khÃ¡ch hÃ ng"
            )
            
            search_col1, search_col2, search_col3 = st.columns(3)
            with search_col1:
                search_length = st.number_input("DÃ i (cm)", min_value=0, value=30, key='search_l')
            with search_col2:
                search_width = st.number_input("Rá»™ng (cm)", min_value=0, value=30, key='search_w')
            with search_col3:
                search_height = st.number_input("DÃ y (cm)", min_value=0.0, value=3.0, key='search_h')
            
            st.divider()
            
            # Show related checkbox and slider
            show_related = st.checkbox("ğŸ“‹ Hiá»ƒn thá»‹ sáº£n pháº©m liÃªn quan", value=False, 
                                       help="Hiá»ƒn thá»‹ cÃ¡c sáº£n pháº©m cÃ³ Ä‘áº·c Ä‘iá»ƒm tÆ°Æ¡ng tá»± náº¿u khÃ´ng tÃ¬m tháº¥y káº¿t quáº£ chÃ­nh xÃ¡c")
            
            if show_related:
                related_count = st.slider("Sá»‘ sáº£n pháº©m liÃªn quan", 5, 50, 20)
            
            search_btn = st.button("ğŸ” TÃ¬m kiáº¿m", type="primary", use_container_width=True)
        
        with col2:
            if search_btn:
                df = st.session_state.data.copy()
                
                # Clean data for searching
                df_clean = df[df['sales_price'].notna() & (df['sales_price'] > 0)].copy()
                df_clean = df_clean.reset_index(drop=True)  # Reset index to avoid alignment issues
                
                # Step 1: Find EXACT matches
                exact_mask = pd.Series([True] * len(df_clean), index=df_clean.index)
                
                if search_family:
                    exact_mask &= df_clean['family'] == search_family
                if search_stone:
                    exact_mask &= df_clean['stone_color_type'] == search_stone
                if search_processing and 'processing_code' in df_clean.columns:
                    exact_mask &= df_clean['processing_code'] == search_processing
                if search_regional_group and 'customer_regional_group' in df_clean.columns:
                    exact_mask &= df_clean['customer_regional_group'] == search_regional_group
                if search_length > 0:
                    exact_mask &= df_clean['length_cm'] == search_length
                if search_width > 0:
                    exact_mask &= df_clean['width_cm'] == search_width
                if search_height > 0:
                    exact_mask &= df_clean['height_cm'] == search_height
                
                exact_matches = df_clean[exact_mask]
                
                # Include processing columns and regional group in display
                display_cols = ['contract_product_name', 'family', 'stone_color_type', 
                                'sku', 'processing_code', 'processing_name',
                                'customer_regional_group',
                                'length_cm', 'width_cm', 'height_cm', 'charge_unit', 'sales_price', 'price_m3', 'segment']
                available_cols = [col for col in display_cols if col in df_clean.columns]
                
                # Column config for English headers
                col_config = {
                    'sku': st.column_config.TextColumn('SKU'),
                    'processing_code': st.column_config.TextColumn('Main Processing Code'),
                    'processing_name': st.column_config.TextColumn('Main Processing'),
                    'customer_regional_group': st.column_config.TextColumn('Regional Group'),
                }
                
                # Display exact matches
                if len(exact_matches) > 0:
                    st.markdown(f"#### âœ… TÃ¬m tháº¥y {len(exact_matches)} sáº£n pháº©m khá»›p chÃ­nh xÃ¡c")
                    st.dataframe(exact_matches[available_cols], use_container_width=True, height=300, column_config=col_config)
                    
                    # Statistics for exact matches
                    valid_prices = exact_matches['sales_price']
                    if len(valid_prices) > 0:
                        st.markdown("##### ğŸ“Š Thá»‘ng kÃª giÃ¡ (khá»›p chÃ­nh xÃ¡c)")
                        stat_col1, stat_col2, stat_col3, stat_col4 = st.columns(4)
                        with stat_col1:
                            st.metric("Tháº¥p nháº¥t", f"${valid_prices.min():,.2f}")
                        with stat_col2:
                            st.metric("Cao nháº¥t", f"${valid_prices.max():,.2f}")
                        with stat_col3:
                            st.metric("Trung bÃ¬nh", f"${valid_prices.mean():,.2f}")
                        with stat_col4:
                            st.metric("Trung vá»‹", f"${valid_prices.median():,.2f}")
                else:
                    st.warning("âš ï¸ KhÃ´ng tÃ¬m tháº¥y sáº£n pháº©m khá»›p chÃ­nh xÃ¡c vá»›i tiÃªu chÃ­.")
                
                # Step 2: Show related products if checkbox is checked
                if show_related:
                    st.divider()
                    st.markdown(f"#### ğŸ”— Sáº£n pháº©m liÃªn quan (top {related_count})")
                    
                    # Find related products based on partial criteria
                    related_mask = pd.Series([False] * len(df_clean), index=df_clean.index)
                    
                    if search_family:
                        related_mask |= df_clean['family'] == search_family
                    if search_stone:
                        related_mask |= df_clean['stone_color_type'] == search_stone
                    if search_processing and 'processing_code' in df_clean.columns:
                        related_mask |= df_clean['processing_code'] == search_processing
                    if search_regional_group and 'customer_regional_group' in df_clean.columns:
                        related_mask |= df_clean['customer_regional_group'] == search_regional_group
                    
                    # Exclude exact matches
                    related_mask &= ~exact_mask
                    
                    related_products = df_clean[related_mask].copy()
                    
                    # Sort by dimension similarity if dimensions provided
                    if search_length > 0 and search_width > 0 and search_height > 0:
                        related_products['dim_diff'] = (
                            abs(related_products['length_cm'] - search_length) +
                            abs(related_products['width_cm'] - search_width) +
                            abs(related_products['height_cm'] - search_height)
                        )
                        related_products = related_products.nsmallest(related_count, 'dim_diff')
                    else:
                        related_products = related_products.head(related_count)
                    
                    if len(related_products) > 0:
                        st.dataframe(related_products[available_cols], use_container_width=True, height=300, column_config=col_config)
                        
                        # Statistics for related products
                        valid_prices = related_products['sales_price']
                        if len(valid_prices) > 0:
                            st.markdown("##### ğŸ“Š Thá»‘ng kÃª giÃ¡ (sáº£n pháº©m liÃªn quan)")
                            stat_col1, stat_col2, stat_col3, stat_col4 = st.columns(4)
                            with stat_col1:
                                st.metric("Tháº¥p nháº¥t", f"${valid_prices.min():,.2f}")
                            with stat_col2:
                                st.metric("Cao nháº¥t", f"${valid_prices.max():,.2f}")
                            with stat_col3:
                                st.metric("Trung bÃ¬nh", f"${valid_prices.mean():,.2f}")
                            with stat_col4:
                                st.metric("Trung vá»‹", f"${valid_prices.median():,.2f}")
                            
                            # Summary
                            price_range = valid_prices.max() - valid_prices.min()
                            st.caption(f"Khoáº£ng giÃ¡: ${price_range:,.2f} | Äá»™ lá»‡ch chuáº©n: ${valid_prices.std():,.2f}")
                    else:
                        st.info("KhÃ´ng tÃ¬m tháº¥y sáº£n pháº©m liÃªn quan.")
    
    # Tab 4: Weight & Conversion Reference
    with tab4:
        st.subheader("ğŸ“ Báº£ng tra cá»©u TLR & Há»‡ sá»‘")
        
        if st.session_state.model_metrics is not None:
            metrics = st.session_state.model_metrics
            loaded = metrics.get('loaded_samples', 0)
            st.success(f"âœ… ÄÃ£ táº£i **{loaded:,}** sáº£n pháº©m cÃ³ giÃ¡")
        
        st.divider()
        
        # TLR Reference Table
        st.markdown("#### âš–ï¸ Trá»ng LÆ°á»£ng RiÃªng (TLR)")
        tlr_data = {
            'Sáº£n pháº©m': [
                'ÄÃ¡ Ä‘en Äak NÃ´ng (Absolute Basalt)',
                'ÄÃ¡ PhÆ°á»›c HÃ²a/Qui NhÆ¡n (cÆ°a cáº¯t mÃ¡y)',
                'ÄÃ¡ PhÆ°á»›c HÃ²a/Qui NhÆ¡n (cháº» tay)',
                'Dark Grey Granite',
                'Granite thÆ°á»ng',
                'Bluestone (Thanh HÃ³a)',
                'ÄÃ¡ tá»• ong'
            ],
            'TLR (táº¥n/mÂ³)': ['2.95', '2.70', '2.65', '2.90', '2.70', '2.70', '2.20'],
            'Ghi chÃº': [
                'HÃ ng Dak NÃ´ng má»—i cont 9.3-9.6 mÂ³',
                '',
                '',
                '',
                '',
                '',
                ''
            ]
        }
        st.dataframe(pd.DataFrame(tlr_data), use_container_width=True, hide_index=True)
        
        st.divider()
        
        # HS Factors Table
        st.markdown("#### ğŸ“Š Há»‡ Sá»‘ á»p ÄÃ¡y (HS)")
        hs_data = {
            'Sáº£n pháº©m': [
                'ÄÃ¡ lÃ¡t 6cm máº·t Ä‘á»‘t, cáº¡nh sá»™',
                'ÄÃ¡ cubic cháº» tay 5Ã—5Ã—5cm',
                'ÄÃ¡ cubic cháº» tay 8Ã—8Ã—8cm',
                'ÄÃ¡ cubic cháº» tay 10Ã—10Ã—8cm, 20Ã—10Ã—8cm',
                'ÄÃ¡ cubic cháº» tay 15Ã—15Ã—12cm',
                'ÄÃ¡ cubic máº·t Ä‘á»‘t, cáº¡nh cháº» tay',
                'ÄÃ¡ cÃ¢y cÆ°a lá»™t'
            ],
            'HS': ['0.97', '1.00', '0.95', '0.875', '0.85', '0.95', '1.05'],
            'Ghi chÃº': [
                'á»p Ä‘Ã¡y giáº£m 3%',
                '',
                '',
                '',
                '',
                '',
                'DÃ y thá»±c táº¿ 10.5cm, +5%'
            ]
        }
        st.dataframe(pd.DataFrame(hs_data), use_container_width=True, hide_index=True)
        
        st.divider()
        
        # Formulas
        st.markdown("#### ğŸ“ CÃ´ng thá»©c tÃ­nh toÃ¡n")
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("""
**TÃ­nh mÂ³ (Thá»ƒ tÃ­ch):**
```
mÂ³ = (DÃ i Ã— Rá»™ng Ã— Cao) / 1.000.000 Ã— Sá»‘ viÃªn
```

**TÃ­nh mÂ² (Diá»‡n tÃ­ch):**
```
mÂ² = (DÃ i Ã— Rá»™ng) / 10.000 Ã— Sá»‘ viÃªn
```

**TÃ­nh Táº¥n (Trá»ng lÆ°á»£ng):**
```
Táº¥n = mÂ³ Ã— TLR Ã— HS
```
            """)
        with col2:
            st.markdown("""
**Quy Ä‘á»•i giÃ¡ tá»« ViÃªn:**
- `GiÃ¡/mÂ² = GiÃ¡ ViÃªn Ã· D(m) Ã· R(m)`
- `GiÃ¡/mÂ³ = GiÃ¡ ViÃªn Ã· D(m) Ã· R(m) Ã· C(m)`
- `GiÃ¡/Táº¥n = GiÃ¡ ViÃªn Ã· D Ã· R Ã· C Ã· TLR Ã· HS`

**Quy Ä‘á»•i giá»¯a Ä‘Æ¡n vá»‹:**
- `GiÃ¡/mÂ² = GiÃ¡/mÂ³ Ã— Cao(m)`
- `GiÃ¡/mÂ³ = GiÃ¡/Táº¥n Ã— TLR Ã— HS`
            """)
        
        st.divider()
        
        # Container weight reference
        st.markdown("#### ğŸš¢ Quy chuáº©n trá»ng lÆ°á»£ng Container")
        container_data = {
            'Thá»‹ trÆ°á»ng': ['Má»¹', 'ChÃ¢u Ã‚u', 'Ãšc', 'Nháº­t'],
            'Trá»ng lÆ°á»£ng (táº¥n)': ['20-21', '27-28', '24-26', '27.5-28']
        }
        st.dataframe(pd.DataFrame(container_data), use_container_width=True, hide_index=True)
    
    # Tab 5: Detailed Data
    with tab5:
        st.subheader("ğŸ“‹ Dá»¯ liá»‡u chi tiáº¿t")
        
        # Filters
        filter_col1, filter_col2, filter_col3, filter_col4 = st.columns(4)
        with filter_col1:
            filter_family = st.multiselect("Loáº¡i sáº£n pháº©m", PRODUCT_FAMILIES)
        with filter_col2:
            filter_segment = st.multiselect("PhÃ¢n khÃºc", ['Economy', 'Common', 'Premium', 'Super premium'])
        with filter_col3:
            filter_regional_group = st.multiselect(
                "NhÃ³m Khu vá»±c KH", 
                [code for code, name in CUSTOMER_REGIONAL_GROUPS if code]
            )
        with filter_col4:
            price_range = st.slider("Khoáº£ng giÃ¡ (USD/mÂ³)", 0, 2000, (0, 2000))
        
        # Apply filters
        filtered_df = st.session_state.data.copy()
        if filter_family:
            filtered_df = filtered_df[filtered_df['family'].isin(filter_family)]
        if filter_segment:
            filtered_df = filtered_df[filtered_df['segment'].isin(filter_segment)]
        if filter_regional_group and 'customer_regional_group' in filtered_df.columns:
            filtered_df = filtered_df[filtered_df['customer_regional_group'].isin(filter_regional_group)]
        filtered_df = filtered_df[
            (filtered_df['price_m3'] >= price_range[0]) & 
            (filtered_df['price_m3'] <= price_range[1])
        ]
        
        st.markdown(f"**Hiá»ƒn thá»‹ {len(filtered_df):,} / {len(st.session_state.data):,} sáº£n pháº©m**")
        
        # Define all columns from the contract query in logical order
        # These match the fields from contract_query.txt and salesforce_loader.py
        all_contract_columns = [
            'contract_product_name',   # Name
            'contract_name',           # Contract__r.Name
            'account_code',            # Account_Code_C__c
            'customer_regional_group', # Contract__r.Account__r.Nhom_Khu_vuc_KH__c
            'stone_color_type',        # Product__r.STONE_Color_Type__c
            'sku',                     # Product__r.StockKeepingUnit (SKU)
            'processing_code',         # Main processing code (from SKU)
            'processing_name',         # Main processing name (English)
            'family',                  # Product__r.Family
            'segment',                 # Segment__c
            'created_date',            # Created_Date__c
            'fy_year',                 # Fiscal Year (calculated)
            'product_description',     # Product_Discription__c
            'product_description_vn',  # Product__r.Product_description_in_Vietnamese__c
            'length_cm',               # Length__c
            'width_cm',                # Width__c
            'height_cm',               # Height__c
            'quantity',                # Quantity__c
            'crates',                  # Crates__c
            'm2',                      # m2__c
            'm3',                      # m3__c
            'ml',                      # ml__c
            'tons',                    # Tons__c
            'sales_price',             # Sales_Price__c
            'charge_unit',             # Charge_Unit__c
            'total_price_usd',         # Total_Price_USD__c
            'price_m3',                # Calculated price per m3
        ]
        
        # Filter to only columns that exist in the dataframe
        available_columns = [col for col in all_contract_columns if col in filtered_df.columns]
        
        # Add any remaining columns not in the predefined list
        remaining_columns = [col for col in filtered_df.columns if col not in available_columns]
        display_columns = available_columns + remaining_columns
        
        # Column configuration for English headers on specific columns
        column_config = {
            'sku': st.column_config.TextColumn('SKU', help='Product Stock Keeping Unit'),
            'processing_code': st.column_config.TextColumn('Main Processing Code', help='KÃ½ hiá»‡u gia cÃ´ng chÃ­nh'),
            'processing_name': st.column_config.TextColumn('Main Processing', help='NhÃ³m mÃ£ gia cÃ´ng chÃ­nh'),
            'customer_regional_group': st.column_config.TextColumn('Regional Group', help='NhÃ³m Khu vá»±c KH'),
        }
        
        # Display data with all columns
        st.dataframe(
            filtered_df[display_columns],
            use_container_width=True,
            height=500,
            column_config=column_config
        )
        
        # Download button
        csv = filtered_df[display_columns].to_csv(index=False)
        st.download_button(
            "ğŸ“¥ Táº£i xuá»‘ng CSV",
            csv,
            "stone_price_data.csv",
            "text/csv",
            use_container_width=True
        )


if __name__ == "__main__":
    main()
